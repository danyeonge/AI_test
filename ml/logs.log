2023-09-05 12:07:47,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:07:47,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:07:47,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:07:47,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:07:48,166:INFO:PyCaret ClassificationExperiment
2023-09-05 12:07:48,166:INFO:Logging name: clf-default-name
2023-09-05 12:07:48,166:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-05 12:07:48,166:INFO:version 3.0.4
2023-09-05 12:07:48,166:INFO:Initializing setup()
2023-09-05 12:07:48,166:INFO:self.USI: 5ae5
2023-09-05 12:07:48,166:INFO:self._variable_keys: {'html_param', 'gpu_n_jobs_param', 'memory', '_ml_usecase', 'X_test', 'logging_param', 'fix_imbalance', 'y_test', 'X_train', 'X', 'seed', 'y_train', 'y', 'is_multiclass', 'data', 'USI', 'idx', '_available_plots', 'n_jobs_param', 'gpu_param', 'fold_shuffle_param', 'exp_id', 'log_plots_param', 'target_param', 'pipeline', 'exp_name_log', 'fold_generator', 'fold_groups_param'}
2023-09-05 12:07:48,166:INFO:Checking environment
2023-09-05 12:07:48,166:INFO:python_version: 3.8.8
2023-09-05 12:07:48,167:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-05 12:07:48,167:INFO:machine: AMD64
2023-09-05 12:07:48,167:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-05 12:07:48,168:INFO:Memory: svmem(total=16822788096, available=8796225536, percent=47.7, used=8026562560, free=8796225536)
2023-09-05 12:07:48,168:INFO:Physical Core: 8
2023-09-05 12:07:48,168:INFO:Logical Core: 16
2023-09-05 12:07:48,168:INFO:Checking libraries
2023-09-05 12:07:48,168:INFO:System:
2023-09-05 12:07:48,168:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-05 12:07:48,168:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-05 12:07:48,168:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-05 12:07:48,168:INFO:PyCaret required dependencies:
2023-09-05 12:07:48,169:INFO:                 pip: 22.3.1
2023-09-05 12:07:48,169:INFO:          setuptools: 65.5.1
2023-09-05 12:07:48,169:INFO:             pycaret: 3.0.4
2023-09-05 12:07:48,169:INFO:             IPython: 8.12.2
2023-09-05 12:07:48,169:INFO:          ipywidgets: 8.0.7
2023-09-05 12:07:48,169:INFO:                tqdm: 4.66.1
2023-09-05 12:07:48,169:INFO:               numpy: 1.23.5
2023-09-05 12:07:48,169:INFO:              pandas: 1.5.3
2023-09-05 12:07:48,169:INFO:              jinja2: 3.1.2
2023-09-05 12:07:48,169:INFO:               scipy: 1.10.1
2023-09-05 12:07:48,169:INFO:              joblib: 1.3.2
2023-09-05 12:07:48,169:INFO:             sklearn: 1.2.2
2023-09-05 12:07:48,169:INFO:                pyod: 1.1.0
2023-09-05 12:07:48,169:INFO:            imblearn: 0.11.0
2023-09-05 12:07:48,169:INFO:   category_encoders: 2.6.2
2023-09-05 12:07:48,169:INFO:            lightgbm: 4.0.0
2023-09-05 12:07:48,169:INFO:               numba: 0.57.1
2023-09-05 12:07:48,170:INFO:            requests: 2.31.0
2023-09-05 12:07:48,170:INFO:          matplotlib: 3.7.2
2023-09-05 12:07:48,170:INFO:          scikitplot: 0.3.7
2023-09-05 12:07:48,170:INFO:         yellowbrick: 1.5
2023-09-05 12:07:48,170:INFO:              plotly: 5.15.0
2023-09-05 12:07:48,170:INFO:    plotly-resampler: Not installed
2023-09-05 12:07:48,170:INFO:             kaleido: 0.2.1
2023-09-05 12:07:48,170:INFO:           schemdraw: 0.15
2023-09-05 12:07:48,170:INFO:         statsmodels: 0.14.0
2023-09-05 12:07:48,170:INFO:              sktime: 0.22.0
2023-09-05 12:07:48,170:INFO:               tbats: 1.1.3
2023-09-05 12:07:48,170:INFO:            pmdarima: 2.0.3
2023-09-05 12:07:48,170:INFO:              psutil: 5.9.5
2023-09-05 12:07:48,170:INFO:          markupsafe: 2.1.3
2023-09-05 12:07:48,170:INFO:             pickle5: Not installed
2023-09-05 12:07:48,170:INFO:         cloudpickle: 2.2.1
2023-09-05 12:07:48,170:INFO:         deprecation: 2.1.0
2023-09-05 12:07:48,170:INFO:              xxhash: 3.3.0
2023-09-05 12:07:48,170:INFO:           wurlitzer: Not installed
2023-09-05 12:07:48,170:INFO:PyCaret optional dependencies:
2023-09-05 12:07:48,175:INFO:                shap: Not installed
2023-09-05 12:07:48,175:INFO:           interpret: Not installed
2023-09-05 12:07:48,175:INFO:                umap: Not installed
2023-09-05 12:07:48,175:INFO:    pandas_profiling: 4.5.1
2023-09-05 12:07:48,175:INFO:  explainerdashboard: Not installed
2023-09-05 12:07:48,175:INFO:             autoviz: Not installed
2023-09-05 12:07:48,175:INFO:           fairlearn: Not installed
2023-09-05 12:07:48,175:INFO:          deepchecks: Not installed
2023-09-05 12:07:48,175:INFO:             xgboost: 1.7.6
2023-09-05 12:07:48,175:INFO:            catboost: 1.2.1
2023-09-05 12:07:48,175:INFO:              kmodes: Not installed
2023-09-05 12:07:48,175:INFO:             mlxtend: Not installed
2023-09-05 12:07:48,175:INFO:       statsforecast: Not installed
2023-09-05 12:07:48,175:INFO:        tune_sklearn: Not installed
2023-09-05 12:07:48,175:INFO:                 ray: Not installed
2023-09-05 12:07:48,175:INFO:            hyperopt: Not installed
2023-09-05 12:07:48,175:INFO:              optuna: 3.3.0
2023-09-05 12:07:48,175:INFO:               skopt: 0.9.0
2023-09-05 12:07:48,175:INFO:              mlflow: Not installed
2023-09-05 12:07:48,175:INFO:              gradio: Not installed
2023-09-05 12:07:48,175:INFO:             fastapi: Not installed
2023-09-05 12:07:48,175:INFO:             uvicorn: Not installed
2023-09-05 12:07:48,175:INFO:              m2cgen: Not installed
2023-09-05 12:07:48,175:INFO:           evidently: Not installed
2023-09-05 12:07:48,175:INFO:               fugue: Not installed
2023-09-05 12:07:48,176:INFO:           streamlit: Not installed
2023-09-05 12:07:48,176:INFO:             prophet: Not installed
2023-09-05 12:07:48,176:INFO:None
2023-09-05 12:07:48,176:INFO:Set up data.
2023-09-05 12:07:48,180:INFO:Set up train/test split.
2023-09-05 12:07:48,183:INFO:Set up index.
2023-09-05 12:07:48,184:INFO:Set up folding strategy.
2023-09-05 12:07:48,184:INFO:Assigning column types.
2023-09-05 12:07:48,185:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-05 12:07:48,225:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 12:07:48,227:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:07:48,257:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:48,259:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:48,289:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 12:07:48,290:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:07:48,308:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:48,310:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:48,311:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-05 12:07:48,343:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:07:48,363:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:48,365:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:48,396:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:07:48,414:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:48,416:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:48,416:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-05 12:07:48,465:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:48,467:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:48,517:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:48,519:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:48,527:INFO:Preparing preprocessing pipeline...
2023-09-05 12:07:48,535:INFO:Set up simple imputation.
2023-09-05 12:07:48,548:INFO:Finished creating preprocessing pipeline.
2023-09-05 12:07:48,551:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pclass', 'sex', 'age', 'fare',
                                             'name_title', 'family',
                                             'fare_per_family', 'cabin2',
                                             'etc'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-09-05 12:07:48,551:INFO:Creating final display dataframe.
2023-09-05 12:07:48,584:INFO:Setup _display_container:                     Description             Value
0                    Session id              6876
1                        Target          survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (712, 10)
6    Transformed test set shape         (179, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 3
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              5ae5
2023-09-05 12:07:48,648:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:48,649:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:48,699:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:07:48,700:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:07:48,701:INFO:setup() successfully completed in 0.54s...............
2023-09-05 12:08:19,653:INFO:PyCaret ClassificationExperiment
2023-09-05 12:08:19,653:INFO:Logging name: clf-default-name
2023-09-05 12:08:19,653:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-05 12:08:19,653:INFO:version 3.0.4
2023-09-05 12:08:19,653:INFO:Initializing setup()
2023-09-05 12:08:19,653:INFO:self.USI: e091
2023-09-05 12:08:19,653:INFO:self._variable_keys: {'html_param', 'gpu_n_jobs_param', 'memory', '_ml_usecase', 'X_test', 'logging_param', 'fix_imbalance', 'y_test', 'X_train', 'X', 'seed', 'y_train', 'y', 'is_multiclass', 'data', 'USI', 'idx', '_available_plots', 'n_jobs_param', 'gpu_param', 'fold_shuffle_param', 'exp_id', 'log_plots_param', 'target_param', 'pipeline', 'exp_name_log', 'fold_generator', 'fold_groups_param'}
2023-09-05 12:08:19,653:INFO:Checking environment
2023-09-05 12:08:19,653:INFO:python_version: 3.8.8
2023-09-05 12:08:19,653:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-05 12:08:19,654:INFO:machine: AMD64
2023-09-05 12:08:19,654:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-05 12:08:19,656:INFO:Memory: svmem(total=16822788096, available=8764346368, percent=47.9, used=8058441728, free=8764346368)
2023-09-05 12:08:19,656:INFO:Physical Core: 8
2023-09-05 12:08:19,656:INFO:Logical Core: 16
2023-09-05 12:08:19,656:INFO:Checking libraries
2023-09-05 12:08:19,656:INFO:System:
2023-09-05 12:08:19,656:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-05 12:08:19,656:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-05 12:08:19,656:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-05 12:08:19,656:INFO:PyCaret required dependencies:
2023-09-05 12:08:19,656:INFO:                 pip: 22.3.1
2023-09-05 12:08:19,656:INFO:          setuptools: 65.5.1
2023-09-05 12:08:19,656:INFO:             pycaret: 3.0.4
2023-09-05 12:08:19,656:INFO:             IPython: 8.12.2
2023-09-05 12:08:19,656:INFO:          ipywidgets: 8.0.7
2023-09-05 12:08:19,656:INFO:                tqdm: 4.66.1
2023-09-05 12:08:19,656:INFO:               numpy: 1.23.5
2023-09-05 12:08:19,656:INFO:              pandas: 1.5.3
2023-09-05 12:08:19,656:INFO:              jinja2: 3.1.2
2023-09-05 12:08:19,656:INFO:               scipy: 1.10.1
2023-09-05 12:08:19,656:INFO:              joblib: 1.3.2
2023-09-05 12:08:19,656:INFO:             sklearn: 1.2.2
2023-09-05 12:08:19,657:INFO:                pyod: 1.1.0
2023-09-05 12:08:19,657:INFO:            imblearn: 0.11.0
2023-09-05 12:08:19,657:INFO:   category_encoders: 2.6.2
2023-09-05 12:08:19,657:INFO:            lightgbm: 4.0.0
2023-09-05 12:08:19,657:INFO:               numba: 0.57.1
2023-09-05 12:08:19,657:INFO:            requests: 2.31.0
2023-09-05 12:08:19,657:INFO:          matplotlib: 3.7.2
2023-09-05 12:08:19,657:INFO:          scikitplot: 0.3.7
2023-09-05 12:08:19,657:INFO:         yellowbrick: 1.5
2023-09-05 12:08:19,657:INFO:              plotly: 5.15.0
2023-09-05 12:08:19,657:INFO:    plotly-resampler: Not installed
2023-09-05 12:08:19,657:INFO:             kaleido: 0.2.1
2023-09-05 12:08:19,657:INFO:           schemdraw: 0.15
2023-09-05 12:08:19,657:INFO:         statsmodels: 0.14.0
2023-09-05 12:08:19,657:INFO:              sktime: 0.22.0
2023-09-05 12:08:19,657:INFO:               tbats: 1.1.3
2023-09-05 12:08:19,657:INFO:            pmdarima: 2.0.3
2023-09-05 12:08:19,657:INFO:              psutil: 5.9.5
2023-09-05 12:08:19,657:INFO:          markupsafe: 2.1.3
2023-09-05 12:08:19,657:INFO:             pickle5: Not installed
2023-09-05 12:08:19,657:INFO:         cloudpickle: 2.2.1
2023-09-05 12:08:19,657:INFO:         deprecation: 2.1.0
2023-09-05 12:08:19,657:INFO:              xxhash: 3.3.0
2023-09-05 12:08:19,657:INFO:           wurlitzer: Not installed
2023-09-05 12:08:19,657:INFO:PyCaret optional dependencies:
2023-09-05 12:08:19,658:INFO:                shap: Not installed
2023-09-05 12:08:19,658:INFO:           interpret: Not installed
2023-09-05 12:08:19,658:INFO:                umap: Not installed
2023-09-05 12:08:19,658:INFO:    pandas_profiling: 4.5.1
2023-09-05 12:08:19,658:INFO:  explainerdashboard: Not installed
2023-09-05 12:08:19,658:INFO:             autoviz: Not installed
2023-09-05 12:08:19,658:INFO:           fairlearn: Not installed
2023-09-05 12:08:19,658:INFO:          deepchecks: Not installed
2023-09-05 12:08:19,658:INFO:             xgboost: 1.7.6
2023-09-05 12:08:19,658:INFO:            catboost: 1.2.1
2023-09-05 12:08:19,658:INFO:              kmodes: Not installed
2023-09-05 12:08:19,658:INFO:             mlxtend: Not installed
2023-09-05 12:08:19,658:INFO:       statsforecast: Not installed
2023-09-05 12:08:19,658:INFO:        tune_sklearn: Not installed
2023-09-05 12:08:19,658:INFO:                 ray: Not installed
2023-09-05 12:08:19,658:INFO:            hyperopt: Not installed
2023-09-05 12:08:19,658:INFO:              optuna: 3.3.0
2023-09-05 12:08:19,658:INFO:               skopt: 0.9.0
2023-09-05 12:08:19,658:INFO:              mlflow: Not installed
2023-09-05 12:08:19,658:INFO:              gradio: Not installed
2023-09-05 12:08:19,658:INFO:             fastapi: Not installed
2023-09-05 12:08:19,658:INFO:             uvicorn: Not installed
2023-09-05 12:08:19,658:INFO:              m2cgen: Not installed
2023-09-05 12:08:19,658:INFO:           evidently: Not installed
2023-09-05 12:08:19,658:INFO:               fugue: Not installed
2023-09-05 12:08:19,658:INFO:           streamlit: Not installed
2023-09-05 12:08:19,658:INFO:             prophet: Not installed
2023-09-05 12:08:19,658:INFO:None
2023-09-05 12:08:19,658:INFO:Set up data.
2023-09-05 12:08:19,662:INFO:Set up train/test split.
2023-09-05 12:08:19,665:INFO:Set up index.
2023-09-05 12:08:19,665:INFO:Set up folding strategy.
2023-09-05 12:08:19,665:INFO:Assigning column types.
2023-09-05 12:08:19,668:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-05 12:08:19,701:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 12:08:19,702:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:08:19,722:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:19,724:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:19,754:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 12:08:19,754:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:08:19,774:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:19,776:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:19,776:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-05 12:08:19,806:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:08:19,824:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:19,826:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:19,856:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:08:19,876:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:19,878:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:19,879:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-05 12:08:19,932:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:19,933:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:19,984:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:19,987:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:19,988:INFO:Preparing preprocessing pipeline...
2023-09-05 12:08:19,989:INFO:Set up simple imputation.
2023-09-05 12:08:19,996:INFO:Finished creating preprocessing pipeline.
2023-09-05 12:08:19,998:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pclass', 'sex', 'age', 'fare',
                                             'name_title', 'family',
                                             'fare_per_family', 'cabin2',
                                             'etc'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-09-05 12:08:19,998:INFO:Creating final display dataframe.
2023-09-05 12:08:20,032:INFO:Setup _display_container:                     Description             Value
0                    Session id              1212
1                        Target          survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (712, 10)
6    Transformed test set shape         (179, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 3
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e091
2023-09-05 12:08:20,085:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:20,087:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:20,137:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:08:20,139:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:08:20,139:INFO:setup() successfully completed in 0.49s...............
2023-09-05 12:12:20,257:INFO:gpu_param set to False
2023-09-05 12:12:20,312:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:12:20,314:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:12:20,364:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:12:20,366:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:12:48,891:INFO:gpu_param set to False
2023-09-05 12:12:48,945:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:12:48,946:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:12:48,997:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:12:48,998:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:14:49,831:INFO:Initializing compare_models()
2023-09-05 12:14:49,831:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost'])
2023-09-05 12:14:49,831:INFO:Checking exceptions
2023-09-05 12:14:49,834:INFO:Preparing display monitor
2023-09-05 12:14:49,851:INFO:Initializing Logistic Regression
2023-09-05 12:14:49,851:INFO:Total runtime is 0.0 minutes
2023-09-05 12:14:49,856:INFO:SubProcess create_model() called ==================================
2023-09-05 12:14:49,856:INFO:Initializing create_model()
2023-09-05 12:14:49,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:14:49,857:INFO:Checking exceptions
2023-09-05 12:14:49,857:INFO:Importing libraries
2023-09-05 12:14:49,857:INFO:Copying training dataset
2023-09-05 12:14:49,860:INFO:Defining folds
2023-09-05 12:14:49,860:INFO:Declaring metric variables
2023-09-05 12:14:49,862:INFO:Importing untrained model
2023-09-05 12:14:49,865:INFO:Logistic Regression Imported successfully
2023-09-05 12:14:49,870:INFO:Starting cross validation
2023-09-05 12:14:49,870:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:14:51,729:INFO:Calculating mean and std
2023-09-05 12:14:51,731:INFO:Creating metrics dataframe
2023-09-05 12:14:51,737:INFO:Uploading results into container
2023-09-05 12:14:51,738:INFO:Uploading model into container now
2023-09-05 12:14:51,739:INFO:_master_model_container: 1
2023-09-05 12:14:51,739:INFO:_display_container: 2
2023-09-05 12:14:51,739:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1212, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-05 12:14:51,739:INFO:create_model() successfully completed......................................
2023-09-05 12:14:51,805:INFO:SubProcess create_model() end ==================================
2023-09-05 12:14:51,806:INFO:Creating metrics dataframe
2023-09-05 12:14:51,811:INFO:Initializing K Neighbors Classifier
2023-09-05 12:14:51,811:INFO:Total runtime is 0.03266356786092122 minutes
2023-09-05 12:14:51,813:INFO:SubProcess create_model() called ==================================
2023-09-05 12:14:51,813:INFO:Initializing create_model()
2023-09-05 12:14:51,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=knn, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:14:51,813:INFO:Checking exceptions
2023-09-05 12:14:51,813:INFO:Importing libraries
2023-09-05 12:14:51,813:INFO:Copying training dataset
2023-09-05 12:14:51,815:INFO:Defining folds
2023-09-05 12:14:51,815:INFO:Declaring metric variables
2023-09-05 12:14:51,818:INFO:Importing untrained model
2023-09-05 12:14:51,820:INFO:K Neighbors Classifier Imported successfully
2023-09-05 12:14:51,824:INFO:Starting cross validation
2023-09-05 12:14:51,825:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:14:53,247:INFO:Calculating mean and std
2023-09-05 12:14:53,249:INFO:Creating metrics dataframe
2023-09-05 12:14:53,253:INFO:Uploading results into container
2023-09-05 12:14:53,254:INFO:Uploading model into container now
2023-09-05 12:14:53,254:INFO:_master_model_container: 2
2023-09-05 12:14:53,255:INFO:_display_container: 2
2023-09-05 12:14:53,255:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-05 12:14:53,255:INFO:create_model() successfully completed......................................
2023-09-05 12:14:53,322:INFO:SubProcess create_model() end ==================================
2023-09-05 12:14:53,322:INFO:Creating metrics dataframe
2023-09-05 12:14:53,328:INFO:Initializing Naive Bayes
2023-09-05 12:14:53,328:INFO:Total runtime is 0.057938142617543535 minutes
2023-09-05 12:14:53,330:INFO:SubProcess create_model() called ==================================
2023-09-05 12:14:53,330:INFO:Initializing create_model()
2023-09-05 12:14:53,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=nb, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:14:53,330:INFO:Checking exceptions
2023-09-05 12:14:53,330:INFO:Importing libraries
2023-09-05 12:14:53,330:INFO:Copying training dataset
2023-09-05 12:14:53,333:INFO:Defining folds
2023-09-05 12:14:53,333:INFO:Declaring metric variables
2023-09-05 12:14:53,335:INFO:Importing untrained model
2023-09-05 12:14:53,337:INFO:Naive Bayes Imported successfully
2023-09-05 12:14:53,341:INFO:Starting cross validation
2023-09-05 12:14:53,342:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:14:54,748:INFO:Calculating mean and std
2023-09-05 12:14:54,750:INFO:Creating metrics dataframe
2023-09-05 12:14:54,755:INFO:Uploading results into container
2023-09-05 12:14:54,755:INFO:Uploading model into container now
2023-09-05 12:14:54,756:INFO:_master_model_container: 3
2023-09-05 12:14:54,756:INFO:_display_container: 2
2023-09-05 12:14:54,756:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-05 12:14:54,756:INFO:create_model() successfully completed......................................
2023-09-05 12:14:54,819:INFO:SubProcess create_model() end ==================================
2023-09-05 12:14:54,819:INFO:Creating metrics dataframe
2023-09-05 12:14:54,825:INFO:Initializing Decision Tree Classifier
2023-09-05 12:14:54,825:INFO:Total runtime is 0.08288689454396565 minutes
2023-09-05 12:14:54,827:INFO:SubProcess create_model() called ==================================
2023-09-05 12:14:54,827:INFO:Initializing create_model()
2023-09-05 12:14:54,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:14:54,827:INFO:Checking exceptions
2023-09-05 12:14:54,827:INFO:Importing libraries
2023-09-05 12:14:54,827:INFO:Copying training dataset
2023-09-05 12:14:54,829:INFO:Defining folds
2023-09-05 12:14:54,829:INFO:Declaring metric variables
2023-09-05 12:14:54,831:INFO:Importing untrained model
2023-09-05 12:14:54,833:INFO:Decision Tree Classifier Imported successfully
2023-09-05 12:14:54,837:INFO:Starting cross validation
2023-09-05 12:14:54,838:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:14:56,236:INFO:Calculating mean and std
2023-09-05 12:14:56,237:INFO:Creating metrics dataframe
2023-09-05 12:14:56,241:INFO:Uploading results into container
2023-09-05 12:14:56,242:INFO:Uploading model into container now
2023-09-05 12:14:56,242:INFO:_master_model_container: 4
2023-09-05 12:14:56,242:INFO:_display_container: 2
2023-09-05 12:14:56,243:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-05 12:14:56,243:INFO:create_model() successfully completed......................................
2023-09-05 12:14:56,306:INFO:SubProcess create_model() end ==================================
2023-09-05 12:14:56,306:INFO:Creating metrics dataframe
2023-09-05 12:14:56,312:INFO:Initializing SVM - Linear Kernel
2023-09-05 12:14:56,312:INFO:Total runtime is 0.10767685572306315 minutes
2023-09-05 12:14:56,314:INFO:SubProcess create_model() called ==================================
2023-09-05 12:14:56,314:INFO:Initializing create_model()
2023-09-05 12:14:56,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=svm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:14:56,314:INFO:Checking exceptions
2023-09-05 12:14:56,314:INFO:Importing libraries
2023-09-05 12:14:56,314:INFO:Copying training dataset
2023-09-05 12:14:56,317:INFO:Defining folds
2023-09-05 12:14:56,317:INFO:Declaring metric variables
2023-09-05 12:14:56,320:INFO:Importing untrained model
2023-09-05 12:14:56,323:INFO:SVM - Linear Kernel Imported successfully
2023-09-05 12:14:56,327:INFO:Starting cross validation
2023-09-05 12:14:56,328:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:14:57,709:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 12:14:57,709:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 12:14:57,709:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 12:14:57,726:INFO:Calculating mean and std
2023-09-05 12:14:57,727:INFO:Creating metrics dataframe
2023-09-05 12:14:57,731:INFO:Uploading results into container
2023-09-05 12:14:57,732:INFO:Uploading model into container now
2023-09-05 12:14:57,732:INFO:_master_model_container: 5
2023-09-05 12:14:57,732:INFO:_display_container: 2
2023-09-05 12:14:57,733:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1212, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-05 12:14:57,733:INFO:create_model() successfully completed......................................
2023-09-05 12:14:57,798:INFO:SubProcess create_model() end ==================================
2023-09-05 12:14:57,798:INFO:Creating metrics dataframe
2023-09-05 12:14:57,805:INFO:Initializing Ridge Classifier
2023-09-05 12:14:57,805:INFO:Total runtime is 0.13256609837214153 minutes
2023-09-05 12:14:57,807:INFO:SubProcess create_model() called ==================================
2023-09-05 12:14:57,807:INFO:Initializing create_model()
2023-09-05 12:14:57,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=ridge, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:14:57,807:INFO:Checking exceptions
2023-09-05 12:14:57,807:INFO:Importing libraries
2023-09-05 12:14:57,807:INFO:Copying training dataset
2023-09-05 12:14:57,809:INFO:Defining folds
2023-09-05 12:14:57,810:INFO:Declaring metric variables
2023-09-05 12:14:57,811:INFO:Importing untrained model
2023-09-05 12:14:57,813:INFO:Ridge Classifier Imported successfully
2023-09-05 12:14:57,818:INFO:Starting cross validation
2023-09-05 12:14:57,818:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:14:57,861:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 12:14:57,861:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 12:14:59,032:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 12:14:59,042:INFO:Calculating mean and std
2023-09-05 12:14:59,043:INFO:Creating metrics dataframe
2023-09-05 12:14:59,046:INFO:Uploading results into container
2023-09-05 12:14:59,046:INFO:Uploading model into container now
2023-09-05 12:14:59,046:INFO:_master_model_container: 6
2023-09-05 12:14:59,047:INFO:_display_container: 2
2023-09-05 12:14:59,047:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1212, solver='auto',
                tol=0.0001)
2023-09-05 12:14:59,047:INFO:create_model() successfully completed......................................
2023-09-05 12:14:59,106:INFO:SubProcess create_model() end ==================================
2023-09-05 12:14:59,106:INFO:Creating metrics dataframe
2023-09-05 12:14:59,113:INFO:Initializing Random Forest Classifier
2023-09-05 12:14:59,113:INFO:Total runtime is 0.1543612003326416 minutes
2023-09-05 12:14:59,115:INFO:SubProcess create_model() called ==================================
2023-09-05 12:14:59,115:INFO:Initializing create_model()
2023-09-05 12:14:59,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:14:59,115:INFO:Checking exceptions
2023-09-05 12:14:59,115:INFO:Importing libraries
2023-09-05 12:14:59,115:INFO:Copying training dataset
2023-09-05 12:14:59,118:INFO:Defining folds
2023-09-05 12:14:59,118:INFO:Declaring metric variables
2023-09-05 12:14:59,119:INFO:Importing untrained model
2023-09-05 12:14:59,121:INFO:Random Forest Classifier Imported successfully
2023-09-05 12:14:59,125:INFO:Starting cross validation
2023-09-05 12:14:59,126:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:14:59,486:INFO:Calculating mean and std
2023-09-05 12:14:59,487:INFO:Creating metrics dataframe
2023-09-05 12:14:59,490:INFO:Uploading results into container
2023-09-05 12:14:59,490:INFO:Uploading model into container now
2023-09-05 12:14:59,491:INFO:_master_model_container: 7
2023-09-05 12:14:59,491:INFO:_display_container: 2
2023-09-05 12:14:59,491:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 12:14:59,491:INFO:create_model() successfully completed......................................
2023-09-05 12:14:59,544:INFO:SubProcess create_model() end ==================================
2023-09-05 12:14:59,544:INFO:Creating metrics dataframe
2023-09-05 12:14:59,551:INFO:Initializing Quadratic Discriminant Analysis
2023-09-05 12:14:59,551:INFO:Total runtime is 0.1616605083147685 minutes
2023-09-05 12:14:59,553:INFO:SubProcess create_model() called ==================================
2023-09-05 12:14:59,553:INFO:Initializing create_model()
2023-09-05 12:14:59,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=qda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:14:59,553:INFO:Checking exceptions
2023-09-05 12:14:59,553:INFO:Importing libraries
2023-09-05 12:14:59,553:INFO:Copying training dataset
2023-09-05 12:14:59,556:INFO:Defining folds
2023-09-05 12:14:59,556:INFO:Declaring metric variables
2023-09-05 12:14:59,558:INFO:Importing untrained model
2023-09-05 12:14:59,560:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-05 12:14:59,564:INFO:Starting cross validation
2023-09-05 12:14:59,564:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:14:59,629:INFO:Calculating mean and std
2023-09-05 12:14:59,629:INFO:Creating metrics dataframe
2023-09-05 12:14:59,633:INFO:Uploading results into container
2023-09-05 12:14:59,634:INFO:Uploading model into container now
2023-09-05 12:14:59,635:INFO:_master_model_container: 8
2023-09-05 12:14:59,635:INFO:_display_container: 2
2023-09-05 12:14:59,635:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-05 12:14:59,635:INFO:create_model() successfully completed......................................
2023-09-05 12:14:59,691:INFO:SubProcess create_model() end ==================================
2023-09-05 12:14:59,691:INFO:Creating metrics dataframe
2023-09-05 12:14:59,697:INFO:Initializing Ada Boost Classifier
2023-09-05 12:14:59,697:INFO:Total runtime is 0.16409619251887006 minutes
2023-09-05 12:14:59,699:INFO:SubProcess create_model() called ==================================
2023-09-05 12:14:59,700:INFO:Initializing create_model()
2023-09-05 12:14:59,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=ada, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:14:59,700:INFO:Checking exceptions
2023-09-05 12:14:59,700:INFO:Importing libraries
2023-09-05 12:14:59,700:INFO:Copying training dataset
2023-09-05 12:14:59,702:INFO:Defining folds
2023-09-05 12:14:59,702:INFO:Declaring metric variables
2023-09-05 12:14:59,704:INFO:Importing untrained model
2023-09-05 12:14:59,706:INFO:Ada Boost Classifier Imported successfully
2023-09-05 12:14:59,711:INFO:Starting cross validation
2023-09-05 12:14:59,712:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:14:59,867:INFO:Calculating mean and std
2023-09-05 12:14:59,868:INFO:Creating metrics dataframe
2023-09-05 12:14:59,871:INFO:Uploading results into container
2023-09-05 12:14:59,871:INFO:Uploading model into container now
2023-09-05 12:14:59,872:INFO:_master_model_container: 9
2023-09-05 12:14:59,872:INFO:_display_container: 2
2023-09-05 12:14:59,872:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1212)
2023-09-05 12:14:59,872:INFO:create_model() successfully completed......................................
2023-09-05 12:14:59,927:INFO:SubProcess create_model() end ==================================
2023-09-05 12:14:59,927:INFO:Creating metrics dataframe
2023-09-05 12:14:59,934:INFO:Initializing Gradient Boosting Classifier
2023-09-05 12:14:59,934:INFO:Total runtime is 0.1680522402127584 minutes
2023-09-05 12:14:59,936:INFO:SubProcess create_model() called ==================================
2023-09-05 12:14:59,936:INFO:Initializing create_model()
2023-09-05 12:14:59,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=gbc, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:14:59,936:INFO:Checking exceptions
2023-09-05 12:14:59,936:INFO:Importing libraries
2023-09-05 12:14:59,936:INFO:Copying training dataset
2023-09-05 12:14:59,938:INFO:Defining folds
2023-09-05 12:14:59,938:INFO:Declaring metric variables
2023-09-05 12:14:59,940:INFO:Importing untrained model
2023-09-05 12:14:59,942:INFO:Gradient Boosting Classifier Imported successfully
2023-09-05 12:14:59,946:INFO:Starting cross validation
2023-09-05 12:14:59,947:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:00,117:INFO:Calculating mean and std
2023-09-05 12:15:00,118:INFO:Creating metrics dataframe
2023-09-05 12:15:00,121:INFO:Uploading results into container
2023-09-05 12:15:00,121:INFO:Uploading model into container now
2023-09-05 12:15:00,122:INFO:_master_model_container: 10
2023-09-05 12:15:00,122:INFO:_display_container: 2
2023-09-05 12:15:00,122:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-05 12:15:00,122:INFO:create_model() successfully completed......................................
2023-09-05 12:15:00,176:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:00,177:INFO:Creating metrics dataframe
2023-09-05 12:15:00,184:INFO:Initializing Linear Discriminant Analysis
2023-09-05 12:15:00,184:INFO:Total runtime is 0.17220779259999597 minutes
2023-09-05 12:15:00,186:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:00,186:INFO:Initializing create_model()
2023-09-05 12:15:00,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=lda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:00,186:INFO:Checking exceptions
2023-09-05 12:15:00,186:INFO:Importing libraries
2023-09-05 12:15:00,186:INFO:Copying training dataset
2023-09-05 12:15:00,188:INFO:Defining folds
2023-09-05 12:15:00,188:INFO:Declaring metric variables
2023-09-05 12:15:00,190:INFO:Importing untrained model
2023-09-05 12:15:00,192:INFO:Linear Discriminant Analysis Imported successfully
2023-09-05 12:15:00,196:INFO:Starting cross validation
2023-09-05 12:15:00,197:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:00,258:INFO:Calculating mean and std
2023-09-05 12:15:00,258:INFO:Creating metrics dataframe
2023-09-05 12:15:00,262:INFO:Uploading results into container
2023-09-05 12:15:00,262:INFO:Uploading model into container now
2023-09-05 12:15:00,262:INFO:_master_model_container: 11
2023-09-05 12:15:00,262:INFO:_display_container: 2
2023-09-05 12:15:00,263:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-05 12:15:00,263:INFO:create_model() successfully completed......................................
2023-09-05 12:15:00,316:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:00,316:INFO:Creating metrics dataframe
2023-09-05 12:15:00,323:INFO:Initializing Extra Trees Classifier
2023-09-05 12:15:00,323:INFO:Total runtime is 0.1745349446932475 minutes
2023-09-05 12:15:00,326:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:00,326:INFO:Initializing create_model()
2023-09-05 12:15:00,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=et, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:00,326:INFO:Checking exceptions
2023-09-05 12:15:00,326:INFO:Importing libraries
2023-09-05 12:15:00,326:INFO:Copying training dataset
2023-09-05 12:15:00,328:INFO:Defining folds
2023-09-05 12:15:00,329:INFO:Declaring metric variables
2023-09-05 12:15:00,330:INFO:Importing untrained model
2023-09-05 12:15:00,333:INFO:Extra Trees Classifier Imported successfully
2023-09-05 12:15:00,336:INFO:Starting cross validation
2023-09-05 12:15:00,337:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:00,668:INFO:Calculating mean and std
2023-09-05 12:15:00,669:INFO:Creating metrics dataframe
2023-09-05 12:15:00,673:INFO:Uploading results into container
2023-09-05 12:15:00,674:INFO:Uploading model into container now
2023-09-05 12:15:00,674:INFO:_master_model_container: 12
2023-09-05 12:15:00,674:INFO:_display_container: 2
2023-09-05 12:15:00,674:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1212, verbose=0, warm_start=False)
2023-09-05 12:15:00,674:INFO:create_model() successfully completed......................................
2023-09-05 12:15:00,727:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:00,727:INFO:Creating metrics dataframe
2023-09-05 12:15:00,734:INFO:Initializing Extreme Gradient Boosting
2023-09-05 12:15:00,734:INFO:Total runtime is 0.18138324817021692 minutes
2023-09-05 12:15:00,736:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:00,736:INFO:Initializing create_model()
2023-09-05 12:15:00,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:00,736:INFO:Checking exceptions
2023-09-05 12:15:00,736:INFO:Importing libraries
2023-09-05 12:15:00,736:INFO:Copying training dataset
2023-09-05 12:15:00,739:INFO:Defining folds
2023-09-05 12:15:00,739:INFO:Declaring metric variables
2023-09-05 12:15:00,741:INFO:Importing untrained model
2023-09-05 12:15:00,743:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 12:15:00,747:INFO:Starting cross validation
2023-09-05 12:15:00,747:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:00,856:INFO:Calculating mean and std
2023-09-05 12:15:00,857:INFO:Creating metrics dataframe
2023-09-05 12:15:00,861:INFO:Uploading results into container
2023-09-05 12:15:00,861:INFO:Uploading model into container now
2023-09-05 12:15:00,861:INFO:_master_model_container: 13
2023-09-05 12:15:00,861:INFO:_display_container: 2
2023-09-05 12:15:00,862:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-05 12:15:00,862:INFO:create_model() successfully completed......................................
2023-09-05 12:15:00,917:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:00,917:INFO:Creating metrics dataframe
2023-09-05 12:15:00,924:INFO:Initializing Light Gradient Boosting Machine
2023-09-05 12:15:00,924:INFO:Total runtime is 0.18454151948293054 minutes
2023-09-05 12:15:00,927:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:00,927:INFO:Initializing create_model()
2023-09-05 12:15:00,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:00,927:INFO:Checking exceptions
2023-09-05 12:15:00,927:INFO:Importing libraries
2023-09-05 12:15:00,927:INFO:Copying training dataset
2023-09-05 12:15:00,929:INFO:Defining folds
2023-09-05 12:15:00,929:INFO:Declaring metric variables
2023-09-05 12:15:00,932:INFO:Importing untrained model
2023-09-05 12:15:00,935:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 12:15:00,939:INFO:Starting cross validation
2023-09-05 12:15:00,940:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:01,169:INFO:Calculating mean and std
2023-09-05 12:15:01,170:INFO:Creating metrics dataframe
2023-09-05 12:15:01,178:INFO:Uploading results into container
2023-09-05 12:15:01,179:INFO:Uploading model into container now
2023-09-05 12:15:01,179:INFO:_master_model_container: 14
2023-09-05 12:15:01,179:INFO:_display_container: 2
2023-09-05 12:15:01,179:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 12:15:01,180:INFO:create_model() successfully completed......................................
2023-09-05 12:15:01,251:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:01,251:INFO:Creating metrics dataframe
2023-09-05 12:15:01,260:INFO:Initializing Dummy Classifier
2023-09-05 12:15:01,260:INFO:Total runtime is 0.1901432077089946 minutes
2023-09-05 12:15:01,262:INFO:SubProcess create_model() called ==================================
2023-09-05 12:15:01,262:INFO:Initializing create_model()
2023-09-05 12:15:01,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=dummy, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE142B20>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:01,262:INFO:Checking exceptions
2023-09-05 12:15:01,262:INFO:Importing libraries
2023-09-05 12:15:01,262:INFO:Copying training dataset
2023-09-05 12:15:01,265:INFO:Defining folds
2023-09-05 12:15:01,265:INFO:Declaring metric variables
2023-09-05 12:15:01,267:INFO:Importing untrained model
2023-09-05 12:15:01,269:INFO:Dummy Classifier Imported successfully
2023-09-05 12:15:01,273:INFO:Starting cross validation
2023-09-05 12:15:01,273:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:15:01,318:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 12:15:01,318:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 12:15:01,318:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 12:15:01,327:INFO:Calculating mean and std
2023-09-05 12:15:01,328:INFO:Creating metrics dataframe
2023-09-05 12:15:01,335:INFO:Uploading results into container
2023-09-05 12:15:01,336:INFO:Uploading model into container now
2023-09-05 12:15:01,336:INFO:_master_model_container: 15
2023-09-05 12:15:01,336:INFO:_display_container: 2
2023-09-05 12:15:01,336:INFO:DummyClassifier(constant=None, random_state=1212, strategy='prior')
2023-09-05 12:15:01,336:INFO:create_model() successfully completed......................................
2023-09-05 12:15:01,389:INFO:SubProcess create_model() end ==================================
2023-09-05 12:15:01,389:INFO:Creating metrics dataframe
2023-09-05 12:15:01,402:INFO:Initializing create_model()
2023-09-05 12:15:01,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:15:01,402:INFO:Checking exceptions
2023-09-05 12:15:01,403:INFO:Importing libraries
2023-09-05 12:15:01,403:INFO:Copying training dataset
2023-09-05 12:15:01,405:INFO:Defining folds
2023-09-05 12:15:01,406:INFO:Declaring metric variables
2023-09-05 12:15:01,406:INFO:Importing untrained model
2023-09-05 12:15:01,406:INFO:Declaring custom model
2023-09-05 12:15:01,406:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 12:15:01,407:INFO:Cross validation set to False
2023-09-05 12:15:01,407:INFO:Fitting Model
2023-09-05 12:15:01,421:INFO:[LightGBM] [Info] Number of positive: 273, number of negative: 439
2023-09-05 12:15:01,422:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.
2023-09-05 12:15:01,422:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-09-05 12:15:01,422:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-09-05 12:15:01,422:INFO:[LightGBM] [Info] Total Bins 274
2023-09-05 12:15:01,423:INFO:[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 9
2023-09-05 12:15:01,423:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028
2023-09-05 12:15:01,423:INFO:[LightGBM] [Info] Start training from score -0.475028
2023-09-05 12:15:01,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:15:01,469:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 12:15:01,470:INFO:create_model() successfully completed......................................
2023-09-05 12:15:01,566:INFO:_master_model_container: 15
2023-09-05 12:15:01,566:INFO:_display_container: 2
2023-09-05 12:15:01,566:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 12:15:01,566:INFO:compare_models() successfully completed......................................
2023-09-05 14:38:17,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 14:38:17,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 14:38:17,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 14:38:17,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 14:43:14,207:INFO:PyCaret RegressionExperiment
2023-09-05 14:43:14,207:INFO:Logging name: reg-default-name
2023-09-05 14:43:14,207:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-05 14:43:14,207:INFO:version 3.0.4
2023-09-05 14:43:14,207:INFO:Initializing setup()
2023-09-05 14:43:14,207:INFO:self.USI: 82ac
2023-09-05 14:43:14,207:INFO:self._variable_keys: {'exp_id', 'target_param', 'gpu_n_jobs_param', 'X_test', 'n_jobs_param', '_available_plots', 'USI', 'log_plots_param', 'html_param', 'idx', '_ml_usecase', 'fold_shuffle_param', 'gpu_param', 'seed', 'y_test', 'fold_groups_param', 'pipeline', 'data', 'transform_target_param', 'fold_generator', 'memory', 'X', 'y_train', 'X_train', 'y', 'logging_param', 'exp_name_log'}
2023-09-05 14:43:14,207:INFO:Checking environment
2023-09-05 14:43:14,207:INFO:python_version: 3.8.8
2023-09-05 14:43:14,207:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-05 14:43:14,207:INFO:machine: AMD64
2023-09-05 14:43:14,207:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-05 14:43:14,210:INFO:Memory: svmem(total=16822788096, available=8295657472, percent=50.7, used=8527130624, free=8295657472)
2023-09-05 14:43:14,210:INFO:Physical Core: 8
2023-09-05 14:43:14,210:INFO:Logical Core: 16
2023-09-05 14:43:14,210:INFO:Checking libraries
2023-09-05 14:43:14,210:INFO:System:
2023-09-05 14:43:14,210:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-05 14:43:14,210:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-05 14:43:14,210:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-05 14:43:14,210:INFO:PyCaret required dependencies:
2023-09-05 14:43:14,245:INFO:                 pip: 22.3.1
2023-09-05 14:43:14,245:INFO:          setuptools: 65.5.1
2023-09-05 14:43:14,245:INFO:             pycaret: 3.0.4
2023-09-05 14:43:14,245:INFO:             IPython: 8.12.2
2023-09-05 14:43:14,245:INFO:          ipywidgets: 8.0.7
2023-09-05 14:43:14,245:INFO:                tqdm: 4.66.1
2023-09-05 14:43:14,245:INFO:               numpy: 1.23.5
2023-09-05 14:43:14,245:INFO:              pandas: 1.5.3
2023-09-05 14:43:14,245:INFO:              jinja2: 3.1.2
2023-09-05 14:43:14,245:INFO:               scipy: 1.10.1
2023-09-05 14:43:14,245:INFO:              joblib: 1.3.2
2023-09-05 14:43:14,245:INFO:             sklearn: 1.2.2
2023-09-05 14:43:14,245:INFO:                pyod: 1.1.0
2023-09-05 14:43:14,245:INFO:            imblearn: 0.11.0
2023-09-05 14:43:14,245:INFO:   category_encoders: 2.6.2
2023-09-05 14:43:14,245:INFO:            lightgbm: 4.0.0
2023-09-05 14:43:14,245:INFO:               numba: 0.57.1
2023-09-05 14:43:14,245:INFO:            requests: 2.31.0
2023-09-05 14:43:14,245:INFO:          matplotlib: 3.7.2
2023-09-05 14:43:14,245:INFO:          scikitplot: 0.3.7
2023-09-05 14:43:14,245:INFO:         yellowbrick: 1.5
2023-09-05 14:43:14,245:INFO:              plotly: 5.15.0
2023-09-05 14:43:14,245:INFO:    plotly-resampler: Not installed
2023-09-05 14:43:14,245:INFO:             kaleido: 0.2.1
2023-09-05 14:43:14,245:INFO:           schemdraw: 0.15
2023-09-05 14:43:14,245:INFO:         statsmodels: 0.14.0
2023-09-05 14:43:14,245:INFO:              sktime: 0.22.0
2023-09-05 14:43:14,245:INFO:               tbats: 1.1.3
2023-09-05 14:43:14,245:INFO:            pmdarima: 2.0.3
2023-09-05 14:43:14,245:INFO:              psutil: 5.9.5
2023-09-05 14:43:14,245:INFO:          markupsafe: 2.1.3
2023-09-05 14:43:14,245:INFO:             pickle5: Not installed
2023-09-05 14:43:14,245:INFO:         cloudpickle: 2.2.1
2023-09-05 14:43:14,245:INFO:         deprecation: 2.1.0
2023-09-05 14:43:14,245:INFO:              xxhash: 3.3.0
2023-09-05 14:43:14,245:INFO:           wurlitzer: Not installed
2023-09-05 14:43:14,245:INFO:PyCaret optional dependencies:
2023-09-05 14:43:14,251:INFO:                shap: Not installed
2023-09-05 14:43:14,251:INFO:           interpret: Not installed
2023-09-05 14:43:14,251:INFO:                umap: Not installed
2023-09-05 14:43:14,251:INFO:    pandas_profiling: 4.5.1
2023-09-05 14:43:14,251:INFO:  explainerdashboard: Not installed
2023-09-05 14:43:14,251:INFO:             autoviz: Not installed
2023-09-05 14:43:14,251:INFO:           fairlearn: Not installed
2023-09-05 14:43:14,251:INFO:          deepchecks: Not installed
2023-09-05 14:43:14,251:INFO:             xgboost: 1.7.6
2023-09-05 14:43:14,252:INFO:            catboost: 1.2.1
2023-09-05 14:43:14,252:INFO:              kmodes: Not installed
2023-09-05 14:43:14,252:INFO:             mlxtend: Not installed
2023-09-05 14:43:14,252:INFO:       statsforecast: Not installed
2023-09-05 14:43:14,252:INFO:        tune_sklearn: Not installed
2023-09-05 14:43:14,252:INFO:                 ray: Not installed
2023-09-05 14:43:14,252:INFO:            hyperopt: Not installed
2023-09-05 14:43:14,252:INFO:              optuna: 3.3.0
2023-09-05 14:43:14,252:INFO:               skopt: 0.9.0
2023-09-05 14:43:14,252:INFO:              mlflow: Not installed
2023-09-05 14:43:14,252:INFO:              gradio: Not installed
2023-09-05 14:43:14,252:INFO:             fastapi: Not installed
2023-09-05 14:43:14,252:INFO:             uvicorn: Not installed
2023-09-05 14:43:14,252:INFO:              m2cgen: Not installed
2023-09-05 14:43:14,252:INFO:           evidently: Not installed
2023-09-05 14:43:14,252:INFO:               fugue: Not installed
2023-09-05 14:43:14,252:INFO:           streamlit: Not installed
2023-09-05 14:43:14,252:INFO:             prophet: Not installed
2023-09-05 14:43:14,252:INFO:None
2023-09-05 14:43:14,252:INFO:Set up data.
2023-09-05 14:43:14,258:INFO:Set up train/test split.
2023-09-05 14:43:14,261:INFO:Set up index.
2023-09-05 14:43:14,262:INFO:Set up folding strategy.
2023-09-05 14:43:14,262:INFO:Assigning column types.
2023-09-05 14:43:14,264:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-05 14:43:14,264:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,267:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,271:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,314:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,343:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,344:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:14,360:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:14,373:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,376:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,379:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,444:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,446:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:14,447:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:14,448:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-09-05 14:43:14,451:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,454:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,521:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:14,523:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:14,526:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,529:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,598:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,598:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:14,600:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:14,600:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-09-05 14:43:14,606:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,648:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,679:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:14,680:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:14,687:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,728:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,758:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,759:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:14,761:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:14,761:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-09-05 14:43:14,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,835:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,835:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:14,837:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:14,881:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:14,912:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:14,914:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:14,914:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-05 14:43:14,957:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:15,000:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:15,002:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:15,045:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:15,074:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:15,076:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:15,076:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-09-05 14:43:15,153:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:15,155:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:15,231:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:15,233:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:15,234:INFO:Preparing preprocessing pipeline...
2023-09-05 14:43:15,234:INFO:Set up simple imputation.
2023-09-05 14:43:15,236:INFO:Set up encoding of ordinal features.
2023-09-05 14:43:15,238:INFO:Set up encoding of categorical features.
2023-09-05 14:43:15,282:INFO:Finished creating preprocessing pipeline.
2023-09-05 14:43:15,311:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-09-05 14:43:15,311:INFO:Creating final display dataframe.
2023-09-05 14:43:15,433:INFO:Setup _display_container:                     Description             Value
0                    Session id              6077
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              82ac
2023-09-05 14:43:17,036:WARNING:C:\AI\pythonProject\venv\lib\site-packages\numba\core\decorators.py:262: NumbaDeprecationWarning: [1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.[0m
  warnings.warn(msg, NumbaDeprecationWarning)

2023-09-05 14:43:17,045:WARNING:C:\AI\pythonProject\venv\lib\site-packages\visions\backends\shared\nan_handling.py:51: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  def hasna(x: np.ndarray) -> bool:

2023-09-05 14:43:17,256:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:17,258:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:17,337:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:17,338:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:17,339:INFO:setup() successfully completed in 3.14s...............
2023-09-05 14:43:17,353:INFO:PyCaret RegressionExperiment
2023-09-05 14:43:17,353:INFO:Logging name: reg-default-name
2023-09-05 14:43:17,354:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-05 14:43:17,354:INFO:version 3.0.4
2023-09-05 14:43:17,354:INFO:Initializing setup()
2023-09-05 14:43:17,354:INFO:self.USI: 6e88
2023-09-05 14:43:17,354:INFO:self._variable_keys: {'exp_id', 'target_param', 'gpu_n_jobs_param', 'X_test', 'n_jobs_param', '_available_plots', 'USI', 'log_plots_param', 'html_param', 'idx', '_ml_usecase', 'fold_shuffle_param', 'gpu_param', 'seed', 'y_test', 'fold_groups_param', 'pipeline', 'data', 'transform_target_param', 'fold_generator', 'memory', 'X', 'y_train', 'X_train', 'y', 'logging_param', 'exp_name_log'}
2023-09-05 14:43:17,354:INFO:Checking environment
2023-09-05 14:43:17,354:INFO:python_version: 3.8.8
2023-09-05 14:43:17,354:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-05 14:43:17,354:INFO:machine: AMD64
2023-09-05 14:43:17,354:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-05 14:43:17,355:INFO:Memory: svmem(total=16822788096, available=8227139584, percent=51.1, used=8595648512, free=8227139584)
2023-09-05 14:43:17,356:INFO:Physical Core: 8
2023-09-05 14:43:17,356:INFO:Logical Core: 16
2023-09-05 14:43:17,356:INFO:Checking libraries
2023-09-05 14:43:17,356:INFO:System:
2023-09-05 14:43:17,356:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-05 14:43:17,356:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-05 14:43:17,356:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-05 14:43:17,356:INFO:PyCaret required dependencies:
2023-09-05 14:43:17,356:INFO:                 pip: 22.3.1
2023-09-05 14:43:17,356:INFO:          setuptools: 65.5.1
2023-09-05 14:43:17,356:INFO:             pycaret: 3.0.4
2023-09-05 14:43:17,356:INFO:             IPython: 8.12.2
2023-09-05 14:43:17,356:INFO:          ipywidgets: 8.0.7
2023-09-05 14:43:17,356:INFO:                tqdm: 4.66.1
2023-09-05 14:43:17,356:INFO:               numpy: 1.23.5
2023-09-05 14:43:17,356:INFO:              pandas: 1.5.3
2023-09-05 14:43:17,356:INFO:              jinja2: 3.1.2
2023-09-05 14:43:17,356:INFO:               scipy: 1.10.1
2023-09-05 14:43:17,356:INFO:              joblib: 1.3.2
2023-09-05 14:43:17,356:INFO:             sklearn: 1.2.2
2023-09-05 14:43:17,356:INFO:                pyod: 1.1.0
2023-09-05 14:43:17,356:INFO:            imblearn: 0.11.0
2023-09-05 14:43:17,356:INFO:   category_encoders: 2.6.2
2023-09-05 14:43:17,356:INFO:            lightgbm: 4.0.0
2023-09-05 14:43:17,356:INFO:               numba: 0.57.1
2023-09-05 14:43:17,356:INFO:            requests: 2.31.0
2023-09-05 14:43:17,356:INFO:          matplotlib: 3.7.2
2023-09-05 14:43:17,356:INFO:          scikitplot: 0.3.7
2023-09-05 14:43:17,356:INFO:         yellowbrick: 1.5
2023-09-05 14:43:17,356:INFO:              plotly: 5.15.0
2023-09-05 14:43:17,356:INFO:    plotly-resampler: Not installed
2023-09-05 14:43:17,356:INFO:             kaleido: 0.2.1
2023-09-05 14:43:17,356:INFO:           schemdraw: 0.15
2023-09-05 14:43:17,356:INFO:         statsmodels: 0.14.0
2023-09-05 14:43:17,356:INFO:              sktime: 0.22.0
2023-09-05 14:43:17,356:INFO:               tbats: 1.1.3
2023-09-05 14:43:17,356:INFO:            pmdarima: 2.0.3
2023-09-05 14:43:17,356:INFO:              psutil: 5.9.5
2023-09-05 14:43:17,356:INFO:          markupsafe: 2.1.3
2023-09-05 14:43:17,356:INFO:             pickle5: Not installed
2023-09-05 14:43:17,356:INFO:         cloudpickle: 2.2.1
2023-09-05 14:43:17,356:INFO:         deprecation: 2.1.0
2023-09-05 14:43:17,357:INFO:              xxhash: 3.3.0
2023-09-05 14:43:17,357:INFO:           wurlitzer: Not installed
2023-09-05 14:43:17,357:INFO:PyCaret optional dependencies:
2023-09-05 14:43:17,357:INFO:                shap: Not installed
2023-09-05 14:43:17,357:INFO:           interpret: Not installed
2023-09-05 14:43:17,357:INFO:                umap: Not installed
2023-09-05 14:43:17,357:INFO:    pandas_profiling: 4.5.1
2023-09-05 14:43:17,357:INFO:  explainerdashboard: Not installed
2023-09-05 14:43:17,357:INFO:             autoviz: Not installed
2023-09-05 14:43:17,357:INFO:           fairlearn: Not installed
2023-09-05 14:43:17,357:INFO:          deepchecks: Not installed
2023-09-05 14:43:17,357:INFO:             xgboost: 1.7.6
2023-09-05 14:43:17,357:INFO:            catboost: 1.2.1
2023-09-05 14:43:17,357:INFO:              kmodes: Not installed
2023-09-05 14:43:17,357:INFO:             mlxtend: Not installed
2023-09-05 14:43:17,357:INFO:       statsforecast: Not installed
2023-09-05 14:43:17,357:INFO:        tune_sklearn: Not installed
2023-09-05 14:43:17,357:INFO:                 ray: Not installed
2023-09-05 14:43:17,357:INFO:            hyperopt: Not installed
2023-09-05 14:43:17,357:INFO:              optuna: 3.3.0
2023-09-05 14:43:17,357:INFO:               skopt: 0.9.0
2023-09-05 14:43:17,357:INFO:              mlflow: Not installed
2023-09-05 14:43:17,357:INFO:              gradio: Not installed
2023-09-05 14:43:17,357:INFO:             fastapi: Not installed
2023-09-05 14:43:17,357:INFO:             uvicorn: Not installed
2023-09-05 14:43:17,357:INFO:              m2cgen: Not installed
2023-09-05 14:43:17,357:INFO:           evidently: Not installed
2023-09-05 14:43:17,357:INFO:               fugue: Not installed
2023-09-05 14:43:17,357:INFO:           streamlit: Not installed
2023-09-05 14:43:17,357:INFO:             prophet: Not installed
2023-09-05 14:43:17,357:INFO:None
2023-09-05 14:43:17,357:INFO:Set up data.
2023-09-05 14:43:17,362:INFO:Set up train/test split.
2023-09-05 14:43:17,365:INFO:Set up index.
2023-09-05 14:43:17,365:INFO:Set up folding strategy.
2023-09-05 14:43:17,365:INFO:Assigning column types.
2023-09-05 14:43:17,367:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-05 14:43:17,367:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,370:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,373:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,411:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,440:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:17,442:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:17,442:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,445:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,448:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,517:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:17,518:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:17,519:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-09-05 14:43:17,522:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,526:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,565:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,595:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,596:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:17,599:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:17,602:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,605:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,678:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:17,680:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:17,680:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-09-05 14:43:17,686:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,722:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,753:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,753:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:17,755:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:17,761:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,830:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:17,832:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:17,832:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-09-05 14:43:17,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,908:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,908:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:17,910:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:17,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 14:43:17,982:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:17,984:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:17,984:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-05 14:43:18,031:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:18,060:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:18,062:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:18,106:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 14:43:18,137:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:18,138:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:18,139:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-09-05 14:43:18,215:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:18,217:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:18,292:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:18,293:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:18,294:INFO:Preparing preprocessing pipeline...
2023-09-05 14:43:18,294:INFO:Set up simple imputation.
2023-09-05 14:43:18,296:INFO:Set up encoding of ordinal features.
2023-09-05 14:43:18,297:INFO:Set up encoding of categorical features.
2023-09-05 14:43:18,339:INFO:Finished creating preprocessing pipeline.
2023-09-05 14:43:18,363:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-09-05 14:43:18,363:INFO:Creating final display dataframe.
2023-09-05 14:43:18,484:INFO:Setup _display_container:                     Description             Value
0                    Session id              5943
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              6e88
2023-09-05 14:43:18,570:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:18,572:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:18,648:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:18,650:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:18,650:INFO:setup() successfully completed in 1.3s...............
2023-09-05 14:43:28,646:INFO:gpu_param set to False
2023-09-05 14:43:28,735:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:28,737:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:28,814:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:28,816:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:28,840:INFO:gpu_param set to False
2023-09-05 14:43:28,921:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:28,923:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:28,998:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 14:43:29,000:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 14:43:29,063:INFO:Initializing compare_models()
2023-09-05 14:43:29,063:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, include=['lr', 'rf'], fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, 'include': ['lr', 'rf'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-05 14:43:29,063:INFO:Checking exceptions
2023-09-05 14:43:29,065:INFO:Preparing display monitor
2023-09-05 14:43:29,084:INFO:Initializing Linear Regression
2023-09-05 14:43:29,084:INFO:Total runtime is 0.0 minutes
2023-09-05 14:43:29,086:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:29,086:INFO:Initializing create_model()
2023-09-05 14:43:29,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E934CA5490>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:29,086:INFO:Checking exceptions
2023-09-05 14:43:29,087:INFO:Importing libraries
2023-09-05 14:43:29,087:INFO:Copying training dataset
2023-09-05 14:43:29,089:INFO:Defining folds
2023-09-05 14:43:29,089:INFO:Declaring metric variables
2023-09-05 14:43:29,091:INFO:Importing untrained model
2023-09-05 14:43:29,094:INFO:Linear Regression Imported successfully
2023-09-05 14:43:29,099:INFO:Starting cross validation
2023-09-05 14:43:29,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:32,231:INFO:Calculating mean and std
2023-09-05 14:43:32,233:INFO:Creating metrics dataframe
2023-09-05 14:43:32,244:INFO:Uploading results into container
2023-09-05 14:43:32,246:INFO:Uploading model into container now
2023-09-05 14:43:32,246:INFO:_master_model_container: 1
2023-09-05 14:43:32,247:INFO:_display_container: 2
2023-09-05 14:43:32,247:INFO:LinearRegression(n_jobs=-1)
2023-09-05 14:43:32,247:INFO:create_model() successfully completed......................................
2023-09-05 14:43:32,329:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:32,329:INFO:Creating metrics dataframe
2023-09-05 14:43:32,334:INFO:Initializing Random Forest Regressor
2023-09-05 14:43:32,335:INFO:Total runtime is 0.05418068965276082 minutes
2023-09-05 14:43:32,337:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:32,337:INFO:Initializing create_model()
2023-09-05 14:43:32,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E934CA5490>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:32,337:INFO:Checking exceptions
2023-09-05 14:43:32,337:INFO:Importing libraries
2023-09-05 14:43:32,337:INFO:Copying training dataset
2023-09-05 14:43:32,340:INFO:Defining folds
2023-09-05 14:43:32,340:INFO:Declaring metric variables
2023-09-05 14:43:32,343:INFO:Importing untrained model
2023-09-05 14:43:32,345:INFO:Random Forest Regressor Imported successfully
2023-09-05 14:43:32,350:INFO:Starting cross validation
2023-09-05 14:43:32,350:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:34,953:INFO:Calculating mean and std
2023-09-05 14:43:34,955:INFO:Creating metrics dataframe
2023-09-05 14:43:34,965:INFO:Uploading results into container
2023-09-05 14:43:34,965:INFO:Uploading model into container now
2023-09-05 14:43:34,966:INFO:_master_model_container: 2
2023-09-05 14:43:34,966:INFO:_display_container: 2
2023-09-05 14:43:34,966:INFO:RandomForestRegressor(n_jobs=-1, random_state=5943)
2023-09-05 14:43:34,966:INFO:create_model() successfully completed......................................
2023-09-05 14:43:35,035:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:35,036:INFO:Creating metrics dataframe
2023-09-05 14:43:35,046:INFO:Initializing create_model()
2023-09-05 14:43:35,046:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=5943), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:35,046:INFO:Checking exceptions
2023-09-05 14:43:35,047:INFO:Importing libraries
2023-09-05 14:43:35,047:INFO:Copying training dataset
2023-09-05 14:43:35,051:INFO:Defining folds
2023-09-05 14:43:35,051:INFO:Declaring metric variables
2023-09-05 14:43:35,051:INFO:Importing untrained model
2023-09-05 14:43:35,051:INFO:Declaring custom model
2023-09-05 14:43:35,052:INFO:Random Forest Regressor Imported successfully
2023-09-05 14:43:35,053:INFO:Cross validation set to False
2023-09-05 14:43:35,053:INFO:Fitting Model
2023-09-05 14:43:35,300:INFO:RandomForestRegressor(n_jobs=-1, random_state=5943)
2023-09-05 14:43:35,301:INFO:create_model() successfully completed......................................
2023-09-05 14:43:35,374:INFO:_master_model_container: 2
2023-09-05 14:43:35,375:INFO:_display_container: 2
2023-09-05 14:43:35,375:INFO:RandomForestRegressor(n_jobs=-1, random_state=5943)
2023-09-05 14:43:35,375:INFO:compare_models() successfully completed......................................
2023-09-05 14:43:35,401:INFO:Initializing compare_models()
2023-09-05 14:43:35,401:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=2, budget_time=0.5, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 2, 'budget_time': 0.5, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-05 14:43:35,401:INFO:Checking exceptions
2023-09-05 14:43:35,404:INFO:Preparing display monitor
2023-09-05 14:43:35,422:INFO:Time budget is 0.5 minutes
2023-09-05 14:43:35,423:INFO:Initializing Linear Regression
2023-09-05 14:43:35,423:INFO:Total runtime is 1.661380132039388e-05 minutes
2023-09-05 14:43:35,425:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:35,425:INFO:Initializing create_model()
2023-09-05 14:43:35,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:35,425:INFO:Checking exceptions
2023-09-05 14:43:35,425:INFO:Importing libraries
2023-09-05 14:43:35,425:INFO:Copying training dataset
2023-09-05 14:43:35,429:INFO:Defining folds
2023-09-05 14:43:35,429:INFO:Declaring metric variables
2023-09-05 14:43:35,432:INFO:Importing untrained model
2023-09-05 14:43:35,434:INFO:Linear Regression Imported successfully
2023-09-05 14:43:35,439:INFO:Starting cross validation
2023-09-05 14:43:35,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:35,666:INFO:Calculating mean and std
2023-09-05 14:43:35,667:INFO:Creating metrics dataframe
2023-09-05 14:43:35,674:INFO:Uploading results into container
2023-09-05 14:43:35,674:INFO:Uploading model into container now
2023-09-05 14:43:35,674:INFO:_master_model_container: 3
2023-09-05 14:43:35,674:INFO:_display_container: 3
2023-09-05 14:43:35,674:INFO:LinearRegression(n_jobs=-1)
2023-09-05 14:43:35,674:INFO:create_model() successfully completed......................................
2023-09-05 14:43:35,735:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:35,735:INFO:Creating metrics dataframe
2023-09-05 14:43:35,739:INFO:Initializing Lasso Regression
2023-09-05 14:43:35,740:INFO:Total runtime is 0.0053024808565775555 minutes
2023-09-05 14:43:35,741:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:35,742:INFO:Initializing create_model()
2023-09-05 14:43:35,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:35,742:INFO:Checking exceptions
2023-09-05 14:43:35,742:INFO:Importing libraries
2023-09-05 14:43:35,742:INFO:Copying training dataset
2023-09-05 14:43:35,745:INFO:Defining folds
2023-09-05 14:43:35,745:INFO:Declaring metric variables
2023-09-05 14:43:35,748:INFO:Importing untrained model
2023-09-05 14:43:35,752:INFO:Lasso Regression Imported successfully
2023-09-05 14:43:35,757:INFO:Starting cross validation
2023-09-05 14:43:35,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:35,982:INFO:Calculating mean and std
2023-09-05 14:43:35,982:INFO:Creating metrics dataframe
2023-09-05 14:43:35,989:INFO:Uploading results into container
2023-09-05 14:43:35,990:INFO:Uploading model into container now
2023-09-05 14:43:35,990:INFO:_master_model_container: 4
2023-09-05 14:43:35,990:INFO:_display_container: 3
2023-09-05 14:43:35,991:INFO:Lasso(random_state=5943)
2023-09-05 14:43:35,991:INFO:create_model() successfully completed......................................
2023-09-05 14:43:36,051:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:36,051:INFO:Creating metrics dataframe
2023-09-05 14:43:36,056:INFO:Initializing Ridge Regression
2023-09-05 14:43:36,056:INFO:Total runtime is 0.010571726163228353 minutes
2023-09-05 14:43:36,058:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:36,058:INFO:Initializing create_model()
2023-09-05 14:43:36,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:36,059:INFO:Checking exceptions
2023-09-05 14:43:36,059:INFO:Importing libraries
2023-09-05 14:43:36,059:INFO:Copying training dataset
2023-09-05 14:43:36,062:INFO:Defining folds
2023-09-05 14:43:36,062:INFO:Declaring metric variables
2023-09-05 14:43:36,065:INFO:Importing untrained model
2023-09-05 14:43:36,068:INFO:Ridge Regression Imported successfully
2023-09-05 14:43:36,073:INFO:Starting cross validation
2023-09-05 14:43:36,073:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:36,317:INFO:Calculating mean and std
2023-09-05 14:43:36,317:INFO:Creating metrics dataframe
2023-09-05 14:43:36,323:INFO:Uploading results into container
2023-09-05 14:43:36,324:INFO:Uploading model into container now
2023-09-05 14:43:36,324:INFO:_master_model_container: 5
2023-09-05 14:43:36,324:INFO:_display_container: 3
2023-09-05 14:43:36,324:INFO:Ridge(random_state=5943)
2023-09-05 14:43:36,324:INFO:create_model() successfully completed......................................
2023-09-05 14:43:36,390:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:36,390:INFO:Creating metrics dataframe
2023-09-05 14:43:36,397:INFO:Initializing Elastic Net
2023-09-05 14:43:36,397:INFO:Total runtime is 0.016256741682688397 minutes
2023-09-05 14:43:36,400:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:36,401:INFO:Initializing create_model()
2023-09-05 14:43:36,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:36,401:INFO:Checking exceptions
2023-09-05 14:43:36,401:INFO:Importing libraries
2023-09-05 14:43:36,401:INFO:Copying training dataset
2023-09-05 14:43:36,404:INFO:Defining folds
2023-09-05 14:43:36,404:INFO:Declaring metric variables
2023-09-05 14:43:36,406:INFO:Importing untrained model
2023-09-05 14:43:36,408:INFO:Elastic Net Imported successfully
2023-09-05 14:43:36,413:INFO:Starting cross validation
2023-09-05 14:43:36,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:36,666:INFO:Calculating mean and std
2023-09-05 14:43:36,667:INFO:Creating metrics dataframe
2023-09-05 14:43:36,673:INFO:Uploading results into container
2023-09-05 14:43:36,674:INFO:Uploading model into container now
2023-09-05 14:43:36,674:INFO:_master_model_container: 6
2023-09-05 14:43:36,674:INFO:_display_container: 3
2023-09-05 14:43:36,674:INFO:ElasticNet(random_state=5943)
2023-09-05 14:43:36,674:INFO:create_model() successfully completed......................................
2023-09-05 14:43:36,739:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:36,739:INFO:Creating metrics dataframe
2023-09-05 14:43:36,745:INFO:Initializing Least Angle Regression
2023-09-05 14:43:36,745:INFO:Total runtime is 0.022058161099751793 minutes
2023-09-05 14:43:36,747:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:36,747:INFO:Initializing create_model()
2023-09-05 14:43:36,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:36,748:INFO:Checking exceptions
2023-09-05 14:43:36,748:INFO:Importing libraries
2023-09-05 14:43:36,748:INFO:Copying training dataset
2023-09-05 14:43:36,750:INFO:Defining folds
2023-09-05 14:43:36,750:INFO:Declaring metric variables
2023-09-05 14:43:36,752:INFO:Importing untrained model
2023-09-05 14:43:36,754:INFO:Least Angle Regression Imported successfully
2023-09-05 14:43:36,758:INFO:Starting cross validation
2023-09-05 14:43:36,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:36,997:INFO:Calculating mean and std
2023-09-05 14:43:36,998:INFO:Creating metrics dataframe
2023-09-05 14:43:37,005:INFO:Uploading results into container
2023-09-05 14:43:37,005:INFO:Uploading model into container now
2023-09-05 14:43:37,005:INFO:_master_model_container: 7
2023-09-05 14:43:37,005:INFO:_display_container: 3
2023-09-05 14:43:37,005:INFO:Lars(random_state=5943)
2023-09-05 14:43:37,005:INFO:create_model() successfully completed......................................
2023-09-05 14:43:37,073:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:37,073:INFO:Creating metrics dataframe
2023-09-05 14:43:37,080:INFO:Initializing Lasso Least Angle Regression
2023-09-05 14:43:37,080:INFO:Total runtime is 0.02763345241546631 minutes
2023-09-05 14:43:37,082:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:37,083:INFO:Initializing create_model()
2023-09-05 14:43:37,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:37,083:INFO:Checking exceptions
2023-09-05 14:43:37,083:INFO:Importing libraries
2023-09-05 14:43:37,083:INFO:Copying training dataset
2023-09-05 14:43:37,085:INFO:Defining folds
2023-09-05 14:43:37,085:INFO:Declaring metric variables
2023-09-05 14:43:37,087:INFO:Importing untrained model
2023-09-05 14:43:37,089:INFO:Lasso Least Angle Regression Imported successfully
2023-09-05 14:43:37,094:INFO:Starting cross validation
2023-09-05 14:43:37,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:37,346:INFO:Calculating mean and std
2023-09-05 14:43:37,347:INFO:Creating metrics dataframe
2023-09-05 14:43:37,353:INFO:Uploading results into container
2023-09-05 14:43:37,353:INFO:Uploading model into container now
2023-09-05 14:43:37,354:INFO:_master_model_container: 8
2023-09-05 14:43:37,354:INFO:_display_container: 3
2023-09-05 14:43:37,354:INFO:LassoLars(random_state=5943)
2023-09-05 14:43:37,354:INFO:create_model() successfully completed......................................
2023-09-05 14:43:37,416:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:37,416:INFO:Creating metrics dataframe
2023-09-05 14:43:37,422:INFO:Initializing Orthogonal Matching Pursuit
2023-09-05 14:43:37,422:INFO:Total runtime is 0.03332682847976685 minutes
2023-09-05 14:43:37,424:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:37,425:INFO:Initializing create_model()
2023-09-05 14:43:37,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:37,425:INFO:Checking exceptions
2023-09-05 14:43:37,425:INFO:Importing libraries
2023-09-05 14:43:37,425:INFO:Copying training dataset
2023-09-05 14:43:37,430:INFO:Defining folds
2023-09-05 14:43:37,430:INFO:Declaring metric variables
2023-09-05 14:43:37,432:INFO:Importing untrained model
2023-09-05 14:43:37,435:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-05 14:43:37,439:INFO:Starting cross validation
2023-09-05 14:43:37,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:37,662:INFO:Calculating mean and std
2023-09-05 14:43:37,663:INFO:Creating metrics dataframe
2023-09-05 14:43:37,670:INFO:Uploading results into container
2023-09-05 14:43:37,671:INFO:Uploading model into container now
2023-09-05 14:43:37,671:INFO:_master_model_container: 9
2023-09-05 14:43:37,671:INFO:_display_container: 3
2023-09-05 14:43:37,671:INFO:OrthogonalMatchingPursuit()
2023-09-05 14:43:37,671:INFO:create_model() successfully completed......................................
2023-09-05 14:43:37,742:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:37,742:INFO:Creating metrics dataframe
2023-09-05 14:43:37,749:INFO:Initializing Bayesian Ridge
2023-09-05 14:43:37,749:INFO:Total runtime is 0.03877891302108765 minutes
2023-09-05 14:43:37,751:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:37,751:INFO:Initializing create_model()
2023-09-05 14:43:37,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:37,751:INFO:Checking exceptions
2023-09-05 14:43:37,751:INFO:Importing libraries
2023-09-05 14:43:37,751:INFO:Copying training dataset
2023-09-05 14:43:37,754:INFO:Defining folds
2023-09-05 14:43:37,754:INFO:Declaring metric variables
2023-09-05 14:43:37,755:INFO:Importing untrained model
2023-09-05 14:43:37,758:INFO:Bayesian Ridge Imported successfully
2023-09-05 14:43:37,762:INFO:Starting cross validation
2023-09-05 14:43:37,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:37,995:INFO:Calculating mean and std
2023-09-05 14:43:37,996:INFO:Creating metrics dataframe
2023-09-05 14:43:38,006:INFO:Uploading results into container
2023-09-05 14:43:38,006:INFO:Uploading model into container now
2023-09-05 14:43:38,006:INFO:_master_model_container: 10
2023-09-05 14:43:38,006:INFO:_display_container: 3
2023-09-05 14:43:38,007:INFO:BayesianRidge()
2023-09-05 14:43:38,007:INFO:create_model() successfully completed......................................
2023-09-05 14:43:38,070:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:38,070:INFO:Creating metrics dataframe
2023-09-05 14:43:38,077:INFO:Initializing Passive Aggressive Regressor
2023-09-05 14:43:38,077:INFO:Total runtime is 0.04424761931101481 minutes
2023-09-05 14:43:38,079:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:38,079:INFO:Initializing create_model()
2023-09-05 14:43:38,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:38,079:INFO:Checking exceptions
2023-09-05 14:43:38,079:INFO:Importing libraries
2023-09-05 14:43:38,079:INFO:Copying training dataset
2023-09-05 14:43:38,082:INFO:Defining folds
2023-09-05 14:43:38,083:INFO:Declaring metric variables
2023-09-05 14:43:38,085:INFO:Importing untrained model
2023-09-05 14:43:38,087:INFO:Passive Aggressive Regressor Imported successfully
2023-09-05 14:43:38,091:INFO:Starting cross validation
2023-09-05 14:43:38,092:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:38,328:INFO:Calculating mean and std
2023-09-05 14:43:38,329:INFO:Creating metrics dataframe
2023-09-05 14:43:38,338:INFO:Uploading results into container
2023-09-05 14:43:38,339:INFO:Uploading model into container now
2023-09-05 14:43:38,339:INFO:_master_model_container: 11
2023-09-05 14:43:38,339:INFO:_display_container: 3
2023-09-05 14:43:38,339:INFO:PassiveAggressiveRegressor(random_state=5943)
2023-09-05 14:43:38,339:INFO:create_model() successfully completed......................................
2023-09-05 14:43:38,407:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:38,408:INFO:Creating metrics dataframe
2023-09-05 14:43:38,414:INFO:Initializing Huber Regressor
2023-09-05 14:43:38,414:INFO:Total runtime is 0.04986648559570313 minutes
2023-09-05 14:43:38,416:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:38,417:INFO:Initializing create_model()
2023-09-05 14:43:38,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:38,417:INFO:Checking exceptions
2023-09-05 14:43:38,417:INFO:Importing libraries
2023-09-05 14:43:38,417:INFO:Copying training dataset
2023-09-05 14:43:38,419:INFO:Defining folds
2023-09-05 14:43:38,419:INFO:Declaring metric variables
2023-09-05 14:43:38,421:INFO:Importing untrained model
2023-09-05 14:43:38,423:INFO:Huber Regressor Imported successfully
2023-09-05 14:43:38,431:INFO:Starting cross validation
2023-09-05 14:43:38,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:38,580:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:38,583:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:38,602:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:38,605:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:38,613:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:38,621:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:38,635:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:38,709:INFO:Calculating mean and std
2023-09-05 14:43:38,710:INFO:Creating metrics dataframe
2023-09-05 14:43:38,721:INFO:Uploading results into container
2023-09-05 14:43:38,721:INFO:Uploading model into container now
2023-09-05 14:43:38,721:INFO:_master_model_container: 12
2023-09-05 14:43:38,721:INFO:_display_container: 3
2023-09-05 14:43:38,722:INFO:HuberRegressor()
2023-09-05 14:43:38,722:INFO:create_model() successfully completed......................................
2023-09-05 14:43:38,785:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:38,785:INFO:Creating metrics dataframe
2023-09-05 14:43:38,793:INFO:Initializing K Neighbors Regressor
2023-09-05 14:43:38,793:INFO:Total runtime is 0.056182396411895756 minutes
2023-09-05 14:43:38,795:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:38,795:INFO:Initializing create_model()
2023-09-05 14:43:38,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:38,796:INFO:Checking exceptions
2023-09-05 14:43:38,796:INFO:Importing libraries
2023-09-05 14:43:38,796:INFO:Copying training dataset
2023-09-05 14:43:38,798:INFO:Defining folds
2023-09-05 14:43:38,798:INFO:Declaring metric variables
2023-09-05 14:43:38,800:INFO:Importing untrained model
2023-09-05 14:43:38,803:INFO:K Neighbors Regressor Imported successfully
2023-09-05 14:43:38,807:INFO:Starting cross validation
2023-09-05 14:43:38,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:39,068:INFO:Calculating mean and std
2023-09-05 14:43:39,070:INFO:Creating metrics dataframe
2023-09-05 14:43:39,077:INFO:Uploading results into container
2023-09-05 14:43:39,078:INFO:Uploading model into container now
2023-09-05 14:43:39,078:INFO:_master_model_container: 13
2023-09-05 14:43:39,078:INFO:_display_container: 3
2023-09-05 14:43:39,078:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-05 14:43:39,078:INFO:create_model() successfully completed......................................
2023-09-05 14:43:39,138:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:39,138:INFO:Creating metrics dataframe
2023-09-05 14:43:39,146:INFO:Initializing Decision Tree Regressor
2023-09-05 14:43:39,146:INFO:Total runtime is 0.06206663449605306 minutes
2023-09-05 14:43:39,149:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:39,149:INFO:Initializing create_model()
2023-09-05 14:43:39,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:39,149:INFO:Checking exceptions
2023-09-05 14:43:39,149:INFO:Importing libraries
2023-09-05 14:43:39,149:INFO:Copying training dataset
2023-09-05 14:43:39,153:INFO:Defining folds
2023-09-05 14:43:39,153:INFO:Declaring metric variables
2023-09-05 14:43:39,155:INFO:Importing untrained model
2023-09-05 14:43:39,157:INFO:Decision Tree Regressor Imported successfully
2023-09-05 14:43:39,160:INFO:Starting cross validation
2023-09-05 14:43:39,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:39,387:INFO:Calculating mean and std
2023-09-05 14:43:39,388:INFO:Creating metrics dataframe
2023-09-05 14:43:39,395:INFO:Uploading results into container
2023-09-05 14:43:39,395:INFO:Uploading model into container now
2023-09-05 14:43:39,396:INFO:_master_model_container: 14
2023-09-05 14:43:39,396:INFO:_display_container: 3
2023-09-05 14:43:39,396:INFO:DecisionTreeRegressor(random_state=5943)
2023-09-05 14:43:39,396:INFO:create_model() successfully completed......................................
2023-09-05 14:43:39,465:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:39,465:INFO:Creating metrics dataframe
2023-09-05 14:43:39,472:INFO:Initializing Random Forest Regressor
2023-09-05 14:43:39,472:INFO:Total runtime is 0.06750209331512451 minutes
2023-09-05 14:43:39,473:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:39,474:INFO:Initializing create_model()
2023-09-05 14:43:39,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:39,474:INFO:Checking exceptions
2023-09-05 14:43:39,474:INFO:Importing libraries
2023-09-05 14:43:39,474:INFO:Copying training dataset
2023-09-05 14:43:39,476:INFO:Defining folds
2023-09-05 14:43:39,476:INFO:Declaring metric variables
2023-09-05 14:43:39,478:INFO:Importing untrained model
2023-09-05 14:43:39,481:INFO:Random Forest Regressor Imported successfully
2023-09-05 14:43:39,487:INFO:Starting cross validation
2023-09-05 14:43:39,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:39,862:INFO:Calculating mean and std
2023-09-05 14:43:39,863:INFO:Creating metrics dataframe
2023-09-05 14:43:39,870:INFO:Uploading results into container
2023-09-05 14:43:39,871:INFO:Uploading model into container now
2023-09-05 14:43:39,871:INFO:_master_model_container: 15
2023-09-05 14:43:39,871:INFO:_display_container: 3
2023-09-05 14:43:39,871:INFO:RandomForestRegressor(n_jobs=-1, random_state=5943)
2023-09-05 14:43:39,871:INFO:create_model() successfully completed......................................
2023-09-05 14:43:39,940:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:39,940:INFO:Creating metrics dataframe
2023-09-05 14:43:39,947:INFO:Initializing Extra Trees Regressor
2023-09-05 14:43:39,947:INFO:Total runtime is 0.07541486024856567 minutes
2023-09-05 14:43:39,950:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:39,950:INFO:Initializing create_model()
2023-09-05 14:43:39,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:39,950:INFO:Checking exceptions
2023-09-05 14:43:39,950:INFO:Importing libraries
2023-09-05 14:43:39,950:INFO:Copying training dataset
2023-09-05 14:43:39,952:INFO:Defining folds
2023-09-05 14:43:39,952:INFO:Declaring metric variables
2023-09-05 14:43:39,954:INFO:Importing untrained model
2023-09-05 14:43:39,956:INFO:Extra Trees Regressor Imported successfully
2023-09-05 14:43:39,963:INFO:Starting cross validation
2023-09-05 14:43:39,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:40,650:INFO:Calculating mean and std
2023-09-05 14:43:40,651:INFO:Creating metrics dataframe
2023-09-05 14:43:40,663:INFO:Uploading results into container
2023-09-05 14:43:40,664:INFO:Uploading model into container now
2023-09-05 14:43:40,664:INFO:_master_model_container: 16
2023-09-05 14:43:40,664:INFO:_display_container: 3
2023-09-05 14:43:40,665:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5943)
2023-09-05 14:43:40,665:INFO:create_model() successfully completed......................................
2023-09-05 14:43:40,736:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:40,736:INFO:Creating metrics dataframe
2023-09-05 14:43:40,743:INFO:Initializing AdaBoost Regressor
2023-09-05 14:43:40,744:INFO:Total runtime is 0.08869647185007731 minutes
2023-09-05 14:43:40,746:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:40,747:INFO:Initializing create_model()
2023-09-05 14:43:40,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:40,747:INFO:Checking exceptions
2023-09-05 14:43:40,747:INFO:Importing libraries
2023-09-05 14:43:40,747:INFO:Copying training dataset
2023-09-05 14:43:40,749:INFO:Defining folds
2023-09-05 14:43:40,749:INFO:Declaring metric variables
2023-09-05 14:43:40,751:INFO:Importing untrained model
2023-09-05 14:43:40,753:INFO:AdaBoost Regressor Imported successfully
2023-09-05 14:43:40,758:INFO:Starting cross validation
2023-09-05 14:43:40,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:41,028:INFO:Calculating mean and std
2023-09-05 14:43:41,028:INFO:Creating metrics dataframe
2023-09-05 14:43:41,039:INFO:Uploading results into container
2023-09-05 14:43:41,040:INFO:Uploading model into container now
2023-09-05 14:43:41,040:INFO:_master_model_container: 17
2023-09-05 14:43:41,040:INFO:_display_container: 3
2023-09-05 14:43:41,040:INFO:AdaBoostRegressor(random_state=5943)
2023-09-05 14:43:41,040:INFO:create_model() successfully completed......................................
2023-09-05 14:43:41,103:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:41,103:INFO:Creating metrics dataframe
2023-09-05 14:43:41,111:INFO:Initializing Gradient Boosting Regressor
2023-09-05 14:43:41,111:INFO:Total runtime is 0.09481371641159057 minutes
2023-09-05 14:43:41,113:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:41,114:INFO:Initializing create_model()
2023-09-05 14:43:41,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:41,114:INFO:Checking exceptions
2023-09-05 14:43:41,114:INFO:Importing libraries
2023-09-05 14:43:41,114:INFO:Copying training dataset
2023-09-05 14:43:41,117:INFO:Defining folds
2023-09-05 14:43:41,117:INFO:Declaring metric variables
2023-09-05 14:43:41,119:INFO:Importing untrained model
2023-09-05 14:43:41,120:INFO:Gradient Boosting Regressor Imported successfully
2023-09-05 14:43:41,124:INFO:Starting cross validation
2023-09-05 14:43:41,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:41,628:INFO:Calculating mean and std
2023-09-05 14:43:41,629:INFO:Creating metrics dataframe
2023-09-05 14:43:41,645:INFO:Uploading results into container
2023-09-05 14:43:41,645:INFO:Uploading model into container now
2023-09-05 14:43:41,645:INFO:_master_model_container: 18
2023-09-05 14:43:41,645:INFO:_display_container: 3
2023-09-05 14:43:41,646:INFO:GradientBoostingRegressor(random_state=5943)
2023-09-05 14:43:41,646:INFO:create_model() successfully completed......................................
2023-09-05 14:43:41,710:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:41,710:INFO:Creating metrics dataframe
2023-09-05 14:43:41,717:INFO:Initializing Extreme Gradient Boosting
2023-09-05 14:43:41,718:INFO:Total runtime is 0.10493687391281127 minutes
2023-09-05 14:43:41,720:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:41,720:INFO:Initializing create_model()
2023-09-05 14:43:41,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:41,720:INFO:Checking exceptions
2023-09-05 14:43:41,720:INFO:Importing libraries
2023-09-05 14:43:41,720:INFO:Copying training dataset
2023-09-05 14:43:41,723:INFO:Defining folds
2023-09-05 14:43:41,723:INFO:Declaring metric variables
2023-09-05 14:43:41,728:INFO:Importing untrained model
2023-09-05 14:43:41,732:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 14:43:41,743:INFO:Starting cross validation
2023-09-05 14:43:41,744:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:42,182:INFO:Calculating mean and std
2023-09-05 14:43:42,182:INFO:Creating metrics dataframe
2023-09-05 14:43:42,204:INFO:Uploading results into container
2023-09-05 14:43:42,205:INFO:Uploading model into container now
2023-09-05 14:43:42,205:INFO:_master_model_container: 19
2023-09-05 14:43:42,206:INFO:_display_container: 3
2023-09-05 14:43:42,207:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5943, ...)
2023-09-05 14:43:42,207:INFO:create_model() successfully completed......................................
2023-09-05 14:43:42,274:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:42,274:INFO:Creating metrics dataframe
2023-09-05 14:43:42,283:INFO:Initializing Light Gradient Boosting Machine
2023-09-05 14:43:42,283:INFO:Total runtime is 0.11434504588445027 minutes
2023-09-05 14:43:42,285:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:42,285:INFO:Initializing create_model()
2023-09-05 14:43:42,285:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:42,285:INFO:Checking exceptions
2023-09-05 14:43:42,285:INFO:Importing libraries
2023-09-05 14:43:42,285:INFO:Copying training dataset
2023-09-05 14:43:42,288:INFO:Defining folds
2023-09-05 14:43:42,288:INFO:Declaring metric variables
2023-09-05 14:43:42,289:INFO:Importing untrained model
2023-09-05 14:43:42,291:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 14:43:42,295:INFO:Starting cross validation
2023-09-05 14:43:42,296:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:43,159:INFO:Calculating mean and std
2023-09-05 14:43:43,161:INFO:Creating metrics dataframe
2023-09-05 14:43:43,186:INFO:Uploading results into container
2023-09-05 14:43:43,186:INFO:Uploading model into container now
2023-09-05 14:43:43,187:INFO:_master_model_container: 20
2023-09-05 14:43:43,187:INFO:_display_container: 3
2023-09-05 14:43:43,187:INFO:LGBMRegressor(n_jobs=-1, random_state=5943)
2023-09-05 14:43:43,187:INFO:create_model() successfully completed......................................
2023-09-05 14:43:43,271:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:43,271:INFO:Creating metrics dataframe
2023-09-05 14:43:43,281:INFO:Initializing CatBoost Regressor
2023-09-05 14:43:43,281:INFO:Total runtime is 0.13098390499750773 minutes
2023-09-05 14:43:43,284:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:43,284:INFO:Initializing create_model()
2023-09-05 14:43:43,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:43,284:INFO:Checking exceptions
2023-09-05 14:43:43,284:INFO:Importing libraries
2023-09-05 14:43:43,284:INFO:Copying training dataset
2023-09-05 14:43:43,287:INFO:Defining folds
2023-09-05 14:43:43,287:INFO:Declaring metric variables
2023-09-05 14:43:43,289:INFO:Importing untrained model
2023-09-05 14:43:43,291:INFO:CatBoost Regressor Imported successfully
2023-09-05 14:43:43,295:INFO:Starting cross validation
2023-09-05 14:43:43,296:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:47,025:INFO:Calculating mean and std
2023-09-05 14:43:47,026:INFO:Creating metrics dataframe
2023-09-05 14:43:47,046:INFO:Uploading results into container
2023-09-05 14:43:47,047:INFO:Uploading model into container now
2023-09-05 14:43:47,047:INFO:_master_model_container: 21
2023-09-05 14:43:47,047:INFO:_display_container: 3
2023-09-05 14:43:47,047:INFO:<catboost.core.CatBoostRegressor object at 0x000001E934C3E0D0>
2023-09-05 14:43:47,047:INFO:create_model() successfully completed......................................
2023-09-05 14:43:47,110:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:47,110:INFO:Creating metrics dataframe
2023-09-05 14:43:47,118:INFO:Initializing Dummy Regressor
2023-09-05 14:43:47,118:INFO:Total runtime is 0.19492953618367515 minutes
2023-09-05 14:43:47,120:INFO:SubProcess create_model() called ==================================
2023-09-05 14:43:47,121:INFO:Initializing create_model()
2023-09-05 14:43:47,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9316929A0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:47,122:INFO:Checking exceptions
2023-09-05 14:43:47,122:INFO:Importing libraries
2023-09-05 14:43:47,122:INFO:Copying training dataset
2023-09-05 14:43:47,127:INFO:Defining folds
2023-09-05 14:43:47,127:INFO:Declaring metric variables
2023-09-05 14:43:47,130:INFO:Importing untrained model
2023-09-05 14:43:47,133:INFO:Dummy Regressor Imported successfully
2023-09-05 14:43:47,138:INFO:Starting cross validation
2023-09-05 14:43:47,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:47,438:INFO:Calculating mean and std
2023-09-05 14:43:47,439:INFO:Creating metrics dataframe
2023-09-05 14:43:47,458:INFO:Uploading results into container
2023-09-05 14:43:47,458:INFO:Uploading model into container now
2023-09-05 14:43:47,459:INFO:_master_model_container: 22
2023-09-05 14:43:47,459:INFO:_display_container: 3
2023-09-05 14:43:47,459:INFO:DummyRegressor()
2023-09-05 14:43:47,459:INFO:create_model() successfully completed......................................
2023-09-05 14:43:47,523:INFO:SubProcess create_model() end ==================================
2023-09-05 14:43:47,523:INFO:Creating metrics dataframe
2023-09-05 14:43:47,537:INFO:Initializing create_model()
2023-09-05 14:43:47,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=GradientBoostingRegressor(random_state=5943), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:47,537:INFO:Checking exceptions
2023-09-05 14:43:47,539:INFO:Importing libraries
2023-09-05 14:43:47,539:INFO:Copying training dataset
2023-09-05 14:43:47,541:INFO:Defining folds
2023-09-05 14:43:47,541:INFO:Declaring metric variables
2023-09-05 14:43:47,541:INFO:Importing untrained model
2023-09-05 14:43:47,541:INFO:Declaring custom model
2023-09-05 14:43:47,542:INFO:Gradient Boosting Regressor Imported successfully
2023-09-05 14:43:47,543:INFO:Cross validation set to False
2023-09-05 14:43:47,543:INFO:Fitting Model
2023-09-05 14:43:47,683:INFO:GradientBoostingRegressor(random_state=5943)
2023-09-05 14:43:47,684:INFO:create_model() successfully completed......................................
2023-09-05 14:43:47,756:INFO:Initializing create_model()
2023-09-05 14:43:47,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=<catboost.core.CatBoostRegressor object at 0x000001E934C3E0D0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:47,756:INFO:Checking exceptions
2023-09-05 14:43:47,758:INFO:Importing libraries
2023-09-05 14:43:47,758:INFO:Copying training dataset
2023-09-05 14:43:47,761:INFO:Defining folds
2023-09-05 14:43:47,761:INFO:Declaring metric variables
2023-09-05 14:43:47,761:INFO:Importing untrained model
2023-09-05 14:43:47,761:INFO:Declaring custom model
2023-09-05 14:43:47,761:INFO:CatBoost Regressor Imported successfully
2023-09-05 14:43:47,762:INFO:Cross validation set to False
2023-09-05 14:43:47,762:INFO:Fitting Model
2023-09-05 14:43:48,944:INFO:<catboost.core.CatBoostRegressor object at 0x000001E934B84280>
2023-09-05 14:43:48,944:INFO:create_model() successfully completed......................................
2023-09-05 14:43:49,025:INFO:_master_model_container: 22
2023-09-05 14:43:49,025:INFO:_display_container: 3
2023-09-05 14:43:49,025:INFO:[GradientBoostingRegressor(random_state=5943), <catboost.core.CatBoostRegressor object at 0x000001E934B84280>]
2023-09-05 14:43:49,025:INFO:compare_models() successfully completed......................................
2023-09-05 14:43:49,054:INFO:Initializing create_model()
2023-09-05 14:43:49,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'max_depth': 5})
2023-09-05 14:43:49,055:INFO:Checking exceptions
2023-09-05 14:43:49,069:INFO:Importing libraries
2023-09-05 14:43:49,069:INFO:Copying training dataset
2023-09-05 14:43:49,073:INFO:Defining folds
2023-09-05 14:43:49,073:INFO:Declaring metric variables
2023-09-05 14:43:49,075:INFO:Importing untrained model
2023-09-05 14:43:49,078:INFO:Decision Tree Regressor Imported successfully
2023-09-05 14:43:49,081:INFO:Starting cross validation
2023-09-05 14:43:49,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:49,386:INFO:Calculating mean and std
2023-09-05 14:43:49,386:INFO:Creating metrics dataframe
2023-09-05 14:43:49,390:INFO:Finalizing model
2023-09-05 14:43:49,469:INFO:Uploading results into container
2023-09-05 14:43:49,469:INFO:Uploading model into container now
2023-09-05 14:43:49,476:INFO:_master_model_container: 23
2023-09-05 14:43:49,476:INFO:_display_container: 4
2023-09-05 14:43:49,477:INFO:DecisionTreeRegressor(max_depth=5, random_state=5943)
2023-09-05 14:43:49,477:INFO:create_model() successfully completed......................................
2023-09-05 14:43:49,648:INFO:Initializing create_model()
2023-09-05 14:43:49,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:49,648:INFO:Checking exceptions
2023-09-05 14:43:49,649:INFO:Importing libraries
2023-09-05 14:43:49,649:INFO:Copying training dataset
2023-09-05 14:43:49,651:INFO:Defining folds
2023-09-05 14:43:49,651:INFO:Declaring metric variables
2023-09-05 14:43:49,651:INFO:Importing untrained model
2023-09-05 14:43:49,651:INFO:Declaring custom model
2023-09-05 14:43:49,652:INFO:Linear Regression Imported successfully
2023-09-05 14:43:49,652:INFO:Starting cross validation
2023-09-05 14:43:49,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:49,826:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:49,826:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:49,826:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:49,828:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:49,846:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:49,850:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:49,850:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:49,850:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:49,850:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:49,850:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:49,861:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:49,862:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:49,865:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:49,866:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:49,868:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:49,871:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:49,873:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:49,875:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:49,880:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:49,883:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,004:INFO:Calculating mean and std
2023-09-05 14:43:50,004:INFO:Creating metrics dataframe
2023-09-05 14:43:50,005:INFO:Finalizing model
2023-09-05 14:43:50,069:INFO:Uploading results into container
2023-09-05 14:43:50,070:INFO:_master_model_container: 23
2023-09-05 14:43:50,070:INFO:_display_container: 5
2023-09-05 14:43:50,070:INFO:LinearRegression(n_jobs=-1)
2023-09-05 14:43:50,070:INFO:create_model() successfully completed......................................
2023-09-05 14:43:50,133:INFO:Initializing create_model()
2023-09-05 14:43:50,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:50,133:INFO:Checking exceptions
2023-09-05 14:43:50,134:INFO:Importing libraries
2023-09-05 14:43:50,134:INFO:Copying training dataset
2023-09-05 14:43:50,136:INFO:Defining folds
2023-09-05 14:43:50,136:INFO:Declaring metric variables
2023-09-05 14:43:50,136:INFO:Importing untrained model
2023-09-05 14:43:50,136:INFO:Declaring custom model
2023-09-05 14:43:50,137:INFO:Random Forest Regressor Imported successfully
2023-09-05 14:43:50,137:INFO:Starting cross validation
2023-09-05 14:43:50,137:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:50,389:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,389:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,395:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,395:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,404:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,407:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,434:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,435:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,435:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,435:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,437:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,438:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,466:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,466:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,467:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,469:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,496:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,497:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,512:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,513:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,573:INFO:Calculating mean and std
2023-09-05 14:43:50,573:INFO:Creating metrics dataframe
2023-09-05 14:43:50,574:INFO:Finalizing model
2023-09-05 14:43:50,663:INFO:Uploading results into container
2023-09-05 14:43:50,663:INFO:_master_model_container: 23
2023-09-05 14:43:50,664:INFO:_display_container: 6
2023-09-05 14:43:50,664:INFO:RandomForestRegressor(n_jobs=-1, random_state=5943)
2023-09-05 14:43:50,664:INFO:create_model() successfully completed......................................
2023-09-05 14:43:50,731:INFO:Initializing create_model()
2023-09-05 14:43:50,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:50,731:INFO:Checking exceptions
2023-09-05 14:43:50,732:INFO:Importing libraries
2023-09-05 14:43:50,732:INFO:Copying training dataset
2023-09-05 14:43:50,735:INFO:Defining folds
2023-09-05 14:43:50,735:INFO:Declaring metric variables
2023-09-05 14:43:50,735:INFO:Importing untrained model
2023-09-05 14:43:50,736:INFO:Declaring custom model
2023-09-05 14:43:50,736:INFO:Linear Regression Imported successfully
2023-09-05 14:43:50,736:INFO:Starting cross validation
2023-09-05 14:43:50,736:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:50,891:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,892:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,904:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,906:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,911:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,914:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,917:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,920:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,925:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,927:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,932:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,934:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,942:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,943:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,948:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,950:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,950:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,951:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:50,960:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:50,961:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,050:INFO:Calculating mean and std
2023-09-05 14:43:51,050:INFO:Creating metrics dataframe
2023-09-05 14:43:51,051:INFO:Finalizing model
2023-09-05 14:43:51,114:INFO:Uploading results into container
2023-09-05 14:43:51,115:INFO:_master_model_container: 23
2023-09-05 14:43:51,115:INFO:_display_container: 7
2023-09-05 14:43:51,115:INFO:LinearRegression(n_jobs=-1)
2023-09-05 14:43:51,115:INFO:create_model() successfully completed......................................
2023-09-05 14:43:51,180:INFO:Initializing create_model()
2023-09-05 14:43:51,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=Lasso(random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:51,180:INFO:Checking exceptions
2023-09-05 14:43:51,182:INFO:Importing libraries
2023-09-05 14:43:51,182:INFO:Copying training dataset
2023-09-05 14:43:51,184:INFO:Defining folds
2023-09-05 14:43:51,185:INFO:Declaring metric variables
2023-09-05 14:43:51,185:INFO:Importing untrained model
2023-09-05 14:43:51,185:INFO:Declaring custom model
2023-09-05 14:43:51,185:INFO:Lasso Regression Imported successfully
2023-09-05 14:43:51,185:INFO:Starting cross validation
2023-09-05 14:43:51,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:51,338:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,340:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,340:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,342:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,356:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,358:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,364:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,367:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,373:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,374:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,374:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,375:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,388:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,389:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,390:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,390:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,392:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,393:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,397:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,398:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,495:INFO:Calculating mean and std
2023-09-05 14:43:51,495:INFO:Creating metrics dataframe
2023-09-05 14:43:51,497:INFO:Finalizing model
2023-09-05 14:43:51,563:INFO:Uploading results into container
2023-09-05 14:43:51,564:INFO:_master_model_container: 23
2023-09-05 14:43:51,564:INFO:_display_container: 8
2023-09-05 14:43:51,564:INFO:Lasso(random_state=5943)
2023-09-05 14:43:51,564:INFO:create_model() successfully completed......................................
2023-09-05 14:43:51,628:INFO:Initializing create_model()
2023-09-05 14:43:51,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=Ridge(random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:51,628:INFO:Checking exceptions
2023-09-05 14:43:51,629:INFO:Importing libraries
2023-09-05 14:43:51,629:INFO:Copying training dataset
2023-09-05 14:43:51,631:INFO:Defining folds
2023-09-05 14:43:51,631:INFO:Declaring metric variables
2023-09-05 14:43:51,631:INFO:Importing untrained model
2023-09-05 14:43:51,631:INFO:Declaring custom model
2023-09-05 14:43:51,632:INFO:Ridge Regression Imported successfully
2023-09-05 14:43:51,632:INFO:Starting cross validation
2023-09-05 14:43:51,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:51,790:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,792:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,796:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,799:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,800:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,800:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,802:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,803:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,812:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,813:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,821:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,821:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,823:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,823:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,832:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,834:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,842:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,843:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,858:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:51,859:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:51,938:INFO:Calculating mean and std
2023-09-05 14:43:51,938:INFO:Creating metrics dataframe
2023-09-05 14:43:51,940:INFO:Finalizing model
2023-09-05 14:43:52,013:INFO:Uploading results into container
2023-09-05 14:43:52,014:INFO:_master_model_container: 23
2023-09-05 14:43:52,014:INFO:_display_container: 9
2023-09-05 14:43:52,014:INFO:Ridge(random_state=5943)
2023-09-05 14:43:52,014:INFO:create_model() successfully completed......................................
2023-09-05 14:43:52,080:INFO:Initializing create_model()
2023-09-05 14:43:52,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=ElasticNet(random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:52,080:INFO:Checking exceptions
2023-09-05 14:43:52,082:INFO:Importing libraries
2023-09-05 14:43:52,082:INFO:Copying training dataset
2023-09-05 14:43:52,084:INFO:Defining folds
2023-09-05 14:43:52,084:INFO:Declaring metric variables
2023-09-05 14:43:52,084:INFO:Importing untrained model
2023-09-05 14:43:52,084:INFO:Declaring custom model
2023-09-05 14:43:52,084:INFO:Elastic Net Imported successfully
2023-09-05 14:43:52,085:INFO:Starting cross validation
2023-09-05 14:43:52,085:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:52,228:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,230:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,245:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,248:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,256:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,258:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,258:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,261:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,270:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,271:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,272:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,273:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,281:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,283:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,292:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,294:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,297:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,298:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,301:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,302:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,383:INFO:Calculating mean and std
2023-09-05 14:43:52,383:INFO:Creating metrics dataframe
2023-09-05 14:43:52,384:INFO:Finalizing model
2023-09-05 14:43:52,456:INFO:Uploading results into container
2023-09-05 14:43:52,457:INFO:_master_model_container: 23
2023-09-05 14:43:52,457:INFO:_display_container: 10
2023-09-05 14:43:52,457:INFO:ElasticNet(random_state=5943)
2023-09-05 14:43:52,457:INFO:create_model() successfully completed......................................
2023-09-05 14:43:52,524:INFO:Initializing create_model()
2023-09-05 14:43:52,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=Lars(random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:52,524:INFO:Checking exceptions
2023-09-05 14:43:52,525:INFO:Importing libraries
2023-09-05 14:43:52,525:INFO:Copying training dataset
2023-09-05 14:43:52,528:INFO:Defining folds
2023-09-05 14:43:52,528:INFO:Declaring metric variables
2023-09-05 14:43:52,528:INFO:Importing untrained model
2023-09-05 14:43:52,528:INFO:Declaring custom model
2023-09-05 14:43:52,528:INFO:Least Angle Regression Imported successfully
2023-09-05 14:43:52,528:INFO:Starting cross validation
2023-09-05 14:43:52,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:52,693:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,696:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,703:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,704:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,705:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,707:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,707:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,709:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,709:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,710:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,716:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,718:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,721:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,723:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,728:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,729:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,729:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,731:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,743:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:52,745:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:52,841:INFO:Calculating mean and std
2023-09-05 14:43:52,841:INFO:Creating metrics dataframe
2023-09-05 14:43:52,842:INFO:Finalizing model
2023-09-05 14:43:52,912:INFO:Uploading results into container
2023-09-05 14:43:52,912:INFO:_master_model_container: 23
2023-09-05 14:43:52,912:INFO:_display_container: 11
2023-09-05 14:43:52,912:INFO:Lars(random_state=5943)
2023-09-05 14:43:52,912:INFO:create_model() successfully completed......................................
2023-09-05 14:43:52,980:INFO:Initializing create_model()
2023-09-05 14:43:52,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=LassoLars(random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:52,981:INFO:Checking exceptions
2023-09-05 14:43:52,982:INFO:Importing libraries
2023-09-05 14:43:52,982:INFO:Copying training dataset
2023-09-05 14:43:52,987:INFO:Defining folds
2023-09-05 14:43:52,987:INFO:Declaring metric variables
2023-09-05 14:43:52,987:INFO:Importing untrained model
2023-09-05 14:43:52,987:INFO:Declaring custom model
2023-09-05 14:43:52,988:INFO:Lasso Least Angle Regression Imported successfully
2023-09-05 14:43:52,988:INFO:Starting cross validation
2023-09-05 14:43:52,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:53,142:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,144:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,162:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,164:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,164:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,166:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,169:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,172:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,172:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,173:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,174:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,177:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,179:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,181:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,201:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,203:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,205:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,206:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,207:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,208:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,298:INFO:Calculating mean and std
2023-09-05 14:43:53,298:INFO:Creating metrics dataframe
2023-09-05 14:43:53,299:INFO:Finalizing model
2023-09-05 14:43:53,371:INFO:Uploading results into container
2023-09-05 14:43:53,372:INFO:_master_model_container: 23
2023-09-05 14:43:53,372:INFO:_display_container: 12
2023-09-05 14:43:53,372:INFO:LassoLars(random_state=5943)
2023-09-05 14:43:53,372:INFO:create_model() successfully completed......................................
2023-09-05 14:43:53,437:INFO:Initializing create_model()
2023-09-05 14:43:53,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=OrthogonalMatchingPursuit(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:53,437:INFO:Checking exceptions
2023-09-05 14:43:53,438:INFO:Importing libraries
2023-09-05 14:43:53,438:INFO:Copying training dataset
2023-09-05 14:43:53,441:INFO:Defining folds
2023-09-05 14:43:53,441:INFO:Declaring metric variables
2023-09-05 14:43:53,441:INFO:Importing untrained model
2023-09-05 14:43:53,441:INFO:Declaring custom model
2023-09-05 14:43:53,441:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-05 14:43:53,441:INFO:Starting cross validation
2023-09-05 14:43:53,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:53,601:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,603:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,607:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,610:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,612:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,613:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,616:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,618:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,640:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,641:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,642:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,643:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,646:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,648:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,652:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,653:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,653:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,654:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,656:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:53,657:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:53,759:INFO:Calculating mean and std
2023-09-05 14:43:53,759:INFO:Creating metrics dataframe
2023-09-05 14:43:53,761:INFO:Finalizing model
2023-09-05 14:43:53,830:INFO:Uploading results into container
2023-09-05 14:43:53,831:INFO:_master_model_container: 23
2023-09-05 14:43:53,831:INFO:_display_container: 13
2023-09-05 14:43:53,831:INFO:OrthogonalMatchingPursuit()
2023-09-05 14:43:53,831:INFO:create_model() successfully completed......................................
2023-09-05 14:43:53,894:INFO:Initializing create_model()
2023-09-05 14:43:53,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=BayesianRidge(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:53,894:INFO:Checking exceptions
2023-09-05 14:43:53,896:INFO:Importing libraries
2023-09-05 14:43:53,896:INFO:Copying training dataset
2023-09-05 14:43:53,898:INFO:Defining folds
2023-09-05 14:43:53,898:INFO:Declaring metric variables
2023-09-05 14:43:53,898:INFO:Importing untrained model
2023-09-05 14:43:53,898:INFO:Declaring custom model
2023-09-05 14:43:53,898:INFO:Bayesian Ridge Imported successfully
2023-09-05 14:43:53,898:INFO:Starting cross validation
2023-09-05 14:43:53,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:54,058:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,060:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,060:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,061:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,062:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,063:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,070:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,072:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,086:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,088:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,088:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,089:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,089:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,091:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,105:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,106:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,107:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,108:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,109:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,110:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,206:INFO:Calculating mean and std
2023-09-05 14:43:54,207:INFO:Creating metrics dataframe
2023-09-05 14:43:54,208:INFO:Finalizing model
2023-09-05 14:43:54,283:INFO:Uploading results into container
2023-09-05 14:43:54,283:INFO:_master_model_container: 23
2023-09-05 14:43:54,283:INFO:_display_container: 14
2023-09-05 14:43:54,283:INFO:BayesianRidge()
2023-09-05 14:43:54,283:INFO:create_model() successfully completed......................................
2023-09-05 14:43:54,353:INFO:Initializing create_model()
2023-09-05 14:43:54,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=PassiveAggressiveRegressor(random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:54,354:INFO:Checking exceptions
2023-09-05 14:43:54,356:INFO:Importing libraries
2023-09-05 14:43:54,356:INFO:Copying training dataset
2023-09-05 14:43:54,358:INFO:Defining folds
2023-09-05 14:43:54,358:INFO:Declaring metric variables
2023-09-05 14:43:54,358:INFO:Importing untrained model
2023-09-05 14:43:54,358:INFO:Declaring custom model
2023-09-05 14:43:54,358:INFO:Passive Aggressive Regressor Imported successfully
2023-09-05 14:43:54,359:INFO:Starting cross validation
2023-09-05 14:43:54,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:54,521:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,522:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,522:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,523:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,523:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,524:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,541:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,543:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,547:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,549:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,549:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,551:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,556:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,560:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,566:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,567:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,578:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,579:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,582:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,583:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,664:INFO:Calculating mean and std
2023-09-05 14:43:54,664:INFO:Creating metrics dataframe
2023-09-05 14:43:54,665:INFO:Finalizing model
2023-09-05 14:43:54,740:INFO:Uploading results into container
2023-09-05 14:43:54,741:INFO:_master_model_container: 23
2023-09-05 14:43:54,741:INFO:_display_container: 15
2023-09-05 14:43:54,741:INFO:PassiveAggressiveRegressor(random_state=5943)
2023-09-05 14:43:54,741:INFO:create_model() successfully completed......................................
2023-09-05 14:43:54,809:INFO:Initializing create_model()
2023-09-05 14:43:54,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=HuberRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:54,809:INFO:Checking exceptions
2023-09-05 14:43:54,810:INFO:Importing libraries
2023-09-05 14:43:54,810:INFO:Copying training dataset
2023-09-05 14:43:54,812:INFO:Defining folds
2023-09-05 14:43:54,813:INFO:Declaring metric variables
2023-09-05 14:43:54,813:INFO:Importing untrained model
2023-09-05 14:43:54,813:INFO:Declaring custom model
2023-09-05 14:43:54,813:INFO:Huber Regressor Imported successfully
2023-09-05 14:43:54,813:INFO:Starting cross validation
2023-09-05 14:43:54,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:54,955:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:54,970:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:54,975:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:54,975:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:54,976:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:54,979:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:54,981:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:54,986:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:55,003:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:55,015:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,017:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,024:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,025:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,030:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,033:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,033:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,037:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,042:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,044:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,045:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,047:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,047:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,049:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,053:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,055:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,055:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,056:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,158:INFO:Calculating mean and std
2023-09-05 14:43:55,158:INFO:Creating metrics dataframe
2023-09-05 14:43:55,159:INFO:Finalizing model
2023-09-05 14:43:55,226:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 14:43:55,240:INFO:Uploading results into container
2023-09-05 14:43:55,240:INFO:_master_model_container: 23
2023-09-05 14:43:55,240:INFO:_display_container: 16
2023-09-05 14:43:55,240:INFO:HuberRegressor()
2023-09-05 14:43:55,240:INFO:create_model() successfully completed......................................
2023-09-05 14:43:55,307:INFO:Initializing create_model()
2023-09-05 14:43:55,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:55,307:INFO:Checking exceptions
2023-09-05 14:43:55,308:INFO:Importing libraries
2023-09-05 14:43:55,308:INFO:Copying training dataset
2023-09-05 14:43:55,311:INFO:Defining folds
2023-09-05 14:43:55,311:INFO:Declaring metric variables
2023-09-05 14:43:55,311:INFO:Importing untrained model
2023-09-05 14:43:55,311:INFO:Declaring custom model
2023-09-05 14:43:55,311:INFO:K Neighbors Regressor Imported successfully
2023-09-05 14:43:55,312:INFO:Starting cross validation
2023-09-05 14:43:55,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:55,491:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,493:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,506:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,508:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,523:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,523:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,524:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,524:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,524:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,526:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,526:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,526:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,537:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,538:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,539:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,539:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,567:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,568:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,645:INFO:Calculating mean and std
2023-09-05 14:43:55,645:INFO:Creating metrics dataframe
2023-09-05 14:43:55,646:INFO:Finalizing model
2023-09-05 14:43:55,717:INFO:Uploading results into container
2023-09-05 14:43:55,718:INFO:_master_model_container: 23
2023-09-05 14:43:55,718:INFO:_display_container: 17
2023-09-05 14:43:55,718:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-05 14:43:55,718:INFO:create_model() successfully completed......................................
2023-09-05 14:43:55,785:INFO:Initializing create_model()
2023-09-05 14:43:55,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=DecisionTreeRegressor(random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:55,785:INFO:Checking exceptions
2023-09-05 14:43:55,787:INFO:Importing libraries
2023-09-05 14:43:55,787:INFO:Copying training dataset
2023-09-05 14:43:55,789:INFO:Defining folds
2023-09-05 14:43:55,790:INFO:Declaring metric variables
2023-09-05 14:43:55,790:INFO:Importing untrained model
2023-09-05 14:43:55,790:INFO:Declaring custom model
2023-09-05 14:43:55,790:INFO:Decision Tree Regressor Imported successfully
2023-09-05 14:43:55,790:INFO:Starting cross validation
2023-09-05 14:43:55,791:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:55,945:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,946:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,947:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,949:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,955:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,956:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,961:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,963:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,978:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,980:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,981:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,982:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,991:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,992:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,993:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,994:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:55,995:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:55,997:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,013:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:56,015:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,106:INFO:Calculating mean and std
2023-09-05 14:43:56,106:INFO:Creating metrics dataframe
2023-09-05 14:43:56,108:INFO:Finalizing model
2023-09-05 14:43:56,176:INFO:Uploading results into container
2023-09-05 14:43:56,176:INFO:_master_model_container: 23
2023-09-05 14:43:56,176:INFO:_display_container: 18
2023-09-05 14:43:56,177:INFO:DecisionTreeRegressor(random_state=5943)
2023-09-05 14:43:56,177:INFO:create_model() successfully completed......................................
2023-09-05 14:43:56,246:INFO:Initializing create_model()
2023-09-05 14:43:56,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:56,246:INFO:Checking exceptions
2023-09-05 14:43:56,248:INFO:Importing libraries
2023-09-05 14:43:56,248:INFO:Copying training dataset
2023-09-05 14:43:56,250:INFO:Defining folds
2023-09-05 14:43:56,250:INFO:Declaring metric variables
2023-09-05 14:43:56,250:INFO:Importing untrained model
2023-09-05 14:43:56,250:INFO:Declaring custom model
2023-09-05 14:43:56,251:INFO:Random Forest Regressor Imported successfully
2023-09-05 14:43:56,251:INFO:Starting cross validation
2023-09-05 14:43:56,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:56,500:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:56,502:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,518:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:56,520:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,532:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:56,533:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:56,533:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:56,533:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:56,534:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,534:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,535:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,535:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,564:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:56,564:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:56,565:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,565:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,579:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:56,580:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,611:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:56,612:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:56,672:INFO:Calculating mean and std
2023-09-05 14:43:56,672:INFO:Creating metrics dataframe
2023-09-05 14:43:56,674:INFO:Finalizing model
2023-09-05 14:43:56,760:INFO:Uploading results into container
2023-09-05 14:43:56,761:INFO:_master_model_container: 23
2023-09-05 14:43:56,761:INFO:_display_container: 19
2023-09-05 14:43:56,761:INFO:RandomForestRegressor(n_jobs=-1, random_state=5943)
2023-09-05 14:43:56,761:INFO:create_model() successfully completed......................................
2023-09-05 14:43:56,824:INFO:Initializing create_model()
2023-09-05 14:43:56,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:56,824:INFO:Checking exceptions
2023-09-05 14:43:56,825:INFO:Importing libraries
2023-09-05 14:43:56,825:INFO:Copying training dataset
2023-09-05 14:43:56,828:INFO:Defining folds
2023-09-05 14:43:56,828:INFO:Declaring metric variables
2023-09-05 14:43:56,828:INFO:Importing untrained model
2023-09-05 14:43:56,828:INFO:Declaring custom model
2023-09-05 14:43:56,829:INFO:Extra Trees Regressor Imported successfully
2023-09-05 14:43:56,829:INFO:Starting cross validation
2023-09-05 14:43:56,830:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:57,105:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,107:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,122:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,123:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,126:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,126:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,152:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,152:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,153:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,153:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,167:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,168:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,168:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,169:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,170:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,182:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,184:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,197:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,198:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,275:INFO:Calculating mean and std
2023-09-05 14:43:57,275:INFO:Creating metrics dataframe
2023-09-05 14:43:57,277:INFO:Finalizing model
2023-09-05 14:43:57,433:INFO:Uploading results into container
2023-09-05 14:43:57,434:INFO:_master_model_container: 23
2023-09-05 14:43:57,434:INFO:_display_container: 20
2023-09-05 14:43:57,434:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5943)
2023-09-05 14:43:57,434:INFO:create_model() successfully completed......................................
2023-09-05 14:43:57,498:INFO:Initializing create_model()
2023-09-05 14:43:57,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=AdaBoostRegressor(random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:57,498:INFO:Checking exceptions
2023-09-05 14:43:57,500:INFO:Importing libraries
2023-09-05 14:43:57,500:INFO:Copying training dataset
2023-09-05 14:43:57,502:INFO:Defining folds
2023-09-05 14:43:57,502:INFO:Declaring metric variables
2023-09-05 14:43:57,502:INFO:Importing untrained model
2023-09-05 14:43:57,502:INFO:Declaring custom model
2023-09-05 14:43:57,502:INFO:AdaBoost Regressor Imported successfully
2023-09-05 14:43:57,502:INFO:Starting cross validation
2023-09-05 14:43:57,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:57,684:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,686:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,687:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,689:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,696:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,698:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,712:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,715:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,716:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,717:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,718:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,719:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,726:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,728:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,733:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,734:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,739:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:57,741:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,741:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:57,845:INFO:Calculating mean and std
2023-09-05 14:43:57,845:INFO:Creating metrics dataframe
2023-09-05 14:43:57,847:INFO:Finalizing model
2023-09-05 14:43:57,925:INFO:Uploading results into container
2023-09-05 14:43:57,926:INFO:_master_model_container: 23
2023-09-05 14:43:57,926:INFO:_display_container: 21
2023-09-05 14:43:57,926:INFO:AdaBoostRegressor(random_state=5943)
2023-09-05 14:43:57,926:INFO:create_model() successfully completed......................................
2023-09-05 14:43:57,989:INFO:Initializing create_model()
2023-09-05 14:43:57,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=GradientBoostingRegressor(random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:57,989:INFO:Checking exceptions
2023-09-05 14:43:57,991:INFO:Importing libraries
2023-09-05 14:43:57,991:INFO:Copying training dataset
2023-09-05 14:43:57,994:INFO:Defining folds
2023-09-05 14:43:57,994:INFO:Declaring metric variables
2023-09-05 14:43:57,995:INFO:Importing untrained model
2023-09-05 14:43:57,995:INFO:Declaring custom model
2023-09-05 14:43:57,995:INFO:Gradient Boosting Regressor Imported successfully
2023-09-05 14:43:57,995:INFO:Starting cross validation
2023-09-05 14:43:57,996:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:58,221:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,223:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,223:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,224:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,229:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,229:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,230:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,231:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,233:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,235:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,235:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,237:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,240:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,241:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,243:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

abels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,244:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,244:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,245:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,247:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,367:INFO:Calculating mean and std
2023-09-05 14:43:58,367:INFO:Creating metrics dataframe
2023-09-05 14:43:58,368:INFO:Finalizing model
2023-09-05 14:43:58,502:INFO:Uploading results into container
2023-09-05 14:43:58,502:INFO:_master_model_container: 23
2023-09-05 14:43:58,502:INFO:_display_container: 22
2023-09-05 14:43:58,502:INFO:GradientBoostingRegressor(random_state=5943)
2023-09-05 14:43:58,502:INFO:create_model() successfully completed......................................
2023-09-05 14:43:58,571:INFO:Initializing create_model()
2023-09-05 14:43:58,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5943, ...), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:58,571:INFO:Checking exceptions
2023-09-05 14:43:58,572:INFO:Importing libraries
2023-09-05 14:43:58,572:INFO:Copying training dataset
2023-09-05 14:43:58,575:INFO:Defining folds
2023-09-05 14:43:58,575:INFO:Declaring metric variables
2023-09-05 14:43:58,575:INFO:Importing untrained model
2023-09-05 14:43:58,575:INFO:Declaring custom model
2023-09-05 14:43:58,576:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 14:43:58,576:INFO:Starting cross validation
2023-09-05 14:43:58,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:58,810:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,812:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,819:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,832:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,908:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,910:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:58,936:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:58,937:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,097:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,100:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,102:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,110:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,116:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,118:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,126:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,132:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,133:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,138:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,141:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,145:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,224:INFO:Calculating mean and std
2023-09-05 14:43:59,224:INFO:Creating metrics dataframe
2023-09-05 14:43:59,226:INFO:Finalizing model
2023-09-05 14:43:59,363:INFO:Uploading results into container
2023-09-05 14:43:59,364:INFO:_master_model_container: 23
2023-09-05 14:43:59,364:INFO:_display_container: 23
2023-09-05 14:43:59,365:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5943, ...)
2023-09-05 14:43:59,365:INFO:create_model() successfully completed......................................
2023-09-05 14:43:59,448:INFO:Initializing create_model()
2023-09-05 14:43:59,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=5943), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:43:59,448:INFO:Checking exceptions
2023-09-05 14:43:59,450:INFO:Importing libraries
2023-09-05 14:43:59,450:INFO:Copying training dataset
2023-09-05 14:43:59,452:INFO:Defining folds
2023-09-05 14:43:59,452:INFO:Declaring metric variables
2023-09-05 14:43:59,452:INFO:Importing untrained model
2023-09-05 14:43:59,452:INFO:Declaring custom model
2023-09-05 14:43:59,452:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 14:43:59,453:INFO:Starting cross validation
2023-09-05 14:43:59,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:43:59,682:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,711:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,724:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,742:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,754:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,764:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,765:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,766:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,767:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,772:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,775:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,778:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,789:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,792:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,800:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,813:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,818:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,827:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:43:59,829:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,855:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:43:59,936:INFO:Calculating mean and std
2023-09-05 14:43:59,936:INFO:Creating metrics dataframe
2023-09-05 14:43:59,938:INFO:Finalizing model
2023-09-05 14:43:59,994:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.
2023-09-05 14:43:59,994:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-09-05 14:43:59,995:INFO:[LightGBM] [Info] Total Bins 321
2023-09-05 14:43:59,995:INFO:[LightGBM] [Info] Number of data points in the train set: 936, number of used features: 9
2023-09-05 14:43:59,995:INFO:[LightGBM] [Info] Start training from score 13370.036527
2023-09-05 14:44:00,055:INFO:Uploading results into container
2023-09-05 14:44:00,056:INFO:_master_model_container: 23
2023-09-05 14:44:00,056:INFO:_display_container: 24
2023-09-05 14:44:00,056:INFO:LGBMRegressor(n_jobs=-1, random_state=5943)
2023-09-05 14:44:00,056:INFO:create_model() successfully completed......................................
2023-09-05 14:44:00,141:INFO:Initializing create_model()
2023-09-05 14:44:00,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=<catboost.core.CatBoostRegressor object at 0x000001E9346B8F40>, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:44:00,141:INFO:Checking exceptions
2023-09-05 14:44:00,142:INFO:Importing libraries
2023-09-05 14:44:00,142:INFO:Copying training dataset
2023-09-05 14:44:00,145:INFO:Defining folds
2023-09-05 14:44:00,145:INFO:Declaring metric variables
2023-09-05 14:44:00,145:INFO:Importing untrained model
2023-09-05 14:44:00,145:INFO:Declaring custom model
2023-09-05 14:44:00,146:INFO:CatBoost Regressor Imported successfully
2023-09-05 14:44:00,146:INFO:Starting cross validation
2023-09-05 14:44:00,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:44:00,321:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:00,325:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:00,370:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:00,372:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:00,376:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:00,378:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:00,388:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:00,390:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:00,706:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:00,706:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:00,708:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:00,708:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:00,710:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:00,714:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:00,723:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:00,725:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:00,731:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:00,732:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:00,745:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:00,746:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:00,809:INFO:Calculating mean and std
2023-09-05 14:44:00,809:INFO:Creating metrics dataframe
2023-09-05 14:44:00,811:INFO:Finalizing model
2023-09-05 14:44:00,882:INFO:Uploading results into container
2023-09-05 14:44:00,882:INFO:_master_model_container: 23
2023-09-05 14:44:00,882:INFO:_display_container: 25
2023-09-05 14:44:00,883:INFO:<catboost.core.CatBoostRegressor object at 0x000001E93506EAC0>
2023-09-05 14:44:00,883:INFO:create_model() successfully completed......................................
2023-09-05 14:44:00,948:INFO:Initializing create_model()
2023-09-05 14:44:00,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=DummyRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:44:00,948:INFO:Checking exceptions
2023-09-05 14:44:00,949:INFO:Importing libraries
2023-09-05 14:44:00,950:INFO:Copying training dataset
2023-09-05 14:44:00,952:INFO:Defining folds
2023-09-05 14:44:00,952:INFO:Declaring metric variables
2023-09-05 14:44:00,953:INFO:Importing untrained model
2023-09-05 14:44:00,953:INFO:Declaring custom model
2023-09-05 14:44:00,953:INFO:Dummy Regressor Imported successfully
2023-09-05 14:44:00,954:INFO:Starting cross validation
2023-09-05 14:44:00,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:44:01,104:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:01,105:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:01,120:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:01,121:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:01,122:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:01,123:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:01,124:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:01,125:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:01,137:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:01,139:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:01,142:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:01,144:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:01,144:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:01,145:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:01,154:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:01,156:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:01,162:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:01,163:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:01,164:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:01,165:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:01,268:INFO:Calculating mean and std
2023-09-05 14:44:01,268:INFO:Creating metrics dataframe
2023-09-05 14:44:01,270:INFO:Finalizing model
2023-09-05 14:44:01,341:INFO:Uploading results into container
2023-09-05 14:44:01,341:INFO:_master_model_container: 23
2023-09-05 14:44:01,341:INFO:_display_container: 26
2023-09-05 14:44:01,341:INFO:DummyRegressor()
2023-09-05 14:44:01,341:INFO:create_model() successfully completed......................................
2023-09-05 14:44:01,995:INFO:Initializing tune_model()
2023-09-05 14:44:01,996:INFO:tune_model(estimator=DecisionTreeRegressor(max_depth=5, random_state=5943), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>)
2023-09-05 14:44:01,996:INFO:Checking exceptions
2023-09-05 14:44:02,010:INFO:Copying training dataset
2023-09-05 14:44:02,013:INFO:Checking base model
2023-09-05 14:44:02,014:INFO:Base model : Decision Tree Regressor
2023-09-05 14:44:02,017:INFO:Declaring metric variables
2023-09-05 14:44:02,020:INFO:Defining Hyperparameters
2023-09-05 14:44:02,106:INFO:Tuning with n_jobs=-1
2023-09-05 14:44:02,106:INFO:Initializing RandomizedSearchCV
2023-09-05 14:44:04,844:INFO:best_params: {'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'absolute_error'}
2023-09-05 14:44:04,844:INFO:Hyperparameter search completed
2023-09-05 14:44:04,844:INFO:SubProcess create_model() called ==================================
2023-09-05 14:44:04,845:INFO:Initializing create_model()
2023-09-05 14:44:04,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=DecisionTreeRegressor(max_depth=5, random_state=5943), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E934AA9490>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'absolute_error'})
2023-09-05 14:44:04,845:INFO:Checking exceptions
2023-09-05 14:44:04,845:INFO:Importing libraries
2023-09-05 14:44:04,845:INFO:Copying training dataset
2023-09-05 14:44:04,848:INFO:Defining folds
2023-09-05 14:44:04,848:INFO:Declaring metric variables
2023-09-05 14:44:04,850:INFO:Importing untrained model
2023-09-05 14:44:04,850:INFO:Declaring custom model
2023-09-05 14:44:04,853:INFO:Decision Tree Regressor Imported successfully
2023-09-05 14:44:04,856:INFO:Starting cross validation
2023-09-05 14:44:04,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:44:05,037:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,038:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,048:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,050:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,050:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,051:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,054:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,054:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,057:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,059:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,069:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,071:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,078:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,080:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,090:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,091:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,112:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,113:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,118:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,119:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,208:INFO:Calculating mean and std
2023-09-05 14:44:05,209:INFO:Creating metrics dataframe
2023-09-05 14:44:05,212:INFO:Finalizing model
2023-09-05 14:44:05,306:INFO:Uploading results into container
2023-09-05 14:44:05,307:INFO:Uploading model into container now
2023-09-05 14:44:05,307:INFO:_master_model_container: 24
2023-09-05 14:44:05,307:INFO:_display_container: 27
2023-09-05 14:44:05,307:INFO:DecisionTreeRegressor(criterion='absolute_error', max_depth=9, max_features=1.0,
                      min_impurity_decrease=0.0001, min_samples_leaf=6,
                      min_samples_split=10, random_state=5943)
2023-09-05 14:44:05,307:INFO:create_model() successfully completed......................................
2023-09-05 14:44:05,373:INFO:SubProcess create_model() end ==================================
2023-09-05 14:44:05,373:INFO:choose_better activated
2023-09-05 14:44:05,375:INFO:SubProcess create_model() called ==================================
2023-09-05 14:44:05,375:INFO:Initializing create_model()
2023-09-05 14:44:05,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9321114C0>, estimator=DecisionTreeRegressor(max_depth=5, random_state=5943), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 14:44:05,375:INFO:Checking exceptions
2023-09-05 14:44:05,376:INFO:Importing libraries
2023-09-05 14:44:05,376:INFO:Copying training dataset
2023-09-05 14:44:05,379:INFO:Defining folds
2023-09-05 14:44:05,379:INFO:Declaring metric variables
2023-09-05 14:44:05,379:INFO:Importing untrained model
2023-09-05 14:44:05,379:INFO:Declaring custom model
2023-09-05 14:44:05,380:INFO:Decision Tree Regressor Imported successfully
2023-09-05 14:44:05,380:INFO:Starting cross validation
2023-09-05 14:44:05,381:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 14:44:05,520:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,521:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (527      9861.025391
505      6796.863281
390     10736.871094
299      9249.495117
152      6334.343750
            ...     
14      39611.757812
114     11488.317383
1292     1515.344849
1261     3277.160889
143     18157.876953
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,533:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,535:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1031    44423.804688
989     14571.890625
528      8342.909180
35       1625.433716
305     19442.353516
            ...     
113      2404.733887
899      2117.338867
286      9432.925781
530     48675.519531
1235     2699.568359
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,553:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,554:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (918     13041.920898
274      2523.169434
1215    12890.057617
153     19964.746094
1025     2020.177002
            ...     
384      8302.536133
1206    36910.609375
608      4435.094238
1042    33475.816406
386     11856.411133
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,564:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,566:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,566:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1266    10704.469727
942      2217.469238
249      4040.558350
332     13429.035156
1176    23887.662109
            ...     
372      7639.417480
911     33732.687500
562      2494.021973
772     12797.209961
436      2254.796631
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,567:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (68       5920.104004
77       1532.469727
1324     4239.892578
968      3279.868652
155      6948.700684
            ...     
1108     2904.087891
130     12815.445312
1058     2480.979004
568     11552.904297
841     12323.935547
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,567:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1010     8269.043945
640      6666.243164
172      1694.796387
675      7222.786133
1095     4561.188477
            ...     
1046     7325.048340
820      7445.917969
903      8125.784668
1027    21595.382812
641     32787.457031
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,580:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,581:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (513      1256.298950
786     12741.166992
1070    39871.703125
105     17560.378906
360     10043.249023
            ...     
194      1137.469727
101      3645.089355
531     14043.476562
201      8871.151367
1221     6593.508301
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,589:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,589:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,590:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (150      5125.215820
115     30259.996094
992     10118.423828
657      4058.712402
1209    12347.171875
            ...     
499     13470.860352
15       1837.237061
147      9877.607422
135      2155.681396
1033    13747.872070
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,591:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (615     42969.851562
1133     9991.038086
672      4399.730957
589      5976.831055
969      8596.828125
            ...     
333     11658.378906
354     14133.038086
1113     5312.169922
234      6710.191895
12       1826.843018
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,596:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 14:44:05,597:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (730     19361.998047
676     12485.800781
908     15170.069336
1218    41661.601562
967      7518.025391
            ...     
273      9617.662109
425      9788.866211
46       3393.356445
1320     5425.023438
1264    10370.912109
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 14:44:05,697:INFO:Calculating mean and std
2023-09-05 14:44:05,697:INFO:Creating metrics dataframe
2023-09-05 14:44:05,699:INFO:Finalizing model
2023-09-05 14:44:05,765:INFO:Uploading results into container
2023-09-05 14:44:05,765:INFO:Uploading model into container now
2023-09-05 14:44:05,766:INFO:_master_model_container: 25
2023-09-05 14:44:05,766:INFO:_display_container: 28
2023-09-05 14:44:05,766:INFO:DecisionTreeRegressor(max_depth=5, random_state=5943)
2023-09-05 14:44:05,766:INFO:create_model() successfully completed......................................
2023-09-05 14:44:05,827:INFO:SubProcess create_model() end ==================================
2023-09-05 14:44:05,828:INFO:DecisionTreeRegressor(max_depth=5, random_state=5943) result for R2 is 0.8226
2023-09-05 14:44:05,828:INFO:DecisionTreeRegressor(criterion='absolute_error', max_depth=9, max_features=1.0,
                      min_impurity_decrease=0.0001, min_samples_leaf=6,
                      min_samples_split=10, random_state=5943) result for R2 is 0.8218
2023-09-05 14:44:05,828:INFO:DecisionTreeRegressor(max_depth=5, random_state=5943) is best model
2023-09-05 14:44:05,828:INFO:choose_better completed
2023-09-05 14:44:05,829:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-05 14:44:05,837:INFO:_master_model_container: 25
2023-09-05 14:44:05,837:INFO:_display_container: 27
2023-09-05 14:44:05,837:INFO:DecisionTreeRegressor(max_depth=5, random_state=5943)
2023-09-05 14:44:05,837:INFO:tune_model() successfully completed......................................
2023-09-05 16:07:41,071:INFO:Initializing create_model()
2023-09-05 16:07:41,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:07:41,073:INFO:Checking exceptions
2023-09-05 16:07:41,129:INFO:Importing libraries
2023-09-05 16:07:41,129:INFO:Copying training dataset
2023-09-05 16:07:41,136:INFO:Defining folds
2023-09-05 16:07:41,136:INFO:Declaring metric variables
2023-09-05 16:07:41,139:INFO:Importing untrained model
2023-09-05 16:07:41,144:INFO:Decision Tree Classifier Imported successfully
2023-09-05 16:07:41,148:INFO:Starting cross validation
2023-09-05 16:07:41,152:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:07:43,099:INFO:Calculating mean and std
2023-09-05 16:07:43,101:INFO:Creating metrics dataframe
2023-09-05 16:07:43,108:INFO:Finalizing model
2023-09-05 16:07:43,148:INFO:Uploading results into container
2023-09-05 16:07:43,148:INFO:Uploading model into container now
2023-09-05 16:07:43,155:INFO:_master_model_container: 16
2023-09-05 16:07:43,155:INFO:_display_container: 3
2023-09-05 16:07:43,156:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-05 16:07:43,156:INFO:create_model() successfully completed......................................
2023-09-05 16:07:43,309:INFO:Initializing ensemble_model()
2023-09-05 16:07:43,309:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best'), method=Boosting, fold=None, n_estimators=10, round=4, choose_better=True, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-09-05 16:07:43,309:INFO:Checking exceptions
2023-09-05 16:07:43,352:INFO:Importing libraries
2023-09-05 16:07:43,353:INFO:Copying training dataset
2023-09-05 16:07:43,353:INFO:Checking base model
2023-09-05 16:07:43,353:INFO:Base model : Decision Tree Classifier
2023-09-05 16:07:43,358:INFO:Importing untrained ensembler
2023-09-05 16:07:43,358:INFO:Ensemble method set to Boosting
2023-09-05 16:07:43,358:INFO:SubProcess create_model() called ==================================
2023-09-05 16:07:43,359:INFO:Initializing create_model()
2023-09-05 16:07:43,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                    class_weight=None,
                                                    criterion='gini',
                                                    max_depth=None,
                                                    max_features=None,
                                                    max_leaf_nodes=None,
                                                    min_impurity_decrease=0.0,
                                                    min_samples_leaf=1,
                                                    min_samples_split=2,
                                                    min_weight_fraction_leaf=0.0,
                                                    random_state=1212,
                                                    splitter='best'),
                   learning_rate=1.0, n_estimators=10, random_state=1212), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CE046100>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:07:43,359:INFO:Checking exceptions
2023-09-05 16:07:43,359:INFO:Importing libraries
2023-09-05 16:07:43,359:INFO:Copying training dataset
2023-09-05 16:07:43,361:INFO:Defining folds
2023-09-05 16:07:43,362:INFO:Declaring metric variables
2023-09-05 16:07:43,364:INFO:Importing untrained model
2023-09-05 16:07:43,364:INFO:Declaring custom model
2023-09-05 16:07:43,368:INFO:Ada Boost Classifier Imported successfully
2023-09-05 16:07:43,374:INFO:Starting cross validation
2023-09-05 16:07:43,375:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:07:44,960:INFO:Calculating mean and std
2023-09-05 16:07:44,962:INFO:Creating metrics dataframe
2023-09-05 16:07:44,967:INFO:Finalizing model
2023-09-05 16:07:45,023:INFO:Uploading results into container
2023-09-05 16:07:45,023:INFO:Uploading model into container now
2023-09-05 16:07:45,024:INFO:_master_model_container: 17
2023-09-05 16:07:45,024:INFO:_display_container: 4
2023-09-05 16:07:45,025:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                    class_weight=None,
                                                    criterion='gini',
                                                    max_depth=None,
                                                    max_features=None,
                                                    max_leaf_nodes=None,
                                                    min_impurity_decrease=0.0,
                                                    min_samples_leaf=1,
                                                    min_samples_split=2,
                                                    min_weight_fraction_leaf=0.0,
                                                    random_state=1212,
                                                    splitter='best'),
                   learning_rate=1.0, n_estimators=10, random_state=1212)
2023-09-05 16:07:45,025:INFO:create_model() successfully completed......................................
2023-09-05 16:07:45,089:INFO:SubProcess create_model() end ==================================
2023-09-05 16:07:45,089:INFO:choose_better activated
2023-09-05 16:07:45,092:INFO:SubProcess create_model() called ==================================
2023-09-05 16:07:45,092:INFO:Initializing create_model()
2023-09-05 16:07:45,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:07:45,092:INFO:Checking exceptions
2023-09-05 16:07:45,093:INFO:Importing libraries
2023-09-05 16:07:45,093:INFO:Copying training dataset
2023-09-05 16:07:45,095:INFO:Defining folds
2023-09-05 16:07:45,095:INFO:Declaring metric variables
2023-09-05 16:07:45,095:INFO:Importing untrained model
2023-09-05 16:07:45,095:INFO:Declaring custom model
2023-09-05 16:07:45,096:INFO:Decision Tree Classifier Imported successfully
2023-09-05 16:07:45,096:INFO:Starting cross validation
2023-09-05 16:07:45,096:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:07:46,651:INFO:Calculating mean and std
2023-09-05 16:07:46,652:INFO:Creating metrics dataframe
2023-09-05 16:07:46,654:INFO:Finalizing model
2023-09-05 16:07:46,695:INFO:Uploading results into container
2023-09-05 16:07:46,696:INFO:Uploading model into container now
2023-09-05 16:07:46,696:INFO:_master_model_container: 18
2023-09-05 16:07:46,696:INFO:_display_container: 5
2023-09-05 16:07:46,696:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-05 16:07:46,696:INFO:create_model() successfully completed......................................
2023-09-05 16:07:46,776:INFO:SubProcess create_model() end ==================================
2023-09-05 16:07:46,777:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best') result for Accuracy is 0.7739
2023-09-05 16:07:46,778:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                    class_weight=None,
                                                    criterion='gini',
                                                    max_depth=None,
                                                    max_features=None,
                                                    max_leaf_nodes=None,
                                                    min_impurity_decrease=0.0,
                                                    min_samples_leaf=1,
                                                    min_samples_split=2,
                                                    min_weight_fraction_leaf=0.0,
                                                    random_state=1212,
                                                    splitter='best'),
                   learning_rate=1.0, n_estimators=10, random_state=1212) result for Accuracy is 0.7641
2023-09-05 16:07:46,778:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best') is best model
2023-09-05 16:07:46,778:INFO:choose_better completed
2023-09-05 16:07:46,778:INFO:Original model was better than the ensembled model, hence it will be returned. NOTE: The display metrics are for the ensembled model (not the original one).
2023-09-05 16:07:46,785:INFO:_master_model_container: 18
2023-09-05 16:07:46,785:INFO:_display_container: 4
2023-09-05 16:07:46,785:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-05 16:07:46,785:INFO:ensemble_model() successfully completed......................................
2023-09-05 16:09:16,815:INFO:Initializing create_model()
2023-09-05 16:09:16,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'max_depth': 5})
2023-09-05 16:09:16,815:INFO:Checking exceptions
2023-09-05 16:09:16,824:INFO:Importing libraries
2023-09-05 16:09:16,824:INFO:Copying training dataset
2023-09-05 16:09:16,828:INFO:Defining folds
2023-09-05 16:09:16,828:INFO:Declaring metric variables
2023-09-05 16:09:16,831:INFO:Importing untrained model
2023-09-05 16:09:16,836:INFO:Decision Tree Classifier Imported successfully
2023-09-05 16:09:16,841:INFO:Starting cross validation
2023-09-05 16:09:16,841:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:09:18,308:INFO:Calculating mean and std
2023-09-05 16:09:18,310:INFO:Creating metrics dataframe
2023-09-05 16:09:18,317:INFO:Finalizing model
2023-09-05 16:09:18,352:INFO:Uploading results into container
2023-09-05 16:09:18,352:INFO:Uploading model into container now
2023-09-05 16:09:18,357:INFO:_master_model_container: 19
2023-09-05 16:09:18,357:INFO:_display_container: 5
2023-09-05 16:09:18,357:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=5, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-05 16:09:18,357:INFO:create_model() successfully completed......................................
2023-09-05 16:45:45,602:INFO:Initializing create_model()
2023-09-05 16:45:45,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'n_estimators': 300, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-05 16:45:45,602:INFO:Checking exceptions
2023-09-05 16:45:45,614:INFO:Importing libraries
2023-09-05 16:45:45,615:INFO:Copying training dataset
2023-09-05 16:45:45,617:INFO:Defining folds
2023-09-05 16:45:45,617:INFO:Declaring metric variables
2023-09-05 16:45:45,620:INFO:Importing untrained model
2023-09-05 16:45:45,625:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:45:45,633:INFO:Starting cross validation
2023-09-05 16:45:45,634:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:45:48,400:INFO:Calculating mean and std
2023-09-05 16:45:48,402:INFO:Creating metrics dataframe
2023-09-05 16:45:48,409:INFO:Finalizing model
2023-09-05 16:45:48,951:INFO:Uploading results into container
2023-09-05 16:45:48,952:INFO:Uploading model into container now
2023-09-05 16:45:48,958:INFO:_master_model_container: 20
2023-09-05 16:45:48,958:INFO:_display_container: 6
2023-09-05 16:45:48,958:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:45:48,958:INFO:create_model() successfully completed......................................
2023-09-05 16:47:45,993:INFO:Initializing create_model()
2023-09-05 16:47:45,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'n_estimators': 300, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-05 16:47:45,993:INFO:Checking exceptions
2023-09-05 16:47:46,002:INFO:Importing libraries
2023-09-05 16:47:46,002:INFO:Copying training dataset
2023-09-05 16:47:46,005:INFO:Defining folds
2023-09-05 16:47:46,006:INFO:Declaring metric variables
2023-09-05 16:47:46,012:INFO:Importing untrained model
2023-09-05 16:47:46,019:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:47:46,025:INFO:Starting cross validation
2023-09-05 16:47:46,025:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:47:47,901:INFO:Calculating mean and std
2023-09-05 16:47:47,903:INFO:Creating metrics dataframe
2023-09-05 16:47:47,910:INFO:Finalizing model
2023-09-05 16:47:47,996:INFO:Uploading results into container
2023-09-05 16:47:47,997:INFO:Uploading model into container now
2023-09-05 16:47:48,002:INFO:_master_model_container: 21
2023-09-05 16:47:48,002:INFO:_display_container: 7
2023-09-05 16:47:48,002:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:47:48,002:INFO:create_model() successfully completed......................................
2023-09-05 16:49:20,545:INFO:Initializing create_model()
2023-09-05 16:49:20,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'n_estimators': 300, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-05 16:49:20,545:INFO:Checking exceptions
2023-09-05 16:49:20,560:INFO:Importing libraries
2023-09-05 16:49:20,560:INFO:Copying training dataset
2023-09-05 16:49:20,562:INFO:Defining folds
2023-09-05 16:49:20,562:INFO:Declaring metric variables
2023-09-05 16:49:20,565:INFO:Importing untrained model
2023-09-05 16:49:20,567:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:49:20,572:INFO:Starting cross validation
2023-09-05 16:49:20,573:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:49:22,403:INFO:Calculating mean and std
2023-09-05 16:49:22,404:INFO:Creating metrics dataframe
2023-09-05 16:49:22,410:INFO:Finalizing model
2023-09-05 16:49:22,510:INFO:Uploading results into container
2023-09-05 16:49:22,510:INFO:Uploading model into container now
2023-09-05 16:49:22,516:INFO:_master_model_container: 22
2023-09-05 16:49:22,516:INFO:_display_container: 8
2023-09-05 16:49:22,516:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:49:22,516:INFO:create_model() successfully completed......................................
2023-09-05 16:49:22,585:INFO:Initializing tune_model()
2023-09-05 16:49:22,585:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'max_depth': [10, 20], 'min_samples_split': [1, 2], 'min_samples_leaf': [1, 2]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>)
2023-09-05 16:49:22,585:INFO:Checking exceptions
2023-09-05 16:49:22,596:INFO:Copying training dataset
2023-09-05 16:49:22,598:INFO:Checking base model
2023-09-05 16:49:22,598:INFO:Base model : Random Forest Classifier
2023-09-05 16:49:22,600:INFO:Declaring metric variables
2023-09-05 16:49:22,602:INFO:Defining Hyperparameters
2023-09-05 16:49:22,671:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [10, 20], 'actual_estimator__min_samples_split': [1, 2], 'actual_estimator__min_samples_leaf': [1, 2]}
2023-09-05 16:49:22,671:INFO:Tuning with n_jobs=-1
2023-09-05 16:49:22,672:INFO:Initializing RandomizedSearchCV
2023-09-05 16:49:25,824:INFO:best_params: {'actual_estimator__n_estimators': 300, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 10}
2023-09-05 16:49:25,825:INFO:Hyperparameter search completed
2023-09-05 16:49:25,825:INFO:SubProcess create_model() called ==================================
2023-09-05 16:49:25,826:INFO:Initializing create_model()
2023-09-05 16:49:25,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CDEFA670>, model_only=True, return_train_score=False, kwargs={'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10})
2023-09-05 16:49:25,826:INFO:Checking exceptions
2023-09-05 16:49:25,826:INFO:Importing libraries
2023-09-05 16:49:25,826:INFO:Copying training dataset
2023-09-05 16:49:25,829:INFO:Defining folds
2023-09-05 16:49:25,829:INFO:Declaring metric variables
2023-09-05 16:49:25,831:INFO:Importing untrained model
2023-09-05 16:49:25,831:INFO:Declaring custom model
2023-09-05 16:49:25,835:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:49:25,840:INFO:Starting cross validation
2023-09-05 16:49:25,840:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:49:26,260:INFO:Calculating mean and std
2023-09-05 16:49:26,261:INFO:Creating metrics dataframe
2023-09-05 16:49:26,269:INFO:Finalizing model
2023-09-05 16:49:26,355:INFO:Uploading results into container
2023-09-05 16:49:26,355:INFO:Uploading model into container now
2023-09-05 16:49:26,355:INFO:_master_model_container: 23
2023-09-05 16:49:26,355:INFO:_display_container: 9
2023-09-05 16:49:26,356:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:49:26,356:INFO:create_model() successfully completed......................................
2023-09-05 16:49:26,414:INFO:SubProcess create_model() end ==================================
2023-09-05 16:49:26,414:INFO:choose_better activated
2023-09-05 16:49:26,416:INFO:SubProcess create_model() called ==================================
2023-09-05 16:49:26,416:INFO:Initializing create_model()
2023-09-05 16:49:26,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:49:26,416:INFO:Checking exceptions
2023-09-05 16:49:26,418:INFO:Importing libraries
2023-09-05 16:49:26,418:INFO:Copying training dataset
2023-09-05 16:49:26,420:INFO:Defining folds
2023-09-05 16:49:26,420:INFO:Declaring metric variables
2023-09-05 16:49:26,420:INFO:Importing untrained model
2023-09-05 16:49:26,420:INFO:Declaring custom model
2023-09-05 16:49:26,420:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:49:26,420:INFO:Starting cross validation
2023-09-05 16:49:26,421:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:49:26,814:INFO:Calculating mean and std
2023-09-05 16:49:26,814:INFO:Creating metrics dataframe
2023-09-05 16:49:26,816:INFO:Finalizing model
2023-09-05 16:49:26,901:INFO:Uploading results into container
2023-09-05 16:49:26,902:INFO:Uploading model into container now
2023-09-05 16:49:26,902:INFO:_master_model_container: 24
2023-09-05 16:49:26,902:INFO:_display_container: 10
2023-09-05 16:49:26,902:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:49:26,902:INFO:create_model() successfully completed......................................
2023-09-05 16:49:26,956:INFO:SubProcess create_model() end ==================================
2023-09-05 16:49:26,957:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8258
2023-09-05 16:49:26,957:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8258
2023-09-05 16:49:26,957:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 16:49:26,958:INFO:choose_better completed
2023-09-05 16:49:26,958:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-05 16:49:26,963:INFO:_master_model_container: 24
2023-09-05 16:49:26,963:INFO:_display_container: 9
2023-09-05 16:49:26,963:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:49:26,963:INFO:tune_model() successfully completed......................................
2023-09-05 16:53:56,975:INFO:Initializing tune_model()
2023-09-05 16:53:56,975:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>)
2023-09-05 16:53:56,975:INFO:Checking exceptions
2023-09-05 16:53:56,975:INFO:Soft dependency imported: optuna: 3.3.0
2023-09-05 16:53:57,385:INFO:Copying training dataset
2023-09-05 16:53:57,387:INFO:Checking base model
2023-09-05 16:53:57,387:INFO:Base model : Random Forest Classifier
2023-09-05 16:53:57,392:INFO:Declaring metric variables
2023-09-05 16:53:57,395:INFO:Defining Hyperparameters
2023-09-05 16:53:57,470:INFO:Tuning with n_jobs=-1
2023-09-05 16:53:57,471:INFO:Initializing optuna.integration.OptunaSearchCV
2023-09-05 16:54:09,361:INFO:best_params: {'actual_estimator__n_estimators': 192, 'actual_estimator__max_depth': 8, 'actual_estimator__min_impurity_decrease': 7.517627721033387e-07, 'actual_estimator__max_features': 0.7807267801400662, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__bootstrap': False, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced'}
2023-09-05 16:54:09,362:INFO:Hyperparameter search completed
2023-09-05 16:54:09,362:INFO:SubProcess create_model() called ==================================
2023-09-05 16:54:09,362:INFO:Initializing create_model()
2023-09-05 16:54:09,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CDFA0EE0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 192, 'max_depth': 8, 'min_impurity_decrease': 7.517627721033387e-07, 'max_features': 0.7807267801400662, 'min_samples_split': 10, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'gini', 'class_weight': 'balanced'})
2023-09-05 16:54:09,363:INFO:Checking exceptions
2023-09-05 16:54:09,363:INFO:Importing libraries
2023-09-05 16:54:09,363:INFO:Copying training dataset
2023-09-05 16:54:09,365:INFO:Defining folds
2023-09-05 16:54:09,366:INFO:Declaring metric variables
2023-09-05 16:54:09,368:INFO:Importing untrained model
2023-09-05 16:54:09,368:INFO:Declaring custom model
2023-09-05 16:54:09,370:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:54:09,376:INFO:Starting cross validation
2023-09-05 16:54:09,377:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:54:09,690:INFO:Calculating mean and std
2023-09-05 16:54:09,691:INFO:Creating metrics dataframe
2023-09-05 16:54:09,695:INFO:Finalizing model
2023-09-05 16:54:10,023:INFO:Uploading results into container
2023-09-05 16:54:10,024:INFO:Uploading model into container now
2023-09-05 16:54:10,024:INFO:_master_model_container: 25
2023-09-05 16:54:10,024:INFO:_display_container: 10
2023-09-05 16:54:10,025:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=8,
                       max_features=0.7807267801400662, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=7.517627721033387e-07,
                       min_samples_leaf=6, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=192,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 16:54:10,025:INFO:create_model() successfully completed......................................
2023-09-05 16:54:10,093:INFO:SubProcess create_model() end ==================================
2023-09-05 16:54:10,093:INFO:choose_better activated
2023-09-05 16:54:10,096:INFO:SubProcess create_model() called ==================================
2023-09-05 16:54:10,096:INFO:Initializing create_model()
2023-09-05 16:54:10,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:54:10,096:INFO:Checking exceptions
2023-09-05 16:54:10,097:INFO:Importing libraries
2023-09-05 16:54:10,097:INFO:Copying training dataset
2023-09-05 16:54:10,099:INFO:Defining folds
2023-09-05 16:54:10,099:INFO:Declaring metric variables
2023-09-05 16:54:10,099:INFO:Importing untrained model
2023-09-05 16:54:10,099:INFO:Declaring custom model
2023-09-05 16:54:10,100:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:54:10,100:INFO:Starting cross validation
2023-09-05 16:54:10,100:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:54:10,513:INFO:Calculating mean and std
2023-09-05 16:54:10,513:INFO:Creating metrics dataframe
2023-09-05 16:54:10,514:INFO:Finalizing model
2023-09-05 16:54:10,608:INFO:Uploading results into container
2023-09-05 16:54:10,608:INFO:Uploading model into container now
2023-09-05 16:54:10,608:INFO:_master_model_container: 26
2023-09-05 16:54:10,608:INFO:_display_container: 11
2023-09-05 16:54:10,608:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:54:10,609:INFO:create_model() successfully completed......................................
2023-09-05 16:54:10,673:INFO:SubProcess create_model() end ==================================
2023-09-05 16:54:10,673:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8258
2023-09-05 16:54:10,673:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=8,
                       max_features=0.7807267801400662, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=7.517627721033387e-07,
                       min_samples_leaf=6, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=192,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.8272
2023-09-05 16:54:10,674:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=8,
                       max_features=0.7807267801400662, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=7.517627721033387e-07,
                       min_samples_leaf=6, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=192,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) is best model
2023-09-05 16:54:10,674:INFO:choose_better completed
2023-09-05 16:54:10,678:INFO:_master_model_container: 26
2023-09-05 16:54:10,678:INFO:_display_container: 10
2023-09-05 16:54:10,678:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=8,
                       max_features=0.7807267801400662, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=7.517627721033387e-07,
                       min_samples_leaf=6, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=192,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 16:54:10,679:INFO:tune_model() successfully completed......................................
2023-09-05 16:54:22,519:INFO:Initializing tune_model()
2023-09-05 16:54:22,519:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>)
2023-09-05 16:54:22,519:INFO:Checking exceptions
2023-09-05 16:54:22,536:INFO:Copying training dataset
2023-09-05 16:54:22,538:INFO:Checking base model
2023-09-05 16:54:22,538:INFO:Base model : Random Forest Classifier
2023-09-05 16:54:22,542:INFO:Declaring metric variables
2023-09-05 16:54:22,544:INFO:Defining Hyperparameters
2023-09-05 16:54:22,618:INFO:Tuning with n_jobs=-1
2023-09-05 16:54:22,618:INFO:Initializing RandomizedSearchCV
2023-09-05 16:54:24,912:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2023-09-05 16:54:24,913:INFO:Hyperparameter search completed
2023-09-05 16:54:24,913:INFO:SubProcess create_model() called ==================================
2023-09-05 16:54:24,913:INFO:Initializing create_model()
2023-09-05 16:54:24,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CDC36850>, model_only=True, return_train_score=False, kwargs={'n_estimators': 160, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 8, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2023-09-05 16:54:24,913:INFO:Checking exceptions
2023-09-05 16:54:24,913:INFO:Importing libraries
2023-09-05 16:54:24,913:INFO:Copying training dataset
2023-09-05 16:54:24,916:INFO:Defining folds
2023-09-05 16:54:24,916:INFO:Declaring metric variables
2023-09-05 16:54:24,918:INFO:Importing untrained model
2023-09-05 16:54:24,918:INFO:Declaring custom model
2023-09-05 16:54:24,920:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:54:24,924:INFO:Starting cross validation
2023-09-05 16:54:24,925:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:54:25,231:INFO:Calculating mean and std
2023-09-05 16:54:25,232:INFO:Creating metrics dataframe
2023-09-05 16:54:25,235:INFO:Finalizing model
2023-09-05 16:54:25,573:INFO:Uploading results into container
2023-09-05 16:54:25,574:INFO:Uploading model into container now
2023-09-05 16:54:25,574:INFO:_master_model_container: 27
2023-09-05 16:54:25,574:INFO:_display_container: 11
2023-09-05 16:54:25,574:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:54:25,574:INFO:create_model() successfully completed......................................
2023-09-05 16:54:25,646:INFO:SubProcess create_model() end ==================================
2023-09-05 16:54:25,647:INFO:choose_better activated
2023-09-05 16:54:25,649:INFO:SubProcess create_model() called ==================================
2023-09-05 16:54:25,649:INFO:Initializing create_model()
2023-09-05 16:54:25,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:54:25,649:INFO:Checking exceptions
2023-09-05 16:54:25,650:INFO:Importing libraries
2023-09-05 16:54:25,650:INFO:Copying training dataset
2023-09-05 16:54:25,652:INFO:Defining folds
2023-09-05 16:54:25,652:INFO:Declaring metric variables
2023-09-05 16:54:25,653:INFO:Importing untrained model
2023-09-05 16:54:25,653:INFO:Declaring custom model
2023-09-05 16:54:25,653:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:54:25,653:INFO:Starting cross validation
2023-09-05 16:54:25,654:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:54:26,083:INFO:Calculating mean and std
2023-09-05 16:54:26,083:INFO:Creating metrics dataframe
2023-09-05 16:54:26,084:INFO:Finalizing model
2023-09-05 16:54:26,187:INFO:Uploading results into container
2023-09-05 16:54:26,188:INFO:Uploading model into container now
2023-09-05 16:54:26,188:INFO:_master_model_container: 28
2023-09-05 16:54:26,188:INFO:_display_container: 12
2023-09-05 16:54:26,188:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:54:26,189:INFO:create_model() successfully completed......................................
2023-09-05 16:54:26,253:INFO:SubProcess create_model() end ==================================
2023-09-05 16:54:26,254:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8258
2023-09-05 16:54:26,254:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8174
2023-09-05 16:54:26,254:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 16:54:26,254:INFO:choose_better completed
2023-09-05 16:54:26,254:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-05 16:54:26,260:INFO:_master_model_container: 28
2023-09-05 16:54:26,260:INFO:_display_container: 11
2023-09-05 16:54:26,261:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:54:26,261:INFO:tune_model() successfully completed......................................
2023-09-05 16:54:41,488:INFO:Initializing tune_model()
2023-09-05 16:54:41,488:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>)
2023-09-05 16:54:41,488:INFO:Checking exceptions
2023-09-05 16:54:41,489:INFO:Soft dependency imported: optuna: 3.3.0
2023-09-05 16:54:41,498:INFO:Copying training dataset
2023-09-05 16:54:41,500:INFO:Checking base model
2023-09-05 16:54:41,501:INFO:Base model : Random Forest Classifier
2023-09-05 16:54:41,505:INFO:Declaring metric variables
2023-09-05 16:54:41,508:INFO:Defining Hyperparameters
2023-09-05 16:54:41,597:INFO:Tuning with n_jobs=-1
2023-09-05 16:54:41,599:INFO:Initializing optuna.integration.OptunaSearchCV
2023-09-05 16:54:49,505:INFO:best_params: {'actual_estimator__n_estimators': 130, 'actual_estimator__max_depth': 7, 'actual_estimator__min_impurity_decrease': 4.788664089214674e-07, 'actual_estimator__max_features': 0.7754410837772163, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__bootstrap': True, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced'}
2023-09-05 16:54:49,506:INFO:Hyperparameter search completed
2023-09-05 16:54:49,506:INFO:SubProcess create_model() called ==================================
2023-09-05 16:54:49,506:INFO:Initializing create_model()
2023-09-05 16:54:49,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CDEF5BB0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 130, 'max_depth': 7, 'min_impurity_decrease': 4.788664089214674e-07, 'max_features': 0.7754410837772163, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': True, 'criterion': 'gini', 'class_weight': 'balanced'})
2023-09-05 16:54:49,506:INFO:Checking exceptions
2023-09-05 16:54:49,506:INFO:Importing libraries
2023-09-05 16:54:49,506:INFO:Copying training dataset
2023-09-05 16:54:49,509:INFO:Defining folds
2023-09-05 16:54:49,509:INFO:Declaring metric variables
2023-09-05 16:54:49,511:INFO:Importing untrained model
2023-09-05 16:54:49,511:INFO:Declaring custom model
2023-09-05 16:54:49,514:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:54:49,520:INFO:Starting cross validation
2023-09-05 16:54:49,521:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:54:49,813:INFO:Calculating mean and std
2023-09-05 16:54:49,814:INFO:Creating metrics dataframe
2023-09-05 16:54:49,818:INFO:Finalizing model
2023-09-05 16:54:50,115:INFO:Uploading results into container
2023-09-05 16:54:50,115:INFO:Uploading model into container now
2023-09-05 16:54:50,115:INFO:_master_model_container: 29
2023-09-05 16:54:50,116:INFO:_display_container: 12
2023-09-05 16:54:50,116:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=7,
                       max_features=0.7754410837772163, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=4.788664089214674e-07,
                       min_samples_leaf=3, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=130,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 16:54:50,116:INFO:create_model() successfully completed......................................
2023-09-05 16:54:50,188:INFO:SubProcess create_model() end ==================================
2023-09-05 16:54:50,189:INFO:choose_better activated
2023-09-05 16:54:50,191:INFO:SubProcess create_model() called ==================================
2023-09-05 16:54:50,192:INFO:Initializing create_model()
2023-09-05 16:54:50,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:54:50,192:INFO:Checking exceptions
2023-09-05 16:54:50,193:INFO:Importing libraries
2023-09-05 16:54:50,193:INFO:Copying training dataset
2023-09-05 16:54:50,195:INFO:Defining folds
2023-09-05 16:54:50,195:INFO:Declaring metric variables
2023-09-05 16:54:50,195:INFO:Importing untrained model
2023-09-05 16:54:50,195:INFO:Declaring custom model
2023-09-05 16:54:50,195:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:54:50,196:INFO:Starting cross validation
2023-09-05 16:54:50,196:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:54:50,661:INFO:Calculating mean and std
2023-09-05 16:54:50,661:INFO:Creating metrics dataframe
2023-09-05 16:54:50,662:INFO:Finalizing model
2023-09-05 16:54:50,771:INFO:Uploading results into container
2023-09-05 16:54:50,771:INFO:Uploading model into container now
2023-09-05 16:54:50,772:INFO:_master_model_container: 30
2023-09-05 16:54:50,772:INFO:_display_container: 13
2023-09-05 16:54:50,772:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:54:50,772:INFO:create_model() successfully completed......................................
2023-09-05 16:54:50,839:INFO:SubProcess create_model() end ==================================
2023-09-05 16:54:50,840:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8258
2023-09-05 16:54:50,840:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=7,
                       max_features=0.7754410837772163, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=4.788664089214674e-07,
                       min_samples_leaf=3, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=130,
                       n_jobs=-1, oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.8244
2023-09-05 16:54:50,840:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 16:54:50,840:INFO:choose_better completed
2023-09-05 16:54:50,840:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-05 16:54:50,846:INFO:_master_model_container: 30
2023-09-05 16:54:50,846:INFO:_display_container: 12
2023-09-05 16:54:50,846:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:54:50,846:INFO:tune_model() successfully completed......................................
2023-09-05 16:58:26,120:INFO:Initializing tune_model()
2023-09-05 16:58:26,120:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>)
2023-09-05 16:58:26,120:INFO:Checking exceptions
2023-09-05 16:58:26,120:INFO:Soft dependency imported: skopt: 0.9.0
2023-09-05 16:58:26,195:INFO:Copying training dataset
2023-09-05 16:58:26,198:INFO:Checking base model
2023-09-05 16:58:26,198:INFO:Base model : Random Forest Classifier
2023-09-05 16:58:26,202:INFO:Declaring metric variables
2023-09-05 16:58:26,205:INFO:Defining Hyperparameters
2023-09-05 16:58:26,282:INFO:Tuning with n_jobs=-1
2023-09-05 16:58:26,285:INFO:Initializing skopt.BayesSearchCV
2023-09-05 16:58:32,610:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', False), ('actual_estimator__class_weight', 'balanced'), ('actual_estimator__criterion', 'entropy'), ('actual_estimator__max_depth', 9), ('actual_estimator__max_features', 0.6572967088396628), ('actual_estimator__min_impurity_decrease', 0.0001578347418897214), ('actual_estimator__min_samples_leaf', 3), ('actual_estimator__min_samples_split', 5), ('actual_estimator__n_estimators', 67)])
2023-09-05 16:58:32,610:INFO:Hyperparameter search completed
2023-09-05 16:58:32,610:INFO:SubProcess create_model() called ==================================
2023-09-05 16:58:32,611:INFO:Initializing create_model()
2023-09-05 16:58:32,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182CCADBD90>, model_only=True, return_train_score=False, kwargs={'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_features': 0.6572967088396628, 'min_impurity_decrease': 0.0001578347418897214, 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 67})
2023-09-05 16:58:32,611:INFO:Checking exceptions
2023-09-05 16:58:32,611:INFO:Importing libraries
2023-09-05 16:58:32,611:INFO:Copying training dataset
2023-09-05 16:58:32,613:INFO:Defining folds
2023-09-05 16:58:32,613:INFO:Declaring metric variables
2023-09-05 16:58:32,616:INFO:Importing untrained model
2023-09-05 16:58:32,616:INFO:Declaring custom model
2023-09-05 16:58:32,619:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:58:32,624:INFO:Starting cross validation
2023-09-05 16:58:32,625:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:58:32,937:INFO:Calculating mean and std
2023-09-05 16:58:32,938:INFO:Creating metrics dataframe
2023-09-05 16:58:32,941:INFO:Finalizing model
2023-09-05 16:58:33,084:INFO:Uploading results into container
2023-09-05 16:58:33,085:INFO:Uploading model into container now
2023-09-05 16:58:33,085:INFO:_master_model_container: 31
2023-09-05 16:58:33,085:INFO:_display_container: 13
2023-09-05 16:58:33,086:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=9,
                       max_features=0.6572967088396628, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.0001578347418897214,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=67, n_jobs=-1,
                       oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 16:58:33,086:INFO:create_model() successfully completed......................................
2023-09-05 16:58:33,156:INFO:SubProcess create_model() end ==================================
2023-09-05 16:58:33,156:INFO:choose_better activated
2023-09-05 16:58:33,159:INFO:SubProcess create_model() called ==================================
2023-09-05 16:58:33,160:INFO:Initializing create_model()
2023-09-05 16:58:33,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182CE142AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:58:33,160:INFO:Checking exceptions
2023-09-05 16:58:33,161:INFO:Importing libraries
2023-09-05 16:58:33,161:INFO:Copying training dataset
2023-09-05 16:58:33,163:INFO:Defining folds
2023-09-05 16:58:33,163:INFO:Declaring metric variables
2023-09-05 16:58:33,163:INFO:Importing untrained model
2023-09-05 16:58:33,163:INFO:Declaring custom model
2023-09-05 16:58:33,164:INFO:Random Forest Classifier Imported successfully
2023-09-05 16:58:33,164:INFO:Starting cross validation
2023-09-05 16:58:33,165:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 16:58:33,632:INFO:Calculating mean and std
2023-09-05 16:58:33,632:INFO:Creating metrics dataframe
2023-09-05 16:58:33,633:INFO:Finalizing model
2023-09-05 16:58:33,745:INFO:Uploading results into container
2023-09-05 16:58:33,745:INFO:Uploading model into container now
2023-09-05 16:58:33,745:INFO:_master_model_container: 32
2023-09-05 16:58:33,745:INFO:_display_container: 14
2023-09-05 16:58:33,746:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:58:33,746:INFO:create_model() successfully completed......................................
2023-09-05 16:58:33,804:INFO:SubProcess create_model() end ==================================
2023-09-05 16:58:33,805:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8258
2023-09-05 16:58:33,805:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=9,
                       max_features=0.6572967088396628, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.0001578347418897214,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=67, n_jobs=-1,
                       oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.8244
2023-09-05 16:58:33,805:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 16:58:33,805:INFO:choose_better completed
2023-09-05 16:58:33,806:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-05 16:58:33,814:INFO:_master_model_container: 32
2023-09-05 16:58:33,814:INFO:_display_container: 13
2023-09-05 16:58:33,814:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 16:58:33,814:INFO:tune_model() successfully completed......................................
2023-09-06 09:32:19,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:32:19,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:32:19,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:32:19,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:32:20,435:INFO:PyCaret ClassificationExperiment
2023-09-06 09:32:20,435:INFO:Logging name: clf-default-name
2023-09-06 09:32:20,435:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-06 09:32:20,435:INFO:version 3.0.4
2023-09-06 09:32:20,435:INFO:Initializing setup()
2023-09-06 09:32:20,435:INFO:self.USI: 0d64
2023-09-06 09:32:20,435:INFO:self._variable_keys: {'memory', 'gpu_n_jobs_param', 'idx', 'is_multiclass', 'logging_param', 'fold_shuffle_param', '_ml_usecase', 'n_jobs_param', 'X_test', 'y_test', 'USI', 'X_train', '_available_plots', 'X', 'fold_generator', 'log_plots_param', 'fold_groups_param', 'exp_id', 'data', 'exp_name_log', 'gpu_param', 'target_param', 'fix_imbalance', 'y_train', 'seed', 'y', 'pipeline', 'html_param'}
2023-09-06 09:32:20,435:INFO:Checking environment
2023-09-06 09:32:20,435:INFO:python_version: 3.8.8
2023-09-06 09:32:20,435:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-06 09:32:20,435:INFO:machine: AMD64
2023-09-06 09:32:20,435:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-06 09:32:20,437:INFO:Memory: svmem(total=16822788096, available=8208449536, percent=51.2, used=8614338560, free=8208449536)
2023-09-06 09:32:20,437:INFO:Physical Core: 8
2023-09-06 09:32:20,437:INFO:Logical Core: 16
2023-09-06 09:32:20,437:INFO:Checking libraries
2023-09-06 09:32:20,437:INFO:System:
2023-09-06 09:32:20,437:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-06 09:32:20,437:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-06 09:32:20,437:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-06 09:32:20,437:INFO:PyCaret required dependencies:
2023-09-06 09:32:20,438:INFO:                 pip: 22.3.1
2023-09-06 09:32:20,438:INFO:          setuptools: 65.5.1
2023-09-06 09:32:20,438:INFO:             pycaret: 3.0.4
2023-09-06 09:32:20,438:INFO:             IPython: 8.12.2
2023-09-06 09:32:20,438:INFO:          ipywidgets: 8.0.7
2023-09-06 09:32:20,438:INFO:                tqdm: 4.66.1
2023-09-06 09:32:20,438:INFO:               numpy: 1.23.5
2023-09-06 09:32:20,438:INFO:              pandas: 1.5.3
2023-09-06 09:32:20,438:INFO:              jinja2: 3.1.2
2023-09-06 09:32:20,438:INFO:               scipy: 1.10.1
2023-09-06 09:32:20,438:INFO:              joblib: 1.3.2
2023-09-06 09:32:20,438:INFO:             sklearn: 1.2.2
2023-09-06 09:32:20,438:INFO:                pyod: 1.1.0
2023-09-06 09:32:20,438:INFO:            imblearn: 0.11.0
2023-09-06 09:32:20,438:INFO:   category_encoders: 2.6.2
2023-09-06 09:32:20,438:INFO:            lightgbm: 4.0.0
2023-09-06 09:32:20,438:INFO:               numba: 0.57.1
2023-09-06 09:32:20,438:INFO:            requests: 2.31.0
2023-09-06 09:32:20,438:INFO:          matplotlib: 3.7.2
2023-09-06 09:32:20,438:INFO:          scikitplot: 0.3.7
2023-09-06 09:32:20,438:INFO:         yellowbrick: 1.5
2023-09-06 09:32:20,438:INFO:              plotly: 5.15.0
2023-09-06 09:32:20,438:INFO:    plotly-resampler: Not installed
2023-09-06 09:32:20,438:INFO:             kaleido: 0.2.1
2023-09-06 09:32:20,438:INFO:           schemdraw: 0.15
2023-09-06 09:32:20,439:INFO:         statsmodels: 0.14.0
2023-09-06 09:32:20,439:INFO:              sktime: 0.22.0
2023-09-06 09:32:20,439:INFO:               tbats: 1.1.3
2023-09-06 09:32:20,439:INFO:            pmdarima: 2.0.3
2023-09-06 09:32:20,439:INFO:              psutil: 5.9.5
2023-09-06 09:32:20,439:INFO:          markupsafe: 2.1.3
2023-09-06 09:32:20,439:INFO:             pickle5: Not installed
2023-09-06 09:32:20,439:INFO:         cloudpickle: 2.2.1
2023-09-06 09:32:20,439:INFO:         deprecation: 2.1.0
2023-09-06 09:32:20,439:INFO:              xxhash: 3.3.0
2023-09-06 09:32:20,439:INFO:           wurlitzer: Not installed
2023-09-06 09:32:20,439:INFO:PyCaret optional dependencies:
2023-09-06 09:32:20,443:INFO:                shap: Not installed
2023-09-06 09:32:20,443:INFO:           interpret: Not installed
2023-09-06 09:32:20,443:INFO:                umap: Not installed
2023-09-06 09:32:20,443:INFO:    pandas_profiling: 4.5.1
2023-09-06 09:32:20,444:INFO:  explainerdashboard: Not installed
2023-09-06 09:32:20,444:INFO:             autoviz: Not installed
2023-09-06 09:32:20,444:INFO:           fairlearn: Not installed
2023-09-06 09:32:20,444:INFO:          deepchecks: Not installed
2023-09-06 09:32:20,444:INFO:             xgboost: 1.7.6
2023-09-06 09:32:20,444:INFO:            catboost: 1.2.1
2023-09-06 09:32:20,444:INFO:              kmodes: Not installed
2023-09-06 09:32:20,444:INFO:             mlxtend: Not installed
2023-09-06 09:32:20,444:INFO:       statsforecast: Not installed
2023-09-06 09:32:20,444:INFO:        tune_sklearn: Not installed
2023-09-06 09:32:20,444:INFO:                 ray: Not installed
2023-09-06 09:32:20,444:INFO:            hyperopt: Not installed
2023-09-06 09:32:20,444:INFO:              optuna: 3.3.0
2023-09-06 09:32:20,444:INFO:               skopt: 0.9.0
2023-09-06 09:32:20,444:INFO:              mlflow: Not installed
2023-09-06 09:32:20,444:INFO:              gradio: Not installed
2023-09-06 09:32:20,444:INFO:             fastapi: Not installed
2023-09-06 09:32:20,444:INFO:             uvicorn: Not installed
2023-09-06 09:32:20,444:INFO:              m2cgen: Not installed
2023-09-06 09:32:20,444:INFO:           evidently: Not installed
2023-09-06 09:32:20,444:INFO:               fugue: Not installed
2023-09-06 09:32:20,444:INFO:           streamlit: Not installed
2023-09-06 09:32:20,444:INFO:             prophet: Not installed
2023-09-06 09:32:20,444:INFO:None
2023-09-06 09:32:20,444:INFO:Set up data.
2023-09-06 09:32:20,448:INFO:Set up train/test split.
2023-09-06 09:32:20,450:INFO:Set up index.
2023-09-06 09:32:20,451:INFO:Set up folding strategy.
2023-09-06 09:32:20,451:INFO:Assigning column types.
2023-09-06 09:32:20,453:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-06 09:32:20,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-06 09:32:20,483:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:32:20,506:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:20,507:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:22,976:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-06 09:32:22,976:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:32:22,995:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:22,997:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:22,997:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-06 09:32:23,027:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:32:23,046:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:23,047:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:23,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:32:23,096:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:23,097:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:23,098:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-06 09:32:23,146:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:23,148:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:23,196:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:23,198:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:23,214:INFO:Preparing preprocessing pipeline...
2023-09-06 09:32:23,215:INFO:Set up simple imputation.
2023-09-06 09:32:23,233:INFO:Finished creating preprocessing pipeline.
2023-09-06 09:32:23,235:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pclass', 'sex', 'age', 'fare',
                                             'name_title', 'family',
                                             'fare_per_family', 'cabin2',
                                             'etc'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-09-06 09:32:23,235:INFO:Creating final display dataframe.
2023-09-06 09:32:23,271:INFO:Setup _display_container:                     Description             Value
0                    Session id              1212
1                        Target          survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (712, 10)
6    Transformed test set shape         (179, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 3
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              0d64
2023-09-06 09:32:23,323:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:23,325:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:23,373:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:23,375:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:23,375:INFO:setup() successfully completed in 3.0s...............
2023-09-06 09:32:23,382:INFO:gpu_param set to False
2023-09-06 09:32:23,432:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:23,433:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:23,482:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:23,484:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:23,493:INFO:gpu_param set to False
2023-09-06 09:32:23,543:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:23,545:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:23,594:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:32:23,596:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:32:23,637:INFO:Initializing compare_models()
2023-09-06 09:32:23,638:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost'])
2023-09-06 09:32:23,638:INFO:Checking exceptions
2023-09-06 09:32:23,640:INFO:Preparing display monitor
2023-09-06 09:32:23,656:INFO:Initializing Logistic Regression
2023-09-06 09:32:23,657:INFO:Total runtime is 1.6629695892333984e-05 minutes
2023-09-06 09:32:23,659:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:23,659:INFO:Initializing create_model()
2023-09-06 09:32:23,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:23,660:INFO:Checking exceptions
2023-09-06 09:32:23,660:INFO:Importing libraries
2023-09-06 09:32:23,660:INFO:Copying training dataset
2023-09-06 09:32:23,662:INFO:Defining folds
2023-09-06 09:32:23,662:INFO:Declaring metric variables
2023-09-06 09:32:23,663:INFO:Importing untrained model
2023-09-06 09:32:23,665:INFO:Logistic Regression Imported successfully
2023-09-06 09:32:23,669:INFO:Starting cross validation
2023-09-06 09:32:23,670:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:25,403:INFO:Calculating mean and std
2023-09-06 09:32:25,404:INFO:Creating metrics dataframe
2023-09-06 09:32:25,460:INFO:Uploading results into container
2023-09-06 09:32:25,460:INFO:Uploading model into container now
2023-09-06 09:32:25,460:INFO:_master_model_container: 1
2023-09-06 09:32:25,460:INFO:_display_container: 2
2023-09-06 09:32:25,461:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1212, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-06 09:32:25,461:INFO:create_model() successfully completed......................................
2023-09-06 09:32:25,502:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:25,503:INFO:Creating metrics dataframe
2023-09-06 09:32:25,508:INFO:Initializing K Neighbors Classifier
2023-09-06 09:32:25,508:INFO:Total runtime is 0.03087592124938965 minutes
2023-09-06 09:32:25,510:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:25,510:INFO:Initializing create_model()
2023-09-06 09:32:25,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=knn, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:25,510:INFO:Checking exceptions
2023-09-06 09:32:25,510:INFO:Importing libraries
2023-09-06 09:32:25,510:INFO:Copying training dataset
2023-09-06 09:32:25,513:INFO:Defining folds
2023-09-06 09:32:25,513:INFO:Declaring metric variables
2023-09-06 09:32:25,515:INFO:Importing untrained model
2023-09-06 09:32:25,518:INFO:K Neighbors Classifier Imported successfully
2023-09-06 09:32:25,521:INFO:Starting cross validation
2023-09-06 09:32:25,522:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:26,945:INFO:Calculating mean and std
2023-09-06 09:32:26,945:INFO:Creating metrics dataframe
2023-09-06 09:32:26,993:INFO:Uploading results into container
2023-09-06 09:32:26,994:INFO:Uploading model into container now
2023-09-06 09:32:26,994:INFO:_master_model_container: 2
2023-09-06 09:32:26,994:INFO:_display_container: 2
2023-09-06 09:32:26,994:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-06 09:32:26,994:INFO:create_model() successfully completed......................................
2023-09-06 09:32:27,039:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:27,040:INFO:Creating metrics dataframe
2023-09-06 09:32:27,046:INFO:Initializing Naive Bayes
2023-09-06 09:32:27,046:INFO:Total runtime is 0.05650760730107625 minutes
2023-09-06 09:32:27,048:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:27,048:INFO:Initializing create_model()
2023-09-06 09:32:27,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=nb, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:27,048:INFO:Checking exceptions
2023-09-06 09:32:27,048:INFO:Importing libraries
2023-09-06 09:32:27,048:INFO:Copying training dataset
2023-09-06 09:32:27,051:INFO:Defining folds
2023-09-06 09:32:27,051:INFO:Declaring metric variables
2023-09-06 09:32:27,053:INFO:Importing untrained model
2023-09-06 09:32:27,055:INFO:Naive Bayes Imported successfully
2023-09-06 09:32:27,059:INFO:Starting cross validation
2023-09-06 09:32:27,059:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:28,465:INFO:Calculating mean and std
2023-09-06 09:32:28,466:INFO:Creating metrics dataframe
2023-09-06 09:32:28,522:INFO:Uploading results into container
2023-09-06 09:32:28,522:INFO:Uploading model into container now
2023-09-06 09:32:28,523:INFO:_master_model_container: 3
2023-09-06 09:32:28,523:INFO:_display_container: 2
2023-09-06 09:32:28,523:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-06 09:32:28,523:INFO:create_model() successfully completed......................................
2023-09-06 09:32:28,563:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:28,563:INFO:Creating metrics dataframe
2023-09-06 09:32:28,569:INFO:Initializing Decision Tree Classifier
2023-09-06 09:32:28,569:INFO:Total runtime is 0.08189771572748819 minutes
2023-09-06 09:32:28,571:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:28,571:INFO:Initializing create_model()
2023-09-06 09:32:28,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:28,571:INFO:Checking exceptions
2023-09-06 09:32:28,571:INFO:Importing libraries
2023-09-06 09:32:28,571:INFO:Copying training dataset
2023-09-06 09:32:28,574:INFO:Defining folds
2023-09-06 09:32:28,574:INFO:Declaring metric variables
2023-09-06 09:32:28,576:INFO:Importing untrained model
2023-09-06 09:32:28,578:INFO:Decision Tree Classifier Imported successfully
2023-09-06 09:32:28,582:INFO:Starting cross validation
2023-09-06 09:32:28,583:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:29,946:INFO:Calculating mean and std
2023-09-06 09:32:29,947:INFO:Creating metrics dataframe
2023-09-06 09:32:29,997:INFO:Uploading results into container
2023-09-06 09:32:29,997:INFO:Uploading model into container now
2023-09-06 09:32:29,998:INFO:_master_model_container: 4
2023-09-06 09:32:29,998:INFO:_display_container: 2
2023-09-06 09:32:29,998:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-06 09:32:29,998:INFO:create_model() successfully completed......................................
2023-09-06 09:32:30,038:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:30,038:INFO:Creating metrics dataframe
2023-09-06 09:32:30,044:INFO:Initializing SVM - Linear Kernel
2023-09-06 09:32:30,044:INFO:Total runtime is 0.10647282600402831 minutes
2023-09-06 09:32:30,046:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:30,046:INFO:Initializing create_model()
2023-09-06 09:32:30,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=svm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:30,046:INFO:Checking exceptions
2023-09-06 09:32:30,046:INFO:Importing libraries
2023-09-06 09:32:30,046:INFO:Copying training dataset
2023-09-06 09:32:30,049:INFO:Defining folds
2023-09-06 09:32:30,049:INFO:Declaring metric variables
2023-09-06 09:32:30,051:INFO:Importing untrained model
2023-09-06 09:32:30,053:INFO:SVM - Linear Kernel Imported successfully
2023-09-06 09:32:30,057:INFO:Starting cross validation
2023-09-06 09:32:30,058:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:31,408:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-06 09:32:31,408:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-06 09:32:31,507:INFO:Calculating mean and std
2023-09-06 09:32:31,508:INFO:Creating metrics dataframe
2023-09-06 09:32:31,563:INFO:Uploading results into container
2023-09-06 09:32:31,563:INFO:Uploading model into container now
2023-09-06 09:32:31,563:INFO:_master_model_container: 5
2023-09-06 09:32:31,563:INFO:_display_container: 2
2023-09-06 09:32:31,564:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1212, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-06 09:32:31,564:INFO:create_model() successfully completed......................................
2023-09-06 09:32:31,611:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:31,611:INFO:Creating metrics dataframe
2023-09-06 09:32:31,618:INFO:Initializing Ridge Classifier
2023-09-06 09:32:31,618:INFO:Total runtime is 0.13270851373672485 minutes
2023-09-06 09:32:31,620:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:31,620:INFO:Initializing create_model()
2023-09-06 09:32:31,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=ridge, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:31,620:INFO:Checking exceptions
2023-09-06 09:32:31,620:INFO:Importing libraries
2023-09-06 09:32:31,620:INFO:Copying training dataset
2023-09-06 09:32:31,623:INFO:Defining folds
2023-09-06 09:32:31,623:INFO:Declaring metric variables
2023-09-06 09:32:31,626:INFO:Importing untrained model
2023-09-06 09:32:31,628:INFO:Ridge Classifier Imported successfully
2023-09-06 09:32:31,632:INFO:Starting cross validation
2023-09-06 09:32:31,633:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:31,671:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 09:32:31,671:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 09:32:32,790:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 09:32:32,797:INFO:Calculating mean and std
2023-09-06 09:32:32,798:INFO:Creating metrics dataframe
2023-09-06 09:32:32,853:INFO:Uploading results into container
2023-09-06 09:32:32,853:INFO:Uploading model into container now
2023-09-06 09:32:32,853:INFO:_master_model_container: 6
2023-09-06 09:32:32,853:INFO:_display_container: 2
2023-09-06 09:32:32,854:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1212, solver='auto',
                tol=0.0001)
2023-09-06 09:32:32,854:INFO:create_model() successfully completed......................................
2023-09-06 09:32:32,895:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:32,895:INFO:Creating metrics dataframe
2023-09-06 09:32:32,901:INFO:Initializing Random Forest Classifier
2023-09-06 09:32:32,901:INFO:Total runtime is 0.15408852497736614 minutes
2023-09-06 09:32:32,903:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:32,903:INFO:Initializing create_model()
2023-09-06 09:32:32,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:32,904:INFO:Checking exceptions
2023-09-06 09:32:32,904:INFO:Importing libraries
2023-09-06 09:32:32,904:INFO:Copying training dataset
2023-09-06 09:32:32,907:INFO:Defining folds
2023-09-06 09:32:32,907:INFO:Declaring metric variables
2023-09-06 09:32:32,910:INFO:Importing untrained model
2023-09-06 09:32:32,912:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:32:32,917:INFO:Starting cross validation
2023-09-06 09:32:32,917:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:33,180:INFO:Calculating mean and std
2023-09-06 09:32:33,180:INFO:Creating metrics dataframe
2023-09-06 09:32:33,233:INFO:Uploading results into container
2023-09-06 09:32:33,233:INFO:Uploading model into container now
2023-09-06 09:32:33,233:INFO:_master_model_container: 7
2023-09-06 09:32:33,233:INFO:_display_container: 2
2023-09-06 09:32:33,234:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:32:33,234:INFO:create_model() successfully completed......................................
2023-09-06 09:32:33,273:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:33,273:INFO:Creating metrics dataframe
2023-09-06 09:32:33,280:INFO:Initializing Quadratic Discriminant Analysis
2023-09-06 09:32:33,280:INFO:Total runtime is 0.1604049841562907 minutes
2023-09-06 09:32:33,282:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:33,282:INFO:Initializing create_model()
2023-09-06 09:32:33,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=qda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:33,282:INFO:Checking exceptions
2023-09-06 09:32:33,282:INFO:Importing libraries
2023-09-06 09:32:33,282:INFO:Copying training dataset
2023-09-06 09:32:33,285:INFO:Defining folds
2023-09-06 09:32:33,285:INFO:Declaring metric variables
2023-09-06 09:32:33,287:INFO:Importing untrained model
2023-09-06 09:32:33,289:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-06 09:32:33,293:INFO:Starting cross validation
2023-09-06 09:32:33,293:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:33,435:INFO:Calculating mean and std
2023-09-06 09:32:33,435:INFO:Creating metrics dataframe
2023-09-06 09:32:33,488:INFO:Uploading results into container
2023-09-06 09:32:33,488:INFO:Uploading model into container now
2023-09-06 09:32:33,488:INFO:_master_model_container: 8
2023-09-06 09:32:33,488:INFO:_display_container: 2
2023-09-06 09:32:33,489:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-06 09:32:33,489:INFO:create_model() successfully completed......................................
2023-09-06 09:32:33,528:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:33,528:INFO:Creating metrics dataframe
2023-09-06 09:32:33,534:INFO:Initializing Ada Boost Classifier
2023-09-06 09:32:33,535:INFO:Total runtime is 0.164661180973053 minutes
2023-09-06 09:32:33,536:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:33,537:INFO:Initializing create_model()
2023-09-06 09:32:33,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=ada, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:33,537:INFO:Checking exceptions
2023-09-06 09:32:33,537:INFO:Importing libraries
2023-09-06 09:32:33,537:INFO:Copying training dataset
2023-09-06 09:32:33,540:INFO:Defining folds
2023-09-06 09:32:33,540:INFO:Declaring metric variables
2023-09-06 09:32:33,542:INFO:Importing untrained model
2023-09-06 09:32:33,544:INFO:Ada Boost Classifier Imported successfully
2023-09-06 09:32:33,548:INFO:Starting cross validation
2023-09-06 09:32:33,549:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:33,768:INFO:Calculating mean and std
2023-09-06 09:32:33,768:INFO:Creating metrics dataframe
2023-09-06 09:32:33,824:INFO:Uploading results into container
2023-09-06 09:32:33,824:INFO:Uploading model into container now
2023-09-06 09:32:33,825:INFO:_master_model_container: 9
2023-09-06 09:32:33,825:INFO:_display_container: 2
2023-09-06 09:32:33,825:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1212)
2023-09-06 09:32:33,825:INFO:create_model() successfully completed......................................
2023-09-06 09:32:33,866:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:33,867:INFO:Creating metrics dataframe
2023-09-06 09:32:33,873:INFO:Initializing Gradient Boosting Classifier
2023-09-06 09:32:33,873:INFO:Total runtime is 0.17028380632400514 minutes
2023-09-06 09:32:33,876:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:33,876:INFO:Initializing create_model()
2023-09-06 09:32:33,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=gbc, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:33,876:INFO:Checking exceptions
2023-09-06 09:32:33,876:INFO:Importing libraries
2023-09-06 09:32:33,876:INFO:Copying training dataset
2023-09-06 09:32:33,879:INFO:Defining folds
2023-09-06 09:32:33,880:INFO:Declaring metric variables
2023-09-06 09:32:33,882:INFO:Importing untrained model
2023-09-06 09:32:33,884:INFO:Gradient Boosting Classifier Imported successfully
2023-09-06 09:32:33,888:INFO:Starting cross validation
2023-09-06 09:32:33,888:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:34,119:INFO:Calculating mean and std
2023-09-06 09:32:34,119:INFO:Creating metrics dataframe
2023-09-06 09:32:34,171:INFO:Uploading results into container
2023-09-06 09:32:34,171:INFO:Uploading model into container now
2023-09-06 09:32:34,171:INFO:_master_model_container: 10
2023-09-06 09:32:34,171:INFO:_display_container: 2
2023-09-06 09:32:34,172:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-06 09:32:34,172:INFO:create_model() successfully completed......................................
2023-09-06 09:32:34,213:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:34,213:INFO:Creating metrics dataframe
2023-09-06 09:32:34,220:INFO:Initializing Linear Discriminant Analysis
2023-09-06 09:32:34,220:INFO:Total runtime is 0.17606832186381025 minutes
2023-09-06 09:32:34,222:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:34,222:INFO:Initializing create_model()
2023-09-06 09:32:34,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=lda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:34,222:INFO:Checking exceptions
2023-09-06 09:32:34,222:INFO:Importing libraries
2023-09-06 09:32:34,222:INFO:Copying training dataset
2023-09-06 09:32:34,225:INFO:Defining folds
2023-09-06 09:32:34,225:INFO:Declaring metric variables
2023-09-06 09:32:34,227:INFO:Importing untrained model
2023-09-06 09:32:34,231:INFO:Linear Discriminant Analysis Imported successfully
2023-09-06 09:32:34,235:INFO:Starting cross validation
2023-09-06 09:32:34,236:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:34,373:INFO:Calculating mean and std
2023-09-06 09:32:34,373:INFO:Creating metrics dataframe
2023-09-06 09:32:34,425:INFO:Uploading results into container
2023-09-06 09:32:34,426:INFO:Uploading model into container now
2023-09-06 09:32:34,426:INFO:_master_model_container: 11
2023-09-06 09:32:34,426:INFO:_display_container: 2
2023-09-06 09:32:34,426:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-06 09:32:34,426:INFO:create_model() successfully completed......................................
2023-09-06 09:32:34,466:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:34,466:INFO:Creating metrics dataframe
2023-09-06 09:32:34,473:INFO:Initializing Extra Trees Classifier
2023-09-06 09:32:34,474:INFO:Total runtime is 0.1803121368090312 minutes
2023-09-06 09:32:34,476:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:34,476:INFO:Initializing create_model()
2023-09-06 09:32:34,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=et, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:34,476:INFO:Checking exceptions
2023-09-06 09:32:34,476:INFO:Importing libraries
2023-09-06 09:32:34,476:INFO:Copying training dataset
2023-09-06 09:32:34,479:INFO:Defining folds
2023-09-06 09:32:34,479:INFO:Declaring metric variables
2023-09-06 09:32:34,481:INFO:Importing untrained model
2023-09-06 09:32:34,483:INFO:Extra Trees Classifier Imported successfully
2023-09-06 09:32:34,487:INFO:Starting cross validation
2023-09-06 09:32:34,487:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:34,770:INFO:Calculating mean and std
2023-09-06 09:32:34,770:INFO:Creating metrics dataframe
2023-09-06 09:32:34,818:INFO:Uploading results into container
2023-09-06 09:32:34,819:INFO:Uploading model into container now
2023-09-06 09:32:34,819:INFO:_master_model_container: 12
2023-09-06 09:32:34,819:INFO:_display_container: 2
2023-09-06 09:32:34,819:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:32:34,819:INFO:create_model() successfully completed......................................
2023-09-06 09:32:34,859:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:34,859:INFO:Creating metrics dataframe
2023-09-06 09:32:34,866:INFO:Initializing Extreme Gradient Boosting
2023-09-06 09:32:34,866:INFO:Total runtime is 0.1868446707725525 minutes
2023-09-06 09:32:34,868:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:34,868:INFO:Initializing create_model()
2023-09-06 09:32:34,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=xgboost, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:34,868:INFO:Checking exceptions
2023-09-06 09:32:34,868:INFO:Importing libraries
2023-09-06 09:32:34,869:INFO:Copying training dataset
2023-09-06 09:32:34,871:INFO:Defining folds
2023-09-06 09:32:34,871:INFO:Declaring metric variables
2023-09-06 09:32:34,873:INFO:Importing untrained model
2023-09-06 09:32:34,876:INFO:Extreme Gradient Boosting Imported successfully
2023-09-06 09:32:34,880:INFO:Starting cross validation
2023-09-06 09:32:34,880:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:35,072:INFO:Calculating mean and std
2023-09-06 09:32:35,073:INFO:Creating metrics dataframe
2023-09-06 09:32:35,127:INFO:Uploading results into container
2023-09-06 09:32:35,127:INFO:Uploading model into container now
2023-09-06 09:32:35,127:INFO:_master_model_container: 13
2023-09-06 09:32:35,127:INFO:_display_container: 2
2023-09-06 09:32:35,128:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-06 09:32:35,128:INFO:create_model() successfully completed......................................
2023-09-06 09:32:35,168:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:35,168:INFO:Creating metrics dataframe
2023-09-06 09:32:35,174:INFO:Initializing Light Gradient Boosting Machine
2023-09-06 09:32:35,174:INFO:Total runtime is 0.19198215007781985 minutes
2023-09-06 09:32:35,176:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:35,176:INFO:Initializing create_model()
2023-09-06 09:32:35,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:35,176:INFO:Checking exceptions
2023-09-06 09:32:35,176:INFO:Importing libraries
2023-09-06 09:32:35,176:INFO:Copying training dataset
2023-09-06 09:32:35,179:INFO:Defining folds
2023-09-06 09:32:35,179:INFO:Declaring metric variables
2023-09-06 09:32:35,182:INFO:Importing untrained model
2023-09-06 09:32:35,184:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-06 09:32:35,187:INFO:Starting cross validation
2023-09-06 09:32:35,188:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:35,372:INFO:Calculating mean and std
2023-09-06 09:32:35,373:INFO:Creating metrics dataframe
2023-09-06 09:32:35,426:INFO:Uploading results into container
2023-09-06 09:32:35,426:INFO:Uploading model into container now
2023-09-06 09:32:35,426:INFO:_master_model_container: 14
2023-09-06 09:32:35,426:INFO:_display_container: 2
2023-09-06 09:32:35,427:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-06 09:32:35,427:INFO:create_model() successfully completed......................................
2023-09-06 09:32:35,466:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:35,466:INFO:Creating metrics dataframe
2023-09-06 09:32:35,474:INFO:Initializing Dummy Classifier
2023-09-06 09:32:35,474:INFO:Total runtime is 0.1969725092252096 minutes
2023-09-06 09:32:35,476:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:35,476:INFO:Initializing create_model()
2023-09-06 09:32:35,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=dummy, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA2324E160>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:35,476:INFO:Checking exceptions
2023-09-06 09:32:35,476:INFO:Importing libraries
2023-09-06 09:32:35,476:INFO:Copying training dataset
2023-09-06 09:32:35,479:INFO:Defining folds
2023-09-06 09:32:35,479:INFO:Declaring metric variables
2023-09-06 09:32:35,482:INFO:Importing untrained model
2023-09-06 09:32:35,484:INFO:Dummy Classifier Imported successfully
2023-09-06 09:32:35,489:INFO:Starting cross validation
2023-09-06 09:32:35,489:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:35,536:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-06 09:32:35,536:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-06 09:32:35,642:INFO:Calculating mean and std
2023-09-06 09:32:35,642:INFO:Creating metrics dataframe
2023-09-06 09:32:35,691:INFO:Uploading results into container
2023-09-06 09:32:35,692:INFO:Uploading model into container now
2023-09-06 09:32:35,692:INFO:_master_model_container: 15
2023-09-06 09:32:35,692:INFO:_display_container: 2
2023-09-06 09:32:35,692:INFO:DummyClassifier(constant=None, random_state=1212, strategy='prior')
2023-09-06 09:32:35,692:INFO:create_model() successfully completed......................................
2023-09-06 09:32:35,732:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:35,732:INFO:Creating metrics dataframe
2023-09-06 09:32:35,744:INFO:Initializing create_model()
2023-09-06 09:32:35,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:35,745:INFO:Checking exceptions
2023-09-06 09:32:35,746:INFO:Importing libraries
2023-09-06 09:32:35,746:INFO:Copying training dataset
2023-09-06 09:32:35,748:INFO:Defining folds
2023-09-06 09:32:35,748:INFO:Declaring metric variables
2023-09-06 09:32:35,748:INFO:Importing untrained model
2023-09-06 09:32:35,748:INFO:Declaring custom model
2023-09-06 09:32:35,748:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-06 09:32:35,749:INFO:Cross validation set to False
2023-09-06 09:32:35,749:INFO:Fitting Model
2023-09-06 09:32:35,761:INFO:[LightGBM] [Info] Number of positive: 273, number of negative: 439
2023-09-06 09:32:35,762:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.
2023-09-06 09:32:35,762:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-09-06 09:32:35,762:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-09-06 09:32:35,762:INFO:[LightGBM] [Info] Total Bins 274
2023-09-06 09:32:35,762:INFO:[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 9
2023-09-06 09:32:35,762:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028
2023-09-06 09:32:35,762:INFO:[LightGBM] [Info] Start training from score -0.475028
2023-09-06 09:32:35,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:32:35,847:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-06 09:32:35,847:INFO:create_model() successfully completed......................................
2023-09-06 09:32:35,902:INFO:Initializing create_model()
2023-09-06 09:32:35,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:35,902:INFO:Checking exceptions
2023-09-06 09:32:35,903:INFO:Importing libraries
2023-09-06 09:32:35,903:INFO:Copying training dataset
2023-09-06 09:32:35,905:INFO:Defining folds
2023-09-06 09:32:35,906:INFO:Declaring metric variables
2023-09-06 09:32:35,906:INFO:Importing untrained model
2023-09-06 09:32:35,906:INFO:Declaring custom model
2023-09-06 09:32:35,906:INFO:Gradient Boosting Classifier Imported successfully
2023-09-06 09:32:35,907:INFO:Cross validation set to False
2023-09-06 09:32:35,907:INFO:Fitting Model
2023-09-06 09:32:36,029:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-06 09:32:36,029:INFO:create_model() successfully completed......................................
2023-09-06 09:32:36,074:INFO:Initializing create_model()
2023-09-06 09:32:36,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:36,074:INFO:Checking exceptions
2023-09-06 09:32:36,075:INFO:Importing libraries
2023-09-06 09:32:36,075:INFO:Copying training dataset
2023-09-06 09:32:36,078:INFO:Defining folds
2023-09-06 09:32:36,078:INFO:Declaring metric variables
2023-09-06 09:32:36,078:INFO:Importing untrained model
2023-09-06 09:32:36,078:INFO:Declaring custom model
2023-09-06 09:32:36,079:INFO:Extreme Gradient Boosting Imported successfully
2023-09-06 09:32:36,079:INFO:Cross validation set to False
2023-09-06 09:32:36,079:INFO:Fitting Model
2023-09-06 09:32:36,176:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-06 09:32:36,176:INFO:create_model() successfully completed......................................
2023-09-06 09:32:36,230:INFO:Initializing create_model()
2023-09-06 09:32:36,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:36,231:INFO:Checking exceptions
2023-09-06 09:32:36,232:INFO:Importing libraries
2023-09-06 09:32:36,232:INFO:Copying training dataset
2023-09-06 09:32:36,234:INFO:Defining folds
2023-09-06 09:32:36,234:INFO:Declaring metric variables
2023-09-06 09:32:36,235:INFO:Importing untrained model
2023-09-06 09:32:36,235:INFO:Declaring custom model
2023-09-06 09:32:36,235:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:32:36,235:INFO:Cross validation set to False
2023-09-06 09:32:36,235:INFO:Fitting Model
2023-09-06 09:32:36,450:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:32:36,450:INFO:create_model() successfully completed......................................
2023-09-06 09:32:36,508:INFO:_master_model_container: 15
2023-09-06 09:32:36,508:INFO:_display_container: 2
2023-09-06 09:32:36,509:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)]
2023-09-06 09:32:36,509:INFO:compare_models() successfully completed......................................
2023-09-06 09:32:36,555:INFO:Initializing create_model()
2023-09-06 09:32:36,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'n_estimators': 300, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-06 09:32:36,556:INFO:Checking exceptions
2023-09-06 09:32:36,566:INFO:Importing libraries
2023-09-06 09:32:36,566:INFO:Copying training dataset
2023-09-06 09:32:36,568:INFO:Defining folds
2023-09-06 09:32:36,568:INFO:Declaring metric variables
2023-09-06 09:32:36,570:INFO:Importing untrained model
2023-09-06 09:32:36,573:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:32:36,577:INFO:Starting cross validation
2023-09-06 09:32:36,578:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:37,009:INFO:Calculating mean and std
2023-09-06 09:32:37,009:INFO:Creating metrics dataframe
2023-09-06 09:32:37,012:INFO:Finalizing model
2023-09-06 09:32:37,152:INFO:Uploading results into container
2023-09-06 09:32:37,153:INFO:Uploading model into container now
2023-09-06 09:32:37,158:INFO:_master_model_container: 16
2023-09-06 09:32:37,158:INFO:_display_container: 3
2023-09-06 09:32:37,158:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:32:37,158:INFO:create_model() successfully completed......................................
2023-09-06 09:32:37,217:INFO:Initializing tune_model()
2023-09-06 09:32:37,217:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 300], 'max_depth': [10, 20], 'min_samples_split': [1, 2], 'min_samples_leaf': [1, 2]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>)
2023-09-06 09:32:37,217:INFO:Checking exceptions
2023-09-06 09:32:37,230:INFO:Copying training dataset
2023-09-06 09:32:37,232:INFO:Checking base model
2023-09-06 09:32:37,232:INFO:Base model : Random Forest Classifier
2023-09-06 09:32:37,234:INFO:Declaring metric variables
2023-09-06 09:32:37,236:INFO:Defining Hyperparameters
2023-09-06 09:32:37,278:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 300], 'actual_estimator__max_depth': [10, 20], 'actual_estimator__min_samples_split': [1, 2], 'actual_estimator__min_samples_leaf': [1, 2]}
2023-09-06 09:32:37,278:INFO:Tuning with n_jobs=-1
2023-09-06 09:32:37,278:INFO:Initializing RandomizedSearchCV
2023-09-06 09:32:39,044:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 10}
2023-09-06 09:32:39,045:INFO:Hyperparameter search completed
2023-09-06 09:32:39,045:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:39,045:INFO:Initializing create_model()
2023-09-06 09:32:39,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA250B8FD0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10})
2023-09-06 09:32:39,045:INFO:Checking exceptions
2023-09-06 09:32:39,045:INFO:Importing libraries
2023-09-06 09:32:39,045:INFO:Copying training dataset
2023-09-06 09:32:39,048:INFO:Defining folds
2023-09-06 09:32:39,048:INFO:Declaring metric variables
2023-09-06 09:32:39,049:INFO:Importing untrained model
2023-09-06 09:32:39,050:INFO:Declaring custom model
2023-09-06 09:32:39,052:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:32:39,055:INFO:Starting cross validation
2023-09-06 09:32:39,056:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:39,324:INFO:Calculating mean and std
2023-09-06 09:32:39,324:INFO:Creating metrics dataframe
2023-09-06 09:32:39,328:INFO:Finalizing model
2023-09-06 09:32:39,556:INFO:Uploading results into container
2023-09-06 09:32:39,557:INFO:Uploading model into container now
2023-09-06 09:32:39,557:INFO:_master_model_container: 17
2023-09-06 09:32:39,557:INFO:_display_container: 4
2023-09-06 09:32:39,557:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:32:39,557:INFO:create_model() successfully completed......................................
2023-09-06 09:32:39,598:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:39,598:INFO:choose_better activated
2023-09-06 09:32:39,600:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:39,601:INFO:Initializing create_model()
2023-09-06 09:32:39,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:39,601:INFO:Checking exceptions
2023-09-06 09:32:39,602:INFO:Importing libraries
2023-09-06 09:32:39,602:INFO:Copying training dataset
2023-09-06 09:32:39,604:INFO:Defining folds
2023-09-06 09:32:39,604:INFO:Declaring metric variables
2023-09-06 09:32:39,604:INFO:Importing untrained model
2023-09-06 09:32:39,604:INFO:Declaring custom model
2023-09-06 09:32:39,604:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:32:39,605:INFO:Starting cross validation
2023-09-06 09:32:39,605:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:40,037:INFO:Calculating mean and std
2023-09-06 09:32:40,037:INFO:Creating metrics dataframe
2023-09-06 09:32:40,038:INFO:Finalizing model
2023-09-06 09:32:40,152:INFO:Uploading results into container
2023-09-06 09:32:40,153:INFO:Uploading model into container now
2023-09-06 09:32:40,153:INFO:_master_model_container: 18
2023-09-06 09:32:40,153:INFO:_display_container: 5
2023-09-06 09:32:40,153:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:32:40,153:INFO:create_model() successfully completed......................................
2023-09-06 09:32:40,195:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:40,196:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8258
2023-09-06 09:32:40,196:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8146
2023-09-06 09:32:40,196:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-06 09:32:40,196:INFO:choose_better completed
2023-09-06 09:32:40,196:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-06 09:32:40,201:INFO:_master_model_container: 18
2023-09-06 09:32:40,201:INFO:_display_container: 4
2023-09-06 09:32:40,202:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:32:40,202:INFO:tune_model() successfully completed......................................
2023-09-06 09:32:40,328:INFO:Initializing tune_model()
2023-09-06 09:32:40,328:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>)
2023-09-06 09:32:40,328:INFO:Checking exceptions
2023-09-06 09:32:40,328:INFO:Soft dependency imported: skopt: 0.9.0
2023-09-06 09:32:40,366:INFO:Copying training dataset
2023-09-06 09:32:40,368:INFO:Checking base model
2023-09-06 09:32:40,368:INFO:Base model : Random Forest Classifier
2023-09-06 09:32:40,370:INFO:Declaring metric variables
2023-09-06 09:32:40,373:INFO:Defining Hyperparameters
2023-09-06 09:32:40,417:INFO:Tuning with n_jobs=-1
2023-09-06 09:32:40,420:INFO:Initializing skopt.BayesSearchCV
2023-09-06 09:32:43,849:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', False), ('actual_estimator__class_weight', 'balanced'), ('actual_estimator__criterion', 'entropy'), ('actual_estimator__max_depth', 9), ('actual_estimator__max_features', 0.6572967088396628), ('actual_estimator__min_impurity_decrease', 0.0001578347418897214), ('actual_estimator__min_samples_leaf', 3), ('actual_estimator__min_samples_split', 5), ('actual_estimator__n_estimators', 67)])
2023-09-06 09:32:43,849:INFO:Hyperparameter search completed
2023-09-06 09:32:43,849:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:43,850:INFO:Initializing create_model()
2023-09-06 09:32:43,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA24C8BD00>, model_only=True, return_train_score=False, kwargs={'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_features': 0.6572967088396628, 'min_impurity_decrease': 0.0001578347418897214, 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 67})
2023-09-06 09:32:43,850:INFO:Checking exceptions
2023-09-06 09:32:43,850:INFO:Importing libraries
2023-09-06 09:32:43,850:INFO:Copying training dataset
2023-09-06 09:32:43,852:INFO:Defining folds
2023-09-06 09:32:43,852:INFO:Declaring metric variables
2023-09-06 09:32:43,854:INFO:Importing untrained model
2023-09-06 09:32:43,854:INFO:Declaring custom model
2023-09-06 09:32:43,857:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:32:43,861:INFO:Starting cross validation
2023-09-06 09:32:43,862:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:44,157:INFO:Calculating mean and std
2023-09-06 09:32:44,158:INFO:Creating metrics dataframe
2023-09-06 09:32:44,161:INFO:Finalizing model
2023-09-06 09:32:44,291:INFO:Uploading results into container
2023-09-06 09:32:44,291:INFO:Uploading model into container now
2023-09-06 09:32:44,292:INFO:_master_model_container: 19
2023-09-06 09:32:44,292:INFO:_display_container: 5
2023-09-06 09:32:44,292:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=9,
                       max_features=0.6572967088396628, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.0001578347418897214,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=67, n_jobs=-1,
                       oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-06 09:32:44,292:INFO:create_model() successfully completed......................................
2023-09-06 09:32:44,334:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:44,334:INFO:choose_better activated
2023-09-06 09:32:44,336:INFO:SubProcess create_model() called ==================================
2023-09-06 09:32:44,337:INFO:Initializing create_model()
2023-09-06 09:32:44,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA226BEF40>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:32:44,337:INFO:Checking exceptions
2023-09-06 09:32:44,338:INFO:Importing libraries
2023-09-06 09:32:44,338:INFO:Copying training dataset
2023-09-06 09:32:44,340:INFO:Defining folds
2023-09-06 09:32:44,340:INFO:Declaring metric variables
2023-09-06 09:32:44,340:INFO:Importing untrained model
2023-09-06 09:32:44,340:INFO:Declaring custom model
2023-09-06 09:32:44,340:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:32:44,341:INFO:Starting cross validation
2023-09-06 09:32:44,341:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:32:44,776:INFO:Calculating mean and std
2023-09-06 09:32:44,776:INFO:Creating metrics dataframe
2023-09-06 09:32:44,777:INFO:Finalizing model
2023-09-06 09:32:44,890:INFO:Uploading results into container
2023-09-06 09:32:44,890:INFO:Uploading model into container now
2023-09-06 09:32:44,890:INFO:_master_model_container: 20
2023-09-06 09:32:44,890:INFO:_display_container: 6
2023-09-06 09:32:44,890:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:32:44,890:INFO:create_model() successfully completed......................................
2023-09-06 09:32:44,932:INFO:SubProcess create_model() end ==================================
2023-09-06 09:32:44,932:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8258
2023-09-06 09:32:44,933:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=9,
                       max_features=0.6572967088396628, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.0001578347418897214,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=67, n_jobs=-1,
                       oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.8244
2023-09-06 09:32:44,933:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-06 09:32:44,933:INFO:choose_better completed
2023-09-06 09:32:44,933:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-06 09:32:44,938:INFO:_master_model_container: 20
2023-09-06 09:32:44,938:INFO:_display_container: 5
2023-09-06 09:32:44,938:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:32:44,938:INFO:tune_model() successfully completed......................................
2023-09-06 09:36:32,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:36:32,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:36:32,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:36:32,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-06 09:36:33,075:INFO:PyCaret ClassificationExperiment
2023-09-06 09:36:33,076:INFO:Logging name: clf-default-name
2023-09-06 09:36:33,076:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-06 09:36:33,076:INFO:version 3.0.4
2023-09-06 09:36:33,076:INFO:Initializing setup()
2023-09-06 09:36:33,076:INFO:self.USI: 3649
2023-09-06 09:36:33,076:INFO:self._variable_keys: {'fold_shuffle_param', '_ml_usecase', 'X_test', 'USI', 'n_jobs_param', 'html_param', 'X', 'idx', 'y', 'y_test', 'logging_param', 'target_param', 'fold_groups_param', 'gpu_n_jobs_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'fold_generator', 'memory', '_available_plots', 'fix_imbalance', 'is_multiclass', 'data', 'X_train', 'exp_id', 'seed', 'pipeline', 'y_train'}
2023-09-06 09:36:33,076:INFO:Checking environment
2023-09-06 09:36:33,076:INFO:python_version: 3.8.8
2023-09-06 09:36:33,076:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-06 09:36:33,076:INFO:machine: AMD64
2023-09-06 09:36:33,076:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-06 09:36:33,077:INFO:Memory: svmem(total=16822788096, available=6618652672, percent=60.7, used=10204135424, free=6618652672)
2023-09-06 09:36:33,077:INFO:Physical Core: 8
2023-09-06 09:36:33,077:INFO:Logical Core: 16
2023-09-06 09:36:33,077:INFO:Checking libraries
2023-09-06 09:36:33,078:INFO:System:
2023-09-06 09:36:33,078:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-06 09:36:33,078:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-06 09:36:33,078:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-06 09:36:33,078:INFO:PyCaret required dependencies:
2023-09-06 09:36:33,100:INFO:                 pip: 22.3.1
2023-09-06 09:36:33,100:INFO:          setuptools: 65.5.1
2023-09-06 09:36:33,100:INFO:             pycaret: 3.0.4
2023-09-06 09:36:33,100:INFO:             IPython: 8.12.2
2023-09-06 09:36:33,100:INFO:          ipywidgets: 8.0.7
2023-09-06 09:36:33,100:INFO:                tqdm: 4.66.1
2023-09-06 09:36:33,100:INFO:               numpy: 1.23.5
2023-09-06 09:36:33,100:INFO:              pandas: 1.5.3
2023-09-06 09:36:33,100:INFO:              jinja2: 3.1.2
2023-09-06 09:36:33,100:INFO:               scipy: 1.10.1
2023-09-06 09:36:33,100:INFO:              joblib: 1.3.2
2023-09-06 09:36:33,100:INFO:             sklearn: 1.2.2
2023-09-06 09:36:33,100:INFO:                pyod: 1.1.0
2023-09-06 09:36:33,100:INFO:            imblearn: 0.11.0
2023-09-06 09:36:33,100:INFO:   category_encoders: 2.6.2
2023-09-06 09:36:33,100:INFO:            lightgbm: 4.0.0
2023-09-06 09:36:33,100:INFO:               numba: 0.57.1
2023-09-06 09:36:33,100:INFO:            requests: 2.31.0
2023-09-06 09:36:33,100:INFO:          matplotlib: 3.7.2
2023-09-06 09:36:33,101:INFO:          scikitplot: 0.3.7
2023-09-06 09:36:33,101:INFO:         yellowbrick: 1.5
2023-09-06 09:36:33,101:INFO:              plotly: 5.15.0
2023-09-06 09:36:33,101:INFO:    plotly-resampler: Not installed
2023-09-06 09:36:33,101:INFO:             kaleido: 0.2.1
2023-09-06 09:36:33,101:INFO:           schemdraw: 0.15
2023-09-06 09:36:33,101:INFO:         statsmodels: 0.14.0
2023-09-06 09:36:33,101:INFO:              sktime: 0.22.0
2023-09-06 09:36:33,101:INFO:               tbats: 1.1.3
2023-09-06 09:36:33,101:INFO:            pmdarima: 2.0.3
2023-09-06 09:36:33,101:INFO:              psutil: 5.9.5
2023-09-06 09:36:33,101:INFO:          markupsafe: 2.1.3
2023-09-06 09:36:33,101:INFO:             pickle5: Not installed
2023-09-06 09:36:33,101:INFO:         cloudpickle: 2.2.1
2023-09-06 09:36:33,101:INFO:         deprecation: 2.1.0
2023-09-06 09:36:33,101:INFO:              xxhash: 3.3.0
2023-09-06 09:36:33,101:INFO:           wurlitzer: Not installed
2023-09-06 09:36:33,101:INFO:PyCaret optional dependencies:
2023-09-06 09:36:33,105:INFO:                shap: Not installed
2023-09-06 09:36:33,105:INFO:           interpret: Not installed
2023-09-06 09:36:33,105:INFO:                umap: Not installed
2023-09-06 09:36:33,105:INFO:    pandas_profiling: 4.5.1
2023-09-06 09:36:33,105:INFO:  explainerdashboard: Not installed
2023-09-06 09:36:33,105:INFO:             autoviz: Not installed
2023-09-06 09:36:33,106:INFO:           fairlearn: Not installed
2023-09-06 09:36:33,106:INFO:          deepchecks: Not installed
2023-09-06 09:36:33,106:INFO:             xgboost: 1.7.6
2023-09-06 09:36:33,106:INFO:            catboost: 1.2.1
2023-09-06 09:36:33,106:INFO:              kmodes: Not installed
2023-09-06 09:36:33,106:INFO:             mlxtend: Not installed
2023-09-06 09:36:33,106:INFO:       statsforecast: Not installed
2023-09-06 09:36:33,106:INFO:        tune_sklearn: Not installed
2023-09-06 09:36:33,106:INFO:                 ray: Not installed
2023-09-06 09:36:33,106:INFO:            hyperopt: Not installed
2023-09-06 09:36:33,106:INFO:              optuna: 3.3.0
2023-09-06 09:36:33,106:INFO:               skopt: 0.9.0
2023-09-06 09:36:33,106:INFO:              mlflow: Not installed
2023-09-06 09:36:33,106:INFO:              gradio: Not installed
2023-09-06 09:36:33,106:INFO:             fastapi: Not installed
2023-09-06 09:36:33,106:INFO:             uvicorn: Not installed
2023-09-06 09:36:33,106:INFO:              m2cgen: Not installed
2023-09-06 09:36:33,106:INFO:           evidently: Not installed
2023-09-06 09:36:33,106:INFO:               fugue: Not installed
2023-09-06 09:36:33,106:INFO:           streamlit: Not installed
2023-09-06 09:36:33,106:INFO:             prophet: Not installed
2023-09-06 09:36:33,106:INFO:None
2023-09-06 09:36:33,106:INFO:Set up data.
2023-09-06 09:36:33,109:INFO:Set up train/test split.
2023-09-06 09:36:33,111:INFO:Set up index.
2023-09-06 09:36:33,111:INFO:Set up folding strategy.
2023-09-06 09:36:33,111:INFO:Assigning column types.
2023-09-06 09:36:33,113:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-06 09:36:33,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-06 09:36:33,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:36:33,164:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:36:33,179:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:36:33,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-06 09:36:33,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:36:33,237:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:36:33,239:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:36:33,239:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-06 09:36:33,268:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:36:33,286:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:36:33,288:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:36:33,316:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-06 09:36:33,334:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:36:33,336:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:36:33,336:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-06 09:36:33,384:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:36:33,385:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:36:33,433:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:36:33,434:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:36:33,436:INFO:Preparing preprocessing pipeline...
2023-09-06 09:36:33,436:INFO:Set up simple imputation.
2023-09-06 09:36:33,445:INFO:Finished creating preprocessing pipeline.
2023-09-06 09:36:33,447:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pregnancies', 'glucose',
                                             'bloodpressure', 'skinthickness',
                                             'insulin', 'bmi', 'diabet',
                                             'age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-09-06 09:36:33,447:INFO:Creating final display dataframe.
2023-09-06 09:36:33,477:INFO:Setup _display_container:                     Description             Value
0                    Session id              1212
1                        Target           outcome
2                   Target type            Binary
3           Original data shape          (755, 9)
4        Transformed data shape          (755, 9)
5   Transformed train set shape          (604, 9)
6    Transformed test set shape          (151, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 3
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3649
2023-09-06 09:36:33,527:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:36:33,529:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:36:33,576:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-06 09:36:33,577:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-06 09:36:33,578:INFO:setup() successfully completed in 0.54s...............
2023-09-06 09:36:33,578:INFO:Initializing compare_models()
2023-09-06 09:36:33,578:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost'])
2023-09-06 09:36:33,578:INFO:Checking exceptions
2023-09-06 09:36:33,580:INFO:Preparing display monitor
2023-09-06 09:36:33,594:INFO:Initializing Logistic Regression
2023-09-06 09:36:33,594:INFO:Total runtime is 0.0 minutes
2023-09-06 09:36:33,596:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:33,596:INFO:Initializing create_model()
2023-09-06 09:36:33,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:33,596:INFO:Checking exceptions
2023-09-06 09:36:33,597:INFO:Importing libraries
2023-09-06 09:36:33,597:INFO:Copying training dataset
2023-09-06 09:36:33,599:INFO:Defining folds
2023-09-06 09:36:33,599:INFO:Declaring metric variables
2023-09-06 09:36:33,600:INFO:Importing untrained model
2023-09-06 09:36:33,602:INFO:Logistic Regression Imported successfully
2023-09-06 09:36:33,606:INFO:Starting cross validation
2023-09-06 09:36:33,607:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:35,323:INFO:Calculating mean and std
2023-09-06 09:36:35,324:INFO:Creating metrics dataframe
2023-09-06 09:36:35,378:INFO:Uploading results into container
2023-09-06 09:36:35,378:INFO:Uploading model into container now
2023-09-06 09:36:35,378:INFO:_master_model_container: 1
2023-09-06 09:36:35,378:INFO:_display_container: 2
2023-09-06 09:36:35,379:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1212, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-06 09:36:35,379:INFO:create_model() successfully completed......................................
2023-09-06 09:36:35,427:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:35,427:INFO:Creating metrics dataframe
2023-09-06 09:36:35,432:INFO:Initializing K Neighbors Classifier
2023-09-06 09:36:35,433:INFO:Total runtime is 0.030653313795725504 minutes
2023-09-06 09:36:35,434:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:35,434:INFO:Initializing create_model()
2023-09-06 09:36:35,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=knn, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:35,435:INFO:Checking exceptions
2023-09-06 09:36:35,435:INFO:Importing libraries
2023-09-06 09:36:35,435:INFO:Copying training dataset
2023-09-06 09:36:35,437:INFO:Defining folds
2023-09-06 09:36:35,437:INFO:Declaring metric variables
2023-09-06 09:36:35,439:INFO:Importing untrained model
2023-09-06 09:36:35,441:INFO:K Neighbors Classifier Imported successfully
2023-09-06 09:36:35,445:INFO:Starting cross validation
2023-09-06 09:36:35,446:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:36,853:INFO:Calculating mean and std
2023-09-06 09:36:36,854:INFO:Creating metrics dataframe
2023-09-06 09:36:36,905:INFO:Uploading results into container
2023-09-06 09:36:36,905:INFO:Uploading model into container now
2023-09-06 09:36:36,906:INFO:_master_model_container: 2
2023-09-06 09:36:36,906:INFO:_display_container: 2
2023-09-06 09:36:36,906:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-06 09:36:36,906:INFO:create_model() successfully completed......................................
2023-09-06 09:36:36,952:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:36,952:INFO:Creating metrics dataframe
2023-09-06 09:36:36,958:INFO:Initializing Naive Bayes
2023-09-06 09:36:36,958:INFO:Total runtime is 0.05607872009277344 minutes
2023-09-06 09:36:36,960:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:36,960:INFO:Initializing create_model()
2023-09-06 09:36:36,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=nb, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:36,960:INFO:Checking exceptions
2023-09-06 09:36:36,960:INFO:Importing libraries
2023-09-06 09:36:36,960:INFO:Copying training dataset
2023-09-06 09:36:36,963:INFO:Defining folds
2023-09-06 09:36:36,963:INFO:Declaring metric variables
2023-09-06 09:36:36,965:INFO:Importing untrained model
2023-09-06 09:36:36,967:INFO:Naive Bayes Imported successfully
2023-09-06 09:36:36,970:INFO:Starting cross validation
2023-09-06 09:36:36,971:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:38,367:INFO:Calculating mean and std
2023-09-06 09:36:38,368:INFO:Creating metrics dataframe
2023-09-06 09:36:38,421:INFO:Uploading results into container
2023-09-06 09:36:38,422:INFO:Uploading model into container now
2023-09-06 09:36:38,422:INFO:_master_model_container: 3
2023-09-06 09:36:38,422:INFO:_display_container: 2
2023-09-06 09:36:38,422:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-06 09:36:38,422:INFO:create_model() successfully completed......................................
2023-09-06 09:36:38,468:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:38,468:INFO:Creating metrics dataframe
2023-09-06 09:36:38,474:INFO:Initializing Decision Tree Classifier
2023-09-06 09:36:38,474:INFO:Total runtime is 0.08133145173390707 minutes
2023-09-06 09:36:38,476:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:38,476:INFO:Initializing create_model()
2023-09-06 09:36:38,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:38,476:INFO:Checking exceptions
2023-09-06 09:36:38,476:INFO:Importing libraries
2023-09-06 09:36:38,476:INFO:Copying training dataset
2023-09-06 09:36:38,479:INFO:Defining folds
2023-09-06 09:36:38,479:INFO:Declaring metric variables
2023-09-06 09:36:38,482:INFO:Importing untrained model
2023-09-06 09:36:38,485:INFO:Decision Tree Classifier Imported successfully
2023-09-06 09:36:38,489:INFO:Starting cross validation
2023-09-06 09:36:38,490:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:39,882:INFO:Calculating mean and std
2023-09-06 09:36:39,883:INFO:Creating metrics dataframe
2023-09-06 09:36:39,935:INFO:Uploading results into container
2023-09-06 09:36:39,936:INFO:Uploading model into container now
2023-09-06 09:36:39,936:INFO:_master_model_container: 4
2023-09-06 09:36:39,936:INFO:_display_container: 2
2023-09-06 09:36:39,936:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-06 09:36:39,936:INFO:create_model() successfully completed......................................
2023-09-06 09:36:39,983:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:39,983:INFO:Creating metrics dataframe
2023-09-06 09:36:39,989:INFO:Initializing SVM - Linear Kernel
2023-09-06 09:36:39,989:INFO:Total runtime is 0.10658130248387655 minutes
2023-09-06 09:36:39,991:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:39,991:INFO:Initializing create_model()
2023-09-06 09:36:39,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=svm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:39,991:INFO:Checking exceptions
2023-09-06 09:36:39,991:INFO:Importing libraries
2023-09-06 09:36:39,991:INFO:Copying training dataset
2023-09-06 09:36:39,994:INFO:Defining folds
2023-09-06 09:36:39,994:INFO:Declaring metric variables
2023-09-06 09:36:39,996:INFO:Importing untrained model
2023-09-06 09:36:39,998:INFO:SVM - Linear Kernel Imported successfully
2023-09-06 09:36:40,001:INFO:Starting cross validation
2023-09-06 09:36:40,001:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:41,282:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-06 09:36:41,282:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-06 09:36:41,282:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-06 09:36:41,395:INFO:Calculating mean and std
2023-09-06 09:36:41,396:INFO:Creating metrics dataframe
2023-09-06 09:36:41,448:INFO:Uploading results into container
2023-09-06 09:36:41,448:INFO:Uploading model into container now
2023-09-06 09:36:41,448:INFO:_master_model_container: 5
2023-09-06 09:36:41,449:INFO:_display_container: 2
2023-09-06 09:36:41,449:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1212, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-06 09:36:41,449:INFO:create_model() successfully completed......................................
2023-09-06 09:36:41,495:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:41,495:INFO:Creating metrics dataframe
2023-09-06 09:36:41,501:INFO:Initializing Ridge Classifier
2023-09-06 09:36:41,501:INFO:Total runtime is 0.13178653319676717 minutes
2023-09-06 09:36:41,503:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:41,503:INFO:Initializing create_model()
2023-09-06 09:36:41,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=ridge, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:41,503:INFO:Checking exceptions
2023-09-06 09:36:41,503:INFO:Importing libraries
2023-09-06 09:36:41,503:INFO:Copying training dataset
2023-09-06 09:36:41,506:INFO:Defining folds
2023-09-06 09:36:41,506:INFO:Declaring metric variables
2023-09-06 09:36:41,508:INFO:Importing untrained model
2023-09-06 09:36:41,510:INFO:Ridge Classifier Imported successfully
2023-09-06 09:36:41,514:INFO:Starting cross validation
2023-09-06 09:36:41,514:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:41,542:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 09:36:41,544:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 09:36:42,623:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-06 09:36:42,640:INFO:Calculating mean and std
2023-09-06 09:36:42,640:INFO:Creating metrics dataframe
2023-09-06 09:36:42,695:INFO:Uploading results into container
2023-09-06 09:36:42,696:INFO:Uploading model into container now
2023-09-06 09:36:42,696:INFO:_master_model_container: 6
2023-09-06 09:36:42,696:INFO:_display_container: 2
2023-09-06 09:36:42,696:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1212, solver='auto',
                tol=0.0001)
2023-09-06 09:36:42,696:INFO:create_model() successfully completed......................................
2023-09-06 09:36:42,742:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:42,742:INFO:Creating metrics dataframe
2023-09-06 09:36:42,748:INFO:Initializing Random Forest Classifier
2023-09-06 09:36:42,749:INFO:Total runtime is 0.1525668501853943 minutes
2023-09-06 09:36:42,750:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:42,751:INFO:Initializing create_model()
2023-09-06 09:36:42,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:42,751:INFO:Checking exceptions
2023-09-06 09:36:42,751:INFO:Importing libraries
2023-09-06 09:36:42,751:INFO:Copying training dataset
2023-09-06 09:36:42,753:INFO:Defining folds
2023-09-06 09:36:42,753:INFO:Declaring metric variables
2023-09-06 09:36:42,755:INFO:Importing untrained model
2023-09-06 09:36:42,757:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:36:42,761:INFO:Starting cross validation
2023-09-06 09:36:42,762:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:43,182:INFO:Calculating mean and std
2023-09-06 09:36:43,183:INFO:Creating metrics dataframe
2023-09-06 09:36:43,235:INFO:Uploading results into container
2023-09-06 09:36:43,235:INFO:Uploading model into container now
2023-09-06 09:36:43,235:INFO:_master_model_container: 7
2023-09-06 09:36:43,235:INFO:_display_container: 2
2023-09-06 09:36:43,236:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:36:43,236:INFO:create_model() successfully completed......................................
2023-09-06 09:36:43,281:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:43,281:INFO:Creating metrics dataframe
2023-09-06 09:36:43,288:INFO:Initializing Quadratic Discriminant Analysis
2023-09-06 09:36:43,288:INFO:Total runtime is 0.16157557566960654 minutes
2023-09-06 09:36:43,290:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:43,290:INFO:Initializing create_model()
2023-09-06 09:36:43,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=qda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:43,290:INFO:Checking exceptions
2023-09-06 09:36:43,290:INFO:Importing libraries
2023-09-06 09:36:43,290:INFO:Copying training dataset
2023-09-06 09:36:43,293:INFO:Defining folds
2023-09-06 09:36:43,293:INFO:Declaring metric variables
2023-09-06 09:36:43,295:INFO:Importing untrained model
2023-09-06 09:36:43,297:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-06 09:36:43,301:INFO:Starting cross validation
2023-09-06 09:36:43,301:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:43,435:INFO:Calculating mean and std
2023-09-06 09:36:43,436:INFO:Creating metrics dataframe
2023-09-06 09:36:43,491:INFO:Uploading results into container
2023-09-06 09:36:43,491:INFO:Uploading model into container now
2023-09-06 09:36:43,492:INFO:_master_model_container: 8
2023-09-06 09:36:43,492:INFO:_display_container: 2
2023-09-06 09:36:43,492:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-06 09:36:43,492:INFO:create_model() successfully completed......................................
2023-09-06 09:36:43,538:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:43,538:INFO:Creating metrics dataframe
2023-09-06 09:36:43,544:INFO:Initializing Ada Boost Classifier
2023-09-06 09:36:43,544:INFO:Total runtime is 0.1658314108848572 minutes
2023-09-06 09:36:43,546:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:43,546:INFO:Initializing create_model()
2023-09-06 09:36:43,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=ada, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:43,547:INFO:Checking exceptions
2023-09-06 09:36:43,547:INFO:Importing libraries
2023-09-06 09:36:43,547:INFO:Copying training dataset
2023-09-06 09:36:43,549:INFO:Defining folds
2023-09-06 09:36:43,549:INFO:Declaring metric variables
2023-09-06 09:36:43,550:INFO:Importing untrained model
2023-09-06 09:36:43,552:INFO:Ada Boost Classifier Imported successfully
2023-09-06 09:36:43,556:INFO:Starting cross validation
2023-09-06 09:36:43,556:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:43,786:INFO:Calculating mean and std
2023-09-06 09:36:43,786:INFO:Creating metrics dataframe
2023-09-06 09:36:43,844:INFO:Uploading results into container
2023-09-06 09:36:43,844:INFO:Uploading model into container now
2023-09-06 09:36:43,844:INFO:_master_model_container: 9
2023-09-06 09:36:43,844:INFO:_display_container: 2
2023-09-06 09:36:43,845:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1212)
2023-09-06 09:36:43,845:INFO:create_model() successfully completed......................................
2023-09-06 09:36:43,891:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:43,891:INFO:Creating metrics dataframe
2023-09-06 09:36:43,897:INFO:Initializing Gradient Boosting Classifier
2023-09-06 09:36:43,897:INFO:Total runtime is 0.1717155734697978 minutes
2023-09-06 09:36:43,899:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:43,899:INFO:Initializing create_model()
2023-09-06 09:36:43,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=gbc, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:43,900:INFO:Checking exceptions
2023-09-06 09:36:43,900:INFO:Importing libraries
2023-09-06 09:36:43,900:INFO:Copying training dataset
2023-09-06 09:36:43,902:INFO:Defining folds
2023-09-06 09:36:43,902:INFO:Declaring metric variables
2023-09-06 09:36:43,904:INFO:Importing untrained model
2023-09-06 09:36:43,906:INFO:Gradient Boosting Classifier Imported successfully
2023-09-06 09:36:43,910:INFO:Starting cross validation
2023-09-06 09:36:43,911:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:44,167:INFO:Calculating mean and std
2023-09-06 09:36:44,167:INFO:Creating metrics dataframe
2023-09-06 09:36:44,223:INFO:Uploading results into container
2023-09-06 09:36:44,223:INFO:Uploading model into container now
2023-09-06 09:36:44,223:INFO:_master_model_container: 10
2023-09-06 09:36:44,224:INFO:_display_container: 2
2023-09-06 09:36:44,224:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-06 09:36:44,224:INFO:create_model() successfully completed......................................
2023-09-06 09:36:44,270:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:44,270:INFO:Creating metrics dataframe
2023-09-06 09:36:44,276:INFO:Initializing Linear Discriminant Analysis
2023-09-06 09:36:44,276:INFO:Total runtime is 0.1780320723851522 minutes
2023-09-06 09:36:44,278:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:44,279:INFO:Initializing create_model()
2023-09-06 09:36:44,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=lda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:44,279:INFO:Checking exceptions
2023-09-06 09:36:44,279:INFO:Importing libraries
2023-09-06 09:36:44,279:INFO:Copying training dataset
2023-09-06 09:36:44,281:INFO:Defining folds
2023-09-06 09:36:44,281:INFO:Declaring metric variables
2023-09-06 09:36:44,283:INFO:Importing untrained model
2023-09-06 09:36:44,285:INFO:Linear Discriminant Analysis Imported successfully
2023-09-06 09:36:44,289:INFO:Starting cross validation
2023-09-06 09:36:44,289:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:44,421:INFO:Calculating mean and std
2023-09-06 09:36:44,421:INFO:Creating metrics dataframe
2023-09-06 09:36:44,476:INFO:Uploading results into container
2023-09-06 09:36:44,476:INFO:Uploading model into container now
2023-09-06 09:36:44,477:INFO:_master_model_container: 11
2023-09-06 09:36:44,477:INFO:_display_container: 2
2023-09-06 09:36:44,477:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-06 09:36:44,477:INFO:create_model() successfully completed......................................
2023-09-06 09:36:44,523:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:44,523:INFO:Creating metrics dataframe
2023-09-06 09:36:44,530:INFO:Initializing Extra Trees Classifier
2023-09-06 09:36:44,530:INFO:Total runtime is 0.18227023283640545 minutes
2023-09-06 09:36:44,532:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:44,532:INFO:Initializing create_model()
2023-09-06 09:36:44,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=et, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:44,532:INFO:Checking exceptions
2023-09-06 09:36:44,532:INFO:Importing libraries
2023-09-06 09:36:44,532:INFO:Copying training dataset
2023-09-06 09:36:44,534:INFO:Defining folds
2023-09-06 09:36:44,535:INFO:Declaring metric variables
2023-09-06 09:36:44,536:INFO:Importing untrained model
2023-09-06 09:36:44,539:INFO:Extra Trees Classifier Imported successfully
2023-09-06 09:36:44,542:INFO:Starting cross validation
2023-09-06 09:36:44,543:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:44,947:INFO:Calculating mean and std
2023-09-06 09:36:44,948:INFO:Creating metrics dataframe
2023-09-06 09:36:45,001:INFO:Uploading results into container
2023-09-06 09:36:45,001:INFO:Uploading model into container now
2023-09-06 09:36:45,001:INFO:_master_model_container: 12
2023-09-06 09:36:45,001:INFO:_display_container: 2
2023-09-06 09:36:45,002:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:36:45,002:INFO:create_model() successfully completed......................................
2023-09-06 09:36:45,048:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:45,048:INFO:Creating metrics dataframe
2023-09-06 09:36:45,054:INFO:Initializing Extreme Gradient Boosting
2023-09-06 09:36:45,054:INFO:Total runtime is 0.19101351499557495 minutes
2023-09-06 09:36:45,056:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:45,056:INFO:Initializing create_model()
2023-09-06 09:36:45,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=xgboost, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:45,056:INFO:Checking exceptions
2023-09-06 09:36:45,056:INFO:Importing libraries
2023-09-06 09:36:45,056:INFO:Copying training dataset
2023-09-06 09:36:45,059:INFO:Defining folds
2023-09-06 09:36:45,059:INFO:Declaring metric variables
2023-09-06 09:36:45,061:INFO:Importing untrained model
2023-09-06 09:36:45,063:INFO:Extreme Gradient Boosting Imported successfully
2023-09-06 09:36:45,067:INFO:Starting cross validation
2023-09-06 09:36:45,067:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:45,250:INFO:Calculating mean and std
2023-09-06 09:36:45,251:INFO:Creating metrics dataframe
2023-09-06 09:36:45,306:INFO:Uploading results into container
2023-09-06 09:36:45,307:INFO:Uploading model into container now
2023-09-06 09:36:45,307:INFO:_master_model_container: 13
2023-09-06 09:36:45,307:INFO:_display_container: 2
2023-09-06 09:36:45,308:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-06 09:36:45,308:INFO:create_model() successfully completed......................................
2023-09-06 09:36:45,353:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:45,353:INFO:Creating metrics dataframe
2023-09-06 09:36:45,360:INFO:Initializing Light Gradient Boosting Machine
2023-09-06 09:36:45,361:INFO:Total runtime is 0.19611855347951254 minutes
2023-09-06 09:36:45,363:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:45,363:INFO:Initializing create_model()
2023-09-06 09:36:45,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:45,363:INFO:Checking exceptions
2023-09-06 09:36:45,363:INFO:Importing libraries
2023-09-06 09:36:45,363:INFO:Copying training dataset
2023-09-06 09:36:45,366:INFO:Defining folds
2023-09-06 09:36:45,366:INFO:Declaring metric variables
2023-09-06 09:36:45,368:INFO:Importing untrained model
2023-09-06 09:36:45,370:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-06 09:36:45,374:INFO:Starting cross validation
2023-09-06 09:36:45,374:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:45,649:INFO:Calculating mean and std
2023-09-06 09:36:45,649:INFO:Creating metrics dataframe
2023-09-06 09:36:45,704:INFO:Uploading results into container
2023-09-06 09:36:45,705:INFO:Uploading model into container now
2023-09-06 09:36:45,705:INFO:_master_model_container: 14
2023-09-06 09:36:45,705:INFO:_display_container: 2
2023-09-06 09:36:45,705:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-06 09:36:45,705:INFO:create_model() successfully completed......................................
2023-09-06 09:36:45,751:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:45,751:INFO:Creating metrics dataframe
2023-09-06 09:36:45,758:INFO:Initializing Dummy Classifier
2023-09-06 09:36:45,759:INFO:Total runtime is 0.20275071064631145 minutes
2023-09-06 09:36:45,760:INFO:SubProcess create_model() called ==================================
2023-09-06 09:36:45,761:INFO:Initializing create_model()
2023-09-06 09:36:45,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=dummy, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000199E21A6FD0>, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:45,761:INFO:Checking exceptions
2023-09-06 09:36:45,761:INFO:Importing libraries
2023-09-06 09:36:45,761:INFO:Copying training dataset
2023-09-06 09:36:45,764:INFO:Defining folds
2023-09-06 09:36:45,764:INFO:Declaring metric variables
2023-09-06 09:36:45,766:INFO:Importing untrained model
2023-09-06 09:36:45,767:INFO:Dummy Classifier Imported successfully
2023-09-06 09:36:45,771:INFO:Starting cross validation
2023-09-06 09:36:45,772:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-06 09:36:45,800:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-06 09:36:45,802:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-06 09:36:45,804:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-06 09:36:45,903:INFO:Calculating mean and std
2023-09-06 09:36:45,903:INFO:Creating metrics dataframe
2023-09-06 09:36:45,958:INFO:Uploading results into container
2023-09-06 09:36:45,958:INFO:Uploading model into container now
2023-09-06 09:36:45,958:INFO:_master_model_container: 15
2023-09-06 09:36:45,958:INFO:_display_container: 2
2023-09-06 09:36:45,959:INFO:DummyClassifier(constant=None, random_state=1212, strategy='prior')
2023-09-06 09:36:45,959:INFO:create_model() successfully completed......................................
2023-09-06 09:36:46,005:INFO:SubProcess create_model() end ==================================
2023-09-06 09:36:46,005:INFO:Creating metrics dataframe
2023-09-06 09:36:46,017:INFO:Initializing create_model()
2023-09-06 09:36:46,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:46,018:INFO:Checking exceptions
2023-09-06 09:36:46,019:INFO:Importing libraries
2023-09-06 09:36:46,019:INFO:Copying training dataset
2023-09-06 09:36:46,021:INFO:Defining folds
2023-09-06 09:36:46,021:INFO:Declaring metric variables
2023-09-06 09:36:46,021:INFO:Importing untrained model
2023-09-06 09:36:46,021:INFO:Declaring custom model
2023-09-06 09:36:46,022:INFO:Gradient Boosting Classifier Imported successfully
2023-09-06 09:36:46,022:INFO:Cross validation set to False
2023-09-06 09:36:46,022:INFO:Fitting Model
2023-09-06 09:36:46,197:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-06 09:36:46,197:INFO:create_model() successfully completed......................................
2023-09-06 09:36:46,245:INFO:Initializing create_model()
2023-09-06 09:36:46,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:46,245:INFO:Checking exceptions
2023-09-06 09:36:46,246:INFO:Importing libraries
2023-09-06 09:36:46,246:INFO:Copying training dataset
2023-09-06 09:36:46,249:INFO:Defining folds
2023-09-06 09:36:46,249:INFO:Declaring metric variables
2023-09-06 09:36:46,249:INFO:Importing untrained model
2023-09-06 09:36:46,249:INFO:Declaring custom model
2023-09-06 09:36:46,249:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-06 09:36:46,250:INFO:Cross validation set to False
2023-09-06 09:36:46,250:INFO:Fitting Model
2023-09-06 09:36:46,263:INFO:[LightGBM] [Info] Number of positive: 212, number of negative: 392
2023-09-06 09:36:46,264:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.
2023-09-06 09:36:46,264:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-09-06 09:36:46,264:INFO:[LightGBM] [Info] Total Bins 657
2023-09-06 09:36:46,264:INFO:[LightGBM] [Info] Number of data points in the train set: 604, number of used features: 8
2023-09-06 09:36:46,264:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.350993 -> initscore=-0.614676
2023-09-06 09:36:46,264:INFO:[LightGBM] [Info] Start training from score -0.614676
2023-09-06 09:36:46,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-06 09:36:46,350:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-06 09:36:46,350:INFO:create_model() successfully completed......................................
2023-09-06 09:36:46,412:INFO:Initializing create_model()
2023-09-06 09:36:46,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:46,412:INFO:Checking exceptions
2023-09-06 09:36:46,413:INFO:Importing libraries
2023-09-06 09:36:46,413:INFO:Copying training dataset
2023-09-06 09:36:46,415:INFO:Defining folds
2023-09-06 09:36:46,415:INFO:Declaring metric variables
2023-09-06 09:36:46,415:INFO:Importing untrained model
2023-09-06 09:36:46,416:INFO:Declaring custom model
2023-09-06 09:36:46,416:INFO:Random Forest Classifier Imported successfully
2023-09-06 09:36:46,416:INFO:Cross validation set to False
2023-09-06 09:36:46,416:INFO:Fitting Model
2023-09-06 09:36:46,633:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-06 09:36:46,633:INFO:create_model() successfully completed......................................
2023-09-06 09:36:46,684:INFO:Initializing create_model()
2023-09-06 09:36:46,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199E19F8610>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-06 09:36:46,684:INFO:Checking exceptions
2023-09-06 09:36:46,685:INFO:Importing libraries
2023-09-06 09:36:46,685:INFO:Copying training dataset
2023-09-06 09:36:46,687:INFO:Defining folds
2023-09-06 09:36:46,687:INFO:Declaring metric variables
2023-09-06 09:36:46,687:INFO:Importing untrained model
2023-09-06 09:36:46,687:INFO:Declaring custom model
2023-09-06 09:36:46,688:INFO:Extreme Gradient Boosting Imported successfully
2023-09-06 09:36:46,688:INFO:Cross validation set to False
2023-09-06 09:36:46,689:INFO:Fitting Model
2023-09-06 09:36:46,787:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-06 09:36:46,787:INFO:create_model() successfully completed......................................
2023-09-06 09:36:46,861:INFO:_master_model_container: 15
2023-09-06 09:36:46,861:INFO:_display_container: 2
2023-09-06 09:36:46,862:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)]
2023-09-06 09:36:46,862:INFO:compare_models() successfully completed......................................
2023-09-14 15:02:04,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-14 15:02:04,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-14 15:02:04,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-14 15:02:04,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-14 15:02:10,271:INFO:PyCaret RegressionExperiment
2023-09-14 15:02:10,271:INFO:Logging name: reg-default-name
2023-09-14 15:02:10,271:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-14 15:02:10,271:INFO:version 3.0.4
2023-09-14 15:02:10,271:INFO:Initializing setup()
2023-09-14 15:02:10,271:INFO:self.USI: ceda
2023-09-14 15:02:10,271:INFO:self._variable_keys: {'n_jobs_param', '_available_plots', 'y', 'y_train', 'memory', 'idx', 'pipeline', 'y_test', 'html_param', 'fold_shuffle_param', 'exp_id', 'target_param', 'data', 'transform_target_param', 'logging_param', 'X', '_ml_usecase', 'gpu_n_jobs_param', 'X_train', 'seed', 'fold_generator', 'log_plots_param', 'fold_groups_param', 'X_test', 'USI', 'exp_name_log', 'gpu_param'}
2023-09-14 15:02:10,271:INFO:Checking environment
2023-09-14 15:02:10,272:INFO:python_version: 3.8.8
2023-09-14 15:02:10,272:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-14 15:02:10,272:INFO:machine: AMD64
2023-09-14 15:02:10,272:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-14 15:02:10,274:INFO:Memory: svmem(total=16822788096, available=8248635392, percent=51.0, used=8574152704, free=8248635392)
2023-09-14 15:02:10,274:INFO:Physical Core: 8
2023-09-14 15:02:10,274:INFO:Logical Core: 16
2023-09-14 15:02:10,274:INFO:Checking libraries
2023-09-14 15:02:10,274:INFO:System:
2023-09-14 15:02:10,274:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-14 15:02:10,274:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-14 15:02:10,274:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-14 15:02:10,274:INFO:PyCaret required dependencies:
2023-09-14 15:02:10,339:INFO:                 pip: 22.3.1
2023-09-14 15:02:10,339:INFO:          setuptools: 65.5.1
2023-09-14 15:02:10,339:INFO:             pycaret: 3.0.4
2023-09-14 15:02:10,339:INFO:             IPython: 8.12.2
2023-09-14 15:02:10,339:INFO:          ipywidgets: 8.0.7
2023-09-14 15:02:10,339:INFO:                tqdm: 4.66.1
2023-09-14 15:02:10,339:INFO:               numpy: 1.23.5
2023-09-14 15:02:10,339:INFO:              pandas: 1.5.3
2023-09-14 15:02:10,339:INFO:              jinja2: 3.1.2
2023-09-14 15:02:10,339:INFO:               scipy: 1.10.1
2023-09-14 15:02:10,339:INFO:              joblib: 1.3.2
2023-09-14 15:02:10,339:INFO:             sklearn: 1.2.2
2023-09-14 15:02:10,339:INFO:                pyod: 1.1.0
2023-09-14 15:02:10,339:INFO:            imblearn: 0.11.0
2023-09-14 15:02:10,339:INFO:   category_encoders: 2.6.2
2023-09-14 15:02:10,340:INFO:            lightgbm: 4.0.0
2023-09-14 15:02:10,340:INFO:               numba: 0.57.1
2023-09-14 15:02:10,340:INFO:            requests: 2.31.0
2023-09-14 15:02:10,340:INFO:          matplotlib: 3.7.2
2023-09-14 15:02:10,340:INFO:          scikitplot: 0.3.7
2023-09-14 15:02:10,340:INFO:         yellowbrick: 1.5
2023-09-14 15:02:10,340:INFO:              plotly: 5.15.0
2023-09-14 15:02:10,340:INFO:    plotly-resampler: Not installed
2023-09-14 15:02:10,340:INFO:             kaleido: 0.2.1
2023-09-14 15:02:10,340:INFO:           schemdraw: 0.15
2023-09-14 15:02:10,340:INFO:         statsmodels: 0.14.0
2023-09-14 15:02:10,340:INFO:              sktime: 0.22.0
2023-09-14 15:02:10,340:INFO:               tbats: 1.1.3
2023-09-14 15:02:10,340:INFO:            pmdarima: 2.0.3
2023-09-14 15:02:10,340:INFO:              psutil: 5.9.5
2023-09-14 15:02:10,340:INFO:          markupsafe: 2.1.3
2023-09-14 15:02:10,340:INFO:             pickle5: Not installed
2023-09-14 15:02:10,340:INFO:         cloudpickle: 2.2.1
2023-09-14 15:02:10,340:INFO:         deprecation: 2.1.0
2023-09-14 15:02:10,340:INFO:              xxhash: 3.3.0
2023-09-14 15:02:10,340:INFO:           wurlitzer: Not installed
2023-09-14 15:02:10,340:INFO:PyCaret optional dependencies:
2023-09-14 15:02:10,346:INFO:                shap: Not installed
2023-09-14 15:02:10,346:INFO:           interpret: Not installed
2023-09-14 15:02:10,346:INFO:                umap: Not installed
2023-09-14 15:02:10,346:INFO:    pandas_profiling: 4.5.1
2023-09-14 15:02:10,346:INFO:  explainerdashboard: Not installed
2023-09-14 15:02:10,346:INFO:             autoviz: Not installed
2023-09-14 15:02:10,346:INFO:           fairlearn: Not installed
2023-09-14 15:02:10,346:INFO:          deepchecks: Not installed
2023-09-14 15:02:10,346:INFO:             xgboost: 1.7.6
2023-09-14 15:02:10,346:INFO:            catboost: 1.2.1
2023-09-14 15:02:10,346:INFO:              kmodes: Not installed
2023-09-14 15:02:10,347:INFO:             mlxtend: Not installed
2023-09-14 15:02:10,347:INFO:       statsforecast: Not installed
2023-09-14 15:02:10,347:INFO:        tune_sklearn: Not installed
2023-09-14 15:02:10,347:INFO:                 ray: Not installed
2023-09-14 15:02:10,347:INFO:            hyperopt: Not installed
2023-09-14 15:02:10,347:INFO:              optuna: 3.3.0
2023-09-14 15:02:10,347:INFO:               skopt: 0.9.0
2023-09-14 15:02:10,347:INFO:              mlflow: Not installed
2023-09-14 15:02:10,347:INFO:              gradio: Not installed
2023-09-14 15:02:10,347:INFO:             fastapi: Not installed
2023-09-14 15:02:10,347:INFO:             uvicorn: Not installed
2023-09-14 15:02:10,347:INFO:              m2cgen: Not installed
2023-09-14 15:02:10,347:INFO:           evidently: Not installed
2023-09-14 15:02:10,347:INFO:               fugue: Not installed
2023-09-14 15:02:10,347:INFO:           streamlit: Not installed
2023-09-14 15:02:10,347:INFO:             prophet: Not installed
2023-09-14 15:02:10,347:INFO:None
2023-09-14 15:02:10,347:INFO:Set up data.
2023-09-14 15:02:10,350:INFO:Set up train/test split.
2023-09-14 15:02:10,352:INFO:Set up index.
2023-09-14 15:02:10,352:INFO:Set up folding strategy.
2023-09-14 15:02:10,353:INFO:Assigning column types.
2023-09-14 15:02:10,355:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-14 15:02:10,355:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,360:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,364:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,404:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,432:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,433:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:10,499:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:10,830:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,833:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,836:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,874:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,902:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:10,904:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:10,904:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-09-14 15:02:10,907:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,910:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,947:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,976:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,976:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:10,978:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:10,981:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-14 15:02:10,984:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,021:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,050:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,050:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:11,051:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:11,053:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-09-14 15:02:11,058:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,123:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,123:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:11,125:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:11,131:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,168:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,199:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,199:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:11,201:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:11,201:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-09-14 15:02:11,244:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,274:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:11,275:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:11,319:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,350:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,350:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:11,352:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:11,352:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-14 15:02:11,402:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,434:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:11,436:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:11,478:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:11,507:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:11,509:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:11,509:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-09-14 15:02:11,584:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:11,585:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:11,659:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:11,661:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:11,676:INFO:Preparing preprocessing pipeline...
2023-09-14 15:02:11,677:INFO:Set up simple imputation.
2023-09-14 15:02:11,697:INFO:Finished creating preprocessing pipeline.
2023-09-14 15:02:11,700:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sl', 'sw', 'pl', 'pw'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-09-14 15:02:11,700:INFO:Creating final display dataframe.
2023-09-14 15:02:11,734:INFO:Setup _display_container:                     Description             Value
0                    Session id              5511
1                        Target            target
2                   Target type        Regression
3           Original data shape          (150, 5)
4        Transformed data shape          (150, 5)
5   Transformed train set shape          (105, 5)
6    Transformed test set shape           (45, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              ceda
2023-09-14 15:02:11,824:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:11,826:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:11,903:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:11,905:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:11,906:INFO:setup() successfully completed in 1.74s...............
2023-09-14 15:02:36,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-14 15:02:36,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-14 15:02:36,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-14 15:02:36,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-14 15:02:46,743:INFO:PyCaret RegressionExperiment
2023-09-14 15:02:46,743:INFO:Logging name: reg-default-name
2023-09-14 15:02:46,743:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-14 15:02:46,743:INFO:version 3.0.4
2023-09-14 15:02:46,743:INFO:Initializing setup()
2023-09-14 15:02:46,743:INFO:self.USI: cafd
2023-09-14 15:02:46,743:INFO:self._variable_keys: {'exp_id', 'logging_param', 'log_plots_param', 'html_param', 'pipeline', 'data', 'gpu_param', 'y_test', 'memory', 'target_param', 'fold_groups_param', 'y_train', 'X_test', 'USI', 'n_jobs_param', 'X_train', 'idx', 'X', 'transform_target_param', 'exp_name_log', 'fold_generator', 'seed', 'fold_shuffle_param', '_ml_usecase', 'y', '_available_plots', 'gpu_n_jobs_param'}
2023-09-14 15:02:46,744:INFO:Checking environment
2023-09-14 15:02:46,744:INFO:python_version: 3.8.8
2023-09-14 15:02:46,744:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-14 15:02:46,744:INFO:machine: AMD64
2023-09-14 15:02:46,744:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-14 15:02:46,745:INFO:Memory: svmem(total=16822788096, available=8201408512, percent=51.2, used=8621379584, free=8201408512)
2023-09-14 15:02:46,745:INFO:Physical Core: 8
2023-09-14 15:02:46,745:INFO:Logical Core: 16
2023-09-14 15:02:46,745:INFO:Checking libraries
2023-09-14 15:02:46,745:INFO:System:
2023-09-14 15:02:46,746:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-14 15:02:46,746:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-14 15:02:46,746:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-14 15:02:46,746:INFO:PyCaret required dependencies:
2023-09-14 15:02:46,781:INFO:                 pip: 22.3.1
2023-09-14 15:02:46,781:INFO:          setuptools: 65.5.1
2023-09-14 15:02:46,781:INFO:             pycaret: 3.0.4
2023-09-14 15:02:46,781:INFO:             IPython: 8.12.2
2023-09-14 15:02:46,781:INFO:          ipywidgets: 8.0.7
2023-09-14 15:02:46,781:INFO:                tqdm: 4.66.1
2023-09-14 15:02:46,781:INFO:               numpy: 1.23.5
2023-09-14 15:02:46,781:INFO:              pandas: 1.5.3
2023-09-14 15:02:46,781:INFO:              jinja2: 3.1.2
2023-09-14 15:02:46,781:INFO:               scipy: 1.10.1
2023-09-14 15:02:46,781:INFO:              joblib: 1.3.2
2023-09-14 15:02:46,781:INFO:             sklearn: 1.2.2
2023-09-14 15:02:46,781:INFO:                pyod: 1.1.0
2023-09-14 15:02:46,781:INFO:            imblearn: 0.11.0
2023-09-14 15:02:46,781:INFO:   category_encoders: 2.6.2
2023-09-14 15:02:46,782:INFO:            lightgbm: 4.0.0
2023-09-14 15:02:46,782:INFO:               numba: 0.57.1
2023-09-14 15:02:46,782:INFO:            requests: 2.31.0
2023-09-14 15:02:46,782:INFO:          matplotlib: 3.7.2
2023-09-14 15:02:46,782:INFO:          scikitplot: 0.3.7
2023-09-14 15:02:46,782:INFO:         yellowbrick: 1.5
2023-09-14 15:02:46,782:INFO:              plotly: 5.15.0
2023-09-14 15:02:46,782:INFO:    plotly-resampler: Not installed
2023-09-14 15:02:46,782:INFO:             kaleido: 0.2.1
2023-09-14 15:02:46,782:INFO:           schemdraw: 0.15
2023-09-14 15:02:46,782:INFO:         statsmodels: 0.14.0
2023-09-14 15:02:46,782:INFO:              sktime: 0.22.0
2023-09-14 15:02:46,782:INFO:               tbats: 1.1.3
2023-09-14 15:02:46,782:INFO:            pmdarima: 2.0.3
2023-09-14 15:02:46,782:INFO:              psutil: 5.9.5
2023-09-14 15:02:46,782:INFO:          markupsafe: 2.1.3
2023-09-14 15:02:46,782:INFO:             pickle5: Not installed
2023-09-14 15:02:46,782:INFO:         cloudpickle: 2.2.1
2023-09-14 15:02:46,782:INFO:         deprecation: 2.1.0
2023-09-14 15:02:46,782:INFO:              xxhash: 3.3.0
2023-09-14 15:02:46,782:INFO:           wurlitzer: Not installed
2023-09-14 15:02:46,782:INFO:PyCaret optional dependencies:
2023-09-14 15:02:46,786:INFO:                shap: Not installed
2023-09-14 15:02:46,787:INFO:           interpret: Not installed
2023-09-14 15:02:46,787:INFO:                umap: Not installed
2023-09-14 15:02:46,787:INFO:    pandas_profiling: 4.5.1
2023-09-14 15:02:46,787:INFO:  explainerdashboard: Not installed
2023-09-14 15:02:46,787:INFO:             autoviz: Not installed
2023-09-14 15:02:46,787:INFO:           fairlearn: Not installed
2023-09-14 15:02:46,787:INFO:          deepchecks: Not installed
2023-09-14 15:02:46,787:INFO:             xgboost: 1.7.6
2023-09-14 15:02:46,787:INFO:            catboost: 1.2.1
2023-09-14 15:02:46,787:INFO:              kmodes: Not installed
2023-09-14 15:02:46,787:INFO:             mlxtend: Not installed
2023-09-14 15:02:46,787:INFO:       statsforecast: Not installed
2023-09-14 15:02:46,787:INFO:        tune_sklearn: Not installed
2023-09-14 15:02:46,787:INFO:                 ray: Not installed
2023-09-14 15:02:46,787:INFO:            hyperopt: Not installed
2023-09-14 15:02:46,787:INFO:              optuna: 3.3.0
2023-09-14 15:02:46,787:INFO:               skopt: 0.9.0
2023-09-14 15:02:46,787:INFO:              mlflow: Not installed
2023-09-14 15:02:46,787:INFO:              gradio: Not installed
2023-09-14 15:02:46,787:INFO:             fastapi: Not installed
2023-09-14 15:02:46,787:INFO:             uvicorn: Not installed
2023-09-14 15:02:46,787:INFO:              m2cgen: Not installed
2023-09-14 15:02:46,787:INFO:           evidently: Not installed
2023-09-14 15:02:46,787:INFO:               fugue: Not installed
2023-09-14 15:02:46,787:INFO:           streamlit: Not installed
2023-09-14 15:02:46,787:INFO:             prophet: Not installed
2023-09-14 15:02:46,787:INFO:None
2023-09-14 15:02:46,787:INFO:Set up data.
2023-09-14 15:02:55,006:INFO:PyCaret RegressionExperiment
2023-09-14 15:02:55,006:INFO:Logging name: reg-default-name
2023-09-14 15:02:55,006:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-14 15:02:55,006:INFO:version 3.0.4
2023-09-14 15:02:55,006:INFO:Initializing setup()
2023-09-14 15:02:55,006:INFO:self.USI: 5f3a
2023-09-14 15:02:55,007:INFO:self._variable_keys: {'exp_id', 'logging_param', 'log_plots_param', 'html_param', 'pipeline', 'data', 'gpu_param', 'y_test', 'memory', 'target_param', 'fold_groups_param', 'y_train', 'X_test', 'USI', 'n_jobs_param', 'X_train', 'idx', 'X', 'transform_target_param', 'exp_name_log', 'fold_generator', 'seed', 'fold_shuffle_param', '_ml_usecase', 'y', '_available_plots', 'gpu_n_jobs_param'}
2023-09-14 15:02:55,007:INFO:Checking environment
2023-09-14 15:02:55,007:INFO:python_version: 3.8.8
2023-09-14 15:02:55,007:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-14 15:02:55,007:INFO:machine: AMD64
2023-09-14 15:02:55,007:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-14 15:02:55,009:INFO:Memory: svmem(total=16822788096, available=8192385024, percent=51.3, used=8630403072, free=8192385024)
2023-09-14 15:02:55,009:INFO:Physical Core: 8
2023-09-14 15:02:55,009:INFO:Logical Core: 16
2023-09-14 15:02:55,009:INFO:Checking libraries
2023-09-14 15:02:55,009:INFO:System:
2023-09-14 15:02:55,009:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-14 15:02:55,009:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-14 15:02:55,009:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-14 15:02:55,009:INFO:PyCaret required dependencies:
2023-09-14 15:02:55,009:INFO:                 pip: 22.3.1
2023-09-14 15:02:55,009:INFO:          setuptools: 65.5.1
2023-09-14 15:02:55,009:INFO:             pycaret: 3.0.4
2023-09-14 15:02:55,009:INFO:             IPython: 8.12.2
2023-09-14 15:02:55,009:INFO:          ipywidgets: 8.0.7
2023-09-14 15:02:55,009:INFO:                tqdm: 4.66.1
2023-09-14 15:02:55,009:INFO:               numpy: 1.23.5
2023-09-14 15:02:55,009:INFO:              pandas: 1.5.3
2023-09-14 15:02:55,009:INFO:              jinja2: 3.1.2
2023-09-14 15:02:55,009:INFO:               scipy: 1.10.1
2023-09-14 15:02:55,009:INFO:              joblib: 1.3.2
2023-09-14 15:02:55,009:INFO:             sklearn: 1.2.2
2023-09-14 15:02:55,009:INFO:                pyod: 1.1.0
2023-09-14 15:02:55,010:INFO:            imblearn: 0.11.0
2023-09-14 15:02:55,010:INFO:   category_encoders: 2.6.2
2023-09-14 15:02:55,010:INFO:            lightgbm: 4.0.0
2023-09-14 15:02:55,010:INFO:               numba: 0.57.1
2023-09-14 15:02:55,010:INFO:            requests: 2.31.0
2023-09-14 15:02:55,010:INFO:          matplotlib: 3.7.2
2023-09-14 15:02:55,010:INFO:          scikitplot: 0.3.7
2023-09-14 15:02:55,010:INFO:         yellowbrick: 1.5
2023-09-14 15:02:55,010:INFO:              plotly: 5.15.0
2023-09-14 15:02:55,010:INFO:    plotly-resampler: Not installed
2023-09-14 15:02:55,010:INFO:             kaleido: 0.2.1
2023-09-14 15:02:55,010:INFO:           schemdraw: 0.15
2023-09-14 15:02:55,010:INFO:         statsmodels: 0.14.0
2023-09-14 15:02:55,010:INFO:              sktime: 0.22.0
2023-09-14 15:02:55,010:INFO:               tbats: 1.1.3
2023-09-14 15:02:55,010:INFO:            pmdarima: 2.0.3
2023-09-14 15:02:55,010:INFO:              psutil: 5.9.5
2023-09-14 15:02:55,010:INFO:          markupsafe: 2.1.3
2023-09-14 15:02:55,010:INFO:             pickle5: Not installed
2023-09-14 15:02:55,010:INFO:         cloudpickle: 2.2.1
2023-09-14 15:02:55,010:INFO:         deprecation: 2.1.0
2023-09-14 15:02:55,010:INFO:              xxhash: 3.3.0
2023-09-14 15:02:55,010:INFO:           wurlitzer: Not installed
2023-09-14 15:02:55,010:INFO:PyCaret optional dependencies:
2023-09-14 15:02:55,010:INFO:                shap: Not installed
2023-09-14 15:02:55,010:INFO:           interpret: Not installed
2023-09-14 15:02:55,010:INFO:                umap: Not installed
2023-09-14 15:02:55,010:INFO:    pandas_profiling: 4.5.1
2023-09-14 15:02:55,010:INFO:  explainerdashboard: Not installed
2023-09-14 15:02:55,010:INFO:             autoviz: Not installed
2023-09-14 15:02:55,010:INFO:           fairlearn: Not installed
2023-09-14 15:02:55,010:INFO:          deepchecks: Not installed
2023-09-14 15:02:55,010:INFO:             xgboost: 1.7.6
2023-09-14 15:02:55,010:INFO:            catboost: 1.2.1
2023-09-14 15:02:55,010:INFO:              kmodes: Not installed
2023-09-14 15:02:55,010:INFO:             mlxtend: Not installed
2023-09-14 15:02:55,010:INFO:       statsforecast: Not installed
2023-09-14 15:02:55,010:INFO:        tune_sklearn: Not installed
2023-09-14 15:02:55,010:INFO:                 ray: Not installed
2023-09-14 15:02:55,010:INFO:            hyperopt: Not installed
2023-09-14 15:02:55,010:INFO:              optuna: 3.3.0
2023-09-14 15:02:55,010:INFO:               skopt: 0.9.0
2023-09-14 15:02:55,010:INFO:              mlflow: Not installed
2023-09-14 15:02:55,010:INFO:              gradio: Not installed
2023-09-14 15:02:55,010:INFO:             fastapi: Not installed
2023-09-14 15:02:55,010:INFO:             uvicorn: Not installed
2023-09-14 15:02:55,011:INFO:              m2cgen: Not installed
2023-09-14 15:02:55,011:INFO:           evidently: Not installed
2023-09-14 15:02:55,011:INFO:               fugue: Not installed
2023-09-14 15:02:55,011:INFO:           streamlit: Not installed
2023-09-14 15:02:55,011:INFO:             prophet: Not installed
2023-09-14 15:02:55,011:INFO:None
2023-09-14 15:02:55,011:INFO:Set up data.
2023-09-14 15:02:55,014:INFO:Set up train/test split.
2023-09-14 15:02:55,016:INFO:Set up index.
2023-09-14 15:02:55,016:INFO:Set up folding strategy.
2023-09-14 15:02:55,016:INFO:Assigning column types.
2023-09-14 15:02:55,017:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-14 15:02:55,018:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,021:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,024:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,090:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,106:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,119:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,123:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,127:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,163:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,191:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,192:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,193:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,194:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-09-14 15:02:55,196:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,199:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,264:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,265:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,266:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,269:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,272:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,312:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,339:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,340:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,342:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,342:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-09-14 15:02:55,347:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,385:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,414:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,416:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,422:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,459:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,488:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,488:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,490:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,490:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-09-14 15:02:55,533:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,561:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,563:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,607:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,637:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,637:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,639:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,640:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-14 15:02:55,682:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,709:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,711:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,754:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-14 15:02:55,784:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,786:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,786:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-09-14 15:02:55,858:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,859:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,932:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:55,934:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:55,935:INFO:Preparing preprocessing pipeline...
2023-09-14 15:02:55,935:INFO:Set up simple imputation.
2023-09-14 15:02:55,947:INFO:Finished creating preprocessing pipeline.
2023-09-14 15:02:55,949:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sl', 'sw', 'pl', 'pw'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-09-14 15:02:55,949:INFO:Creating final display dataframe.
2023-09-14 15:02:55,980:INFO:Setup _display_container:                     Description             Value
0                    Session id               820
1                        Target            target
2                   Target type        Regression
3           Original data shape          (150, 5)
4        Transformed data shape          (150, 5)
5   Transformed train set shape          (105, 5)
6    Transformed test set shape           (45, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              5f3a
2023-09-14 15:02:56,060:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:56,062:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:56,134:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-14 15:02:56,136:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-14 15:02:56,137:INFO:setup() successfully completed in 1.2s...............
2023-09-14 15:03:18,539:INFO:Initializing compare_models()
2023-09-14 15:03:18,540:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2023-09-14 15:03:18,540:INFO:Checking exceptions
2023-09-14 15:03:28,558:INFO:Initializing compare_models()
2023-09-14 15:03:28,558:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2023-09-14 15:03:28,558:INFO:Checking exceptions
2023-09-14 15:03:28,560:INFO:Preparing display monitor
2023-09-14 15:03:28,581:INFO:Initializing Linear Regression
2023-09-14 15:03:28,581:INFO:Total runtime is 0.0 minutes
2023-09-14 15:03:28,584:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:28,585:INFO:Initializing create_model()
2023-09-14 15:03:28,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:28,585:INFO:Checking exceptions
2023-09-14 15:03:28,585:INFO:Importing libraries
2023-09-14 15:03:28,585:INFO:Copying training dataset
2023-09-14 15:03:28,588:INFO:Defining folds
2023-09-14 15:03:28,588:INFO:Declaring metric variables
2023-09-14 15:03:28,591:INFO:Importing untrained model
2023-09-14 15:03:28,594:INFO:Linear Regression Imported successfully
2023-09-14 15:03:28,599:INFO:Starting cross validation
2023-09-14 15:03:28,604:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:31,858:INFO:Calculating mean and std
2023-09-14 15:03:31,859:INFO:Creating metrics dataframe
2023-09-14 15:03:31,940:INFO:Uploading results into container
2023-09-14 15:03:31,941:INFO:Uploading model into container now
2023-09-14 15:03:31,941:INFO:_master_model_container: 1
2023-09-14 15:03:31,941:INFO:_display_container: 2
2023-09-14 15:03:31,941:INFO:LinearRegression(n_jobs=-1)
2023-09-14 15:03:31,941:INFO:create_model() successfully completed......................................
2023-09-14 15:03:32,058:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:32,058:INFO:Creating metrics dataframe
2023-09-14 15:03:32,063:INFO:Initializing Lasso Regression
2023-09-14 15:03:32,063:INFO:Total runtime is 0.05803336302439372 minutes
2023-09-14 15:03:32,065:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:32,065:INFO:Initializing create_model()
2023-09-14 15:03:32,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:32,065:INFO:Checking exceptions
2023-09-14 15:03:32,066:INFO:Importing libraries
2023-09-14 15:03:32,066:INFO:Copying training dataset
2023-09-14 15:03:32,068:INFO:Defining folds
2023-09-14 15:03:32,068:INFO:Declaring metric variables
2023-09-14 15:03:32,070:INFO:Importing untrained model
2023-09-14 15:03:32,072:INFO:Lasso Regression Imported successfully
2023-09-14 15:03:32,076:INFO:Starting cross validation
2023-09-14 15:03:32,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:34,187:INFO:Calculating mean and std
2023-09-14 15:03:34,188:INFO:Creating metrics dataframe
2023-09-14 15:03:34,271:INFO:Uploading results into container
2023-09-14 15:03:34,272:INFO:Uploading model into container now
2023-09-14 15:03:34,272:INFO:_master_model_container: 2
2023-09-14 15:03:34,272:INFO:_display_container: 2
2023-09-14 15:03:34,272:INFO:Lasso(random_state=820)
2023-09-14 15:03:34,272:INFO:create_model() successfully completed......................................
2023-09-14 15:03:34,386:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:34,386:INFO:Creating metrics dataframe
2023-09-14 15:03:34,392:INFO:Initializing Ridge Regression
2023-09-14 15:03:34,392:INFO:Total runtime is 0.09684992233912151 minutes
2023-09-14 15:03:34,394:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:34,394:INFO:Initializing create_model()
2023-09-14 15:03:34,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:34,394:INFO:Checking exceptions
2023-09-14 15:03:34,394:INFO:Importing libraries
2023-09-14 15:03:34,394:INFO:Copying training dataset
2023-09-14 15:03:34,397:INFO:Defining folds
2023-09-14 15:03:34,397:INFO:Declaring metric variables
2023-09-14 15:03:34,399:INFO:Importing untrained model
2023-09-14 15:03:34,401:INFO:Ridge Regression Imported successfully
2023-09-14 15:03:34,405:INFO:Starting cross validation
2023-09-14 15:03:34,405:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:35,046:INFO:Calculating mean and std
2023-09-14 15:03:35,048:INFO:Creating metrics dataframe
2023-09-14 15:03:35,130:INFO:Uploading results into container
2023-09-14 15:03:35,130:INFO:Uploading model into container now
2023-09-14 15:03:35,131:INFO:_master_model_container: 3
2023-09-14 15:03:35,131:INFO:_display_container: 2
2023-09-14 15:03:35,131:INFO:Ridge(random_state=820)
2023-09-14 15:03:35,131:INFO:create_model() successfully completed......................................
2023-09-14 15:03:35,243:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:35,243:INFO:Creating metrics dataframe
2023-09-14 15:03:35,249:INFO:Initializing Elastic Net
2023-09-14 15:03:35,249:INFO:Total runtime is 0.11113260189692181 minutes
2023-09-14 15:03:35,251:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:35,251:INFO:Initializing create_model()
2023-09-14 15:03:35,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:35,251:INFO:Checking exceptions
2023-09-14 15:03:35,251:INFO:Importing libraries
2023-09-14 15:03:35,251:INFO:Copying training dataset
2023-09-14 15:03:35,255:INFO:Defining folds
2023-09-14 15:03:35,256:INFO:Declaring metric variables
2023-09-14 15:03:35,259:INFO:Importing untrained model
2023-09-14 15:03:35,262:INFO:Elastic Net Imported successfully
2023-09-14 15:03:35,266:INFO:Starting cross validation
2023-09-14 15:03:35,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:35,900:INFO:Calculating mean and std
2023-09-14 15:03:35,901:INFO:Creating metrics dataframe
2023-09-14 15:03:35,985:INFO:Uploading results into container
2023-09-14 15:03:35,985:INFO:Uploading model into container now
2023-09-14 15:03:35,986:INFO:_master_model_container: 4
2023-09-14 15:03:35,986:INFO:_display_container: 2
2023-09-14 15:03:35,986:INFO:ElasticNet(random_state=820)
2023-09-14 15:03:35,986:INFO:create_model() successfully completed......................................
2023-09-14 15:03:36,100:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:36,100:INFO:Creating metrics dataframe
2023-09-14 15:03:36,106:INFO:Initializing Least Angle Regression
2023-09-14 15:03:36,106:INFO:Total runtime is 0.12541050910949708 minutes
2023-09-14 15:03:36,109:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:36,109:INFO:Initializing create_model()
2023-09-14 15:03:36,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:36,109:INFO:Checking exceptions
2023-09-14 15:03:36,109:INFO:Importing libraries
2023-09-14 15:03:36,109:INFO:Copying training dataset
2023-09-14 15:03:36,111:INFO:Defining folds
2023-09-14 15:03:36,111:INFO:Declaring metric variables
2023-09-14 15:03:36,114:INFO:Importing untrained model
2023-09-14 15:03:36,116:INFO:Least Angle Regression Imported successfully
2023-09-14 15:03:36,120:INFO:Starting cross validation
2023-09-14 15:03:36,121:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:36,752:INFO:Calculating mean and std
2023-09-14 15:03:36,753:INFO:Creating metrics dataframe
2023-09-14 15:03:36,836:INFO:Uploading results into container
2023-09-14 15:03:36,836:INFO:Uploading model into container now
2023-09-14 15:03:36,837:INFO:_master_model_container: 5
2023-09-14 15:03:36,837:INFO:_display_container: 2
2023-09-14 15:03:36,837:INFO:Lars(random_state=820)
2023-09-14 15:03:36,837:INFO:create_model() successfully completed......................................
2023-09-14 15:03:36,949:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:36,950:INFO:Creating metrics dataframe
2023-09-14 15:03:36,955:INFO:Initializing Lasso Least Angle Regression
2023-09-14 15:03:36,955:INFO:Total runtime is 0.13956837256749471 minutes
2023-09-14 15:03:36,958:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:36,958:INFO:Initializing create_model()
2023-09-14 15:03:36,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:36,958:INFO:Checking exceptions
2023-09-14 15:03:36,958:INFO:Importing libraries
2023-09-14 15:03:36,958:INFO:Copying training dataset
2023-09-14 15:03:36,961:INFO:Defining folds
2023-09-14 15:03:36,961:INFO:Declaring metric variables
2023-09-14 15:03:36,963:INFO:Importing untrained model
2023-09-14 15:03:36,966:INFO:Lasso Least Angle Regression Imported successfully
2023-09-14 15:03:36,970:INFO:Starting cross validation
2023-09-14 15:03:36,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:37,622:INFO:Calculating mean and std
2023-09-14 15:03:37,623:INFO:Creating metrics dataframe
2023-09-14 15:03:37,703:INFO:Uploading results into container
2023-09-14 15:03:37,703:INFO:Uploading model into container now
2023-09-14 15:03:37,703:INFO:_master_model_container: 6
2023-09-14 15:03:37,703:INFO:_display_container: 2
2023-09-14 15:03:37,704:INFO:LassoLars(random_state=820)
2023-09-14 15:03:37,704:INFO:create_model() successfully completed......................................
2023-09-14 15:03:37,815:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:37,815:INFO:Creating metrics dataframe
2023-09-14 15:03:37,822:INFO:Initializing Orthogonal Matching Pursuit
2023-09-14 15:03:37,822:INFO:Total runtime is 0.15401615301767985 minutes
2023-09-14 15:03:37,824:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:37,824:INFO:Initializing create_model()
2023-09-14 15:03:37,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:37,824:INFO:Checking exceptions
2023-09-14 15:03:37,824:INFO:Importing libraries
2023-09-14 15:03:37,824:INFO:Copying training dataset
2023-09-14 15:03:37,827:INFO:Defining folds
2023-09-14 15:03:37,827:INFO:Declaring metric variables
2023-09-14 15:03:37,830:INFO:Importing untrained model
2023-09-14 15:03:37,832:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-14 15:03:37,836:INFO:Starting cross validation
2023-09-14 15:03:37,837:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:38,481:INFO:Calculating mean and std
2023-09-14 15:03:38,482:INFO:Creating metrics dataframe
2023-09-14 15:03:38,564:INFO:Uploading results into container
2023-09-14 15:03:38,564:INFO:Uploading model into container now
2023-09-14 15:03:38,564:INFO:_master_model_container: 7
2023-09-14 15:03:38,565:INFO:_display_container: 2
2023-09-14 15:03:38,565:INFO:OrthogonalMatchingPursuit()
2023-09-14 15:03:38,565:INFO:create_model() successfully completed......................................
2023-09-14 15:03:38,674:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:38,674:INFO:Creating metrics dataframe
2023-09-14 15:03:38,681:INFO:Initializing Bayesian Ridge
2023-09-14 15:03:38,681:INFO:Total runtime is 0.1683316707611084 minutes
2023-09-14 15:03:38,683:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:38,683:INFO:Initializing create_model()
2023-09-14 15:03:38,683:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:38,683:INFO:Checking exceptions
2023-09-14 15:03:38,683:INFO:Importing libraries
2023-09-14 15:03:38,683:INFO:Copying training dataset
2023-09-14 15:03:38,686:INFO:Defining folds
2023-09-14 15:03:38,686:INFO:Declaring metric variables
2023-09-14 15:03:38,688:INFO:Importing untrained model
2023-09-14 15:03:38,690:INFO:Bayesian Ridge Imported successfully
2023-09-14 15:03:38,694:INFO:Starting cross validation
2023-09-14 15:03:38,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:39,366:INFO:Calculating mean and std
2023-09-14 15:03:39,367:INFO:Creating metrics dataframe
2023-09-14 15:03:39,448:INFO:Uploading results into container
2023-09-14 15:03:39,449:INFO:Uploading model into container now
2023-09-14 15:03:39,449:INFO:_master_model_container: 8
2023-09-14 15:03:39,449:INFO:_display_container: 2
2023-09-14 15:03:39,449:INFO:BayesianRidge()
2023-09-14 15:03:39,449:INFO:create_model() successfully completed......................................
2023-09-14 15:03:39,559:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:39,559:INFO:Creating metrics dataframe
2023-09-14 15:03:39,565:INFO:Initializing Passive Aggressive Regressor
2023-09-14 15:03:39,566:INFO:Total runtime is 0.1830780824025472 minutes
2023-09-14 15:03:39,567:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:39,568:INFO:Initializing create_model()
2023-09-14 15:03:39,568:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:39,568:INFO:Checking exceptions
2023-09-14 15:03:39,568:INFO:Importing libraries
2023-09-14 15:03:39,568:INFO:Copying training dataset
2023-09-14 15:03:39,570:INFO:Defining folds
2023-09-14 15:03:39,570:INFO:Declaring metric variables
2023-09-14 15:03:39,574:INFO:Importing untrained model
2023-09-14 15:03:39,578:INFO:Passive Aggressive Regressor Imported successfully
2023-09-14 15:03:39,583:INFO:Starting cross validation
2023-09-14 15:03:39,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:40,218:INFO:Calculating mean and std
2023-09-14 15:03:40,219:INFO:Creating metrics dataframe
2023-09-14 15:03:40,300:INFO:Uploading results into container
2023-09-14 15:03:40,301:INFO:Uploading model into container now
2023-09-14 15:03:40,301:INFO:_master_model_container: 9
2023-09-14 15:03:40,301:INFO:_display_container: 2
2023-09-14 15:03:40,301:INFO:PassiveAggressiveRegressor(random_state=820)
2023-09-14 15:03:40,301:INFO:create_model() successfully completed......................................
2023-09-14 15:03:40,411:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:40,412:INFO:Creating metrics dataframe
2023-09-14 15:03:40,419:INFO:Initializing Huber Regressor
2023-09-14 15:03:40,419:INFO:Total runtime is 0.19730785687764485 minutes
2023-09-14 15:03:40,421:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:40,421:INFO:Initializing create_model()
2023-09-14 15:03:40,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:40,421:INFO:Checking exceptions
2023-09-14 15:03:40,421:INFO:Importing libraries
2023-09-14 15:03:40,421:INFO:Copying training dataset
2023-09-14 15:03:40,425:INFO:Defining folds
2023-09-14 15:03:40,425:INFO:Declaring metric variables
2023-09-14 15:03:40,427:INFO:Importing untrained model
2023-09-14 15:03:40,429:INFO:Huber Regressor Imported successfully
2023-09-14 15:03:40,433:INFO:Starting cross validation
2023-09-14 15:03:40,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:41,112:INFO:Calculating mean and std
2023-09-14 15:03:41,113:INFO:Creating metrics dataframe
2023-09-14 15:03:41,198:INFO:Uploading results into container
2023-09-14 15:03:41,199:INFO:Uploading model into container now
2023-09-14 15:03:41,199:INFO:_master_model_container: 10
2023-09-14 15:03:41,199:INFO:_display_container: 2
2023-09-14 15:03:41,199:INFO:HuberRegressor()
2023-09-14 15:03:41,199:INFO:create_model() successfully completed......................................
2023-09-14 15:03:41,313:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:41,313:INFO:Creating metrics dataframe
2023-09-14 15:03:41,320:INFO:Initializing K Neighbors Regressor
2023-09-14 15:03:41,320:INFO:Total runtime is 0.21231133143107095 minutes
2023-09-14 15:03:41,322:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:41,322:INFO:Initializing create_model()
2023-09-14 15:03:41,322:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:41,322:INFO:Checking exceptions
2023-09-14 15:03:41,322:INFO:Importing libraries
2023-09-14 15:03:41,322:INFO:Copying training dataset
2023-09-14 15:03:41,325:INFO:Defining folds
2023-09-14 15:03:41,325:INFO:Declaring metric variables
2023-09-14 15:03:41,328:INFO:Importing untrained model
2023-09-14 15:03:41,331:INFO:K Neighbors Regressor Imported successfully
2023-09-14 15:03:41,337:INFO:Starting cross validation
2023-09-14 15:03:41,338:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:42,061:INFO:Calculating mean and std
2023-09-14 15:03:42,062:INFO:Creating metrics dataframe
2023-09-14 15:03:42,195:INFO:Uploading results into container
2023-09-14 15:03:42,196:INFO:Uploading model into container now
2023-09-14 15:03:42,196:INFO:_master_model_container: 11
2023-09-14 15:03:42,196:INFO:_display_container: 2
2023-09-14 15:03:42,196:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-14 15:03:42,196:INFO:create_model() successfully completed......................................
2023-09-14 15:03:42,310:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:42,310:INFO:Creating metrics dataframe
2023-09-14 15:03:42,317:INFO:Initializing Decision Tree Regressor
2023-09-14 15:03:42,317:INFO:Total runtime is 0.2289392590522766 minutes
2023-09-14 15:03:42,320:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:42,320:INFO:Initializing create_model()
2023-09-14 15:03:42,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:42,321:INFO:Checking exceptions
2023-09-14 15:03:42,321:INFO:Importing libraries
2023-09-14 15:03:42,321:INFO:Copying training dataset
2023-09-14 15:03:42,324:INFO:Defining folds
2023-09-14 15:03:42,324:INFO:Declaring metric variables
2023-09-14 15:03:42,326:INFO:Importing untrained model
2023-09-14 15:03:42,329:INFO:Decision Tree Regressor Imported successfully
2023-09-14 15:03:42,333:INFO:Starting cross validation
2023-09-14 15:03:42,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:42,971:INFO:Calculating mean and std
2023-09-14 15:03:42,972:INFO:Creating metrics dataframe
2023-09-14 15:03:43,053:INFO:Uploading results into container
2023-09-14 15:03:43,053:INFO:Uploading model into container now
2023-09-14 15:03:43,053:INFO:_master_model_container: 12
2023-09-14 15:03:43,053:INFO:_display_container: 2
2023-09-14 15:03:43,054:INFO:DecisionTreeRegressor(random_state=820)
2023-09-14 15:03:43,054:INFO:create_model() successfully completed......................................
2023-09-14 15:03:43,192:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:43,192:INFO:Creating metrics dataframe
2023-09-14 15:03:43,205:INFO:Initializing Random Forest Regressor
2023-09-14 15:03:43,205:INFO:Total runtime is 0.24373352130254108 minutes
2023-09-14 15:03:43,210:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:43,211:INFO:Initializing create_model()
2023-09-14 15:03:43,211:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:43,211:INFO:Checking exceptions
2023-09-14 15:03:43,211:INFO:Importing libraries
2023-09-14 15:03:43,211:INFO:Copying training dataset
2023-09-14 15:03:43,214:INFO:Defining folds
2023-09-14 15:03:43,214:INFO:Declaring metric variables
2023-09-14 15:03:43,217:INFO:Importing untrained model
2023-09-14 15:03:43,221:INFO:Random Forest Regressor Imported successfully
2023-09-14 15:03:43,226:INFO:Starting cross validation
2023-09-14 15:03:43,227:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:44,175:INFO:Calculating mean and std
2023-09-14 15:03:44,176:INFO:Creating metrics dataframe
2023-09-14 15:03:44,264:INFO:Uploading results into container
2023-09-14 15:03:44,265:INFO:Uploading model into container now
2023-09-14 15:03:44,265:INFO:_master_model_container: 13
2023-09-14 15:03:44,265:INFO:_display_container: 2
2023-09-14 15:03:44,265:INFO:RandomForestRegressor(n_jobs=-1, random_state=820)
2023-09-14 15:03:44,265:INFO:create_model() successfully completed......................................
2023-09-14 15:03:44,371:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:44,371:INFO:Creating metrics dataframe
2023-09-14 15:03:44,379:INFO:Initializing Extra Trees Regressor
2023-09-14 15:03:44,379:INFO:Total runtime is 0.2632959206899007 minutes
2023-09-14 15:03:44,381:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:44,381:INFO:Initializing create_model()
2023-09-14 15:03:44,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:44,381:INFO:Checking exceptions
2023-09-14 15:03:44,381:INFO:Importing libraries
2023-09-14 15:03:44,381:INFO:Copying training dataset
2023-09-14 15:03:44,384:INFO:Defining folds
2023-09-14 15:03:44,384:INFO:Declaring metric variables
2023-09-14 15:03:44,386:INFO:Importing untrained model
2023-09-14 15:03:44,388:INFO:Extra Trees Regressor Imported successfully
2023-09-14 15:03:44,392:INFO:Starting cross validation
2023-09-14 15:03:44,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:45,244:INFO:Calculating mean and std
2023-09-14 15:03:45,245:INFO:Creating metrics dataframe
2023-09-14 15:03:45,332:INFO:Uploading results into container
2023-09-14 15:03:45,333:INFO:Uploading model into container now
2023-09-14 15:03:45,333:INFO:_master_model_container: 14
2023-09-14 15:03:45,333:INFO:_display_container: 2
2023-09-14 15:03:45,333:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=820)
2023-09-14 15:03:45,333:INFO:create_model() successfully completed......................................
2023-09-14 15:03:45,447:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:45,447:INFO:Creating metrics dataframe
2023-09-14 15:03:45,454:INFO:Initializing AdaBoost Regressor
2023-09-14 15:03:45,454:INFO:Total runtime is 0.2812182545661926 minutes
2023-09-14 15:03:45,457:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:45,457:INFO:Initializing create_model()
2023-09-14 15:03:45,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:45,457:INFO:Checking exceptions
2023-09-14 15:03:45,457:INFO:Importing libraries
2023-09-14 15:03:45,457:INFO:Copying training dataset
2023-09-14 15:03:45,460:INFO:Defining folds
2023-09-14 15:03:45,460:INFO:Declaring metric variables
2023-09-14 15:03:45,463:INFO:Importing untrained model
2023-09-14 15:03:45,466:INFO:AdaBoost Regressor Imported successfully
2023-09-14 15:03:45,472:INFO:Starting cross validation
2023-09-14 15:03:45,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:46,211:INFO:Calculating mean and std
2023-09-14 15:03:46,212:INFO:Creating metrics dataframe
2023-09-14 15:03:46,295:INFO:Uploading results into container
2023-09-14 15:03:46,295:INFO:Uploading model into container now
2023-09-14 15:03:46,296:INFO:_master_model_container: 15
2023-09-14 15:03:46,296:INFO:_display_container: 2
2023-09-14 15:03:46,296:INFO:AdaBoostRegressor(random_state=820)
2023-09-14 15:03:46,296:INFO:create_model() successfully completed......................................
2023-09-14 15:03:46,416:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:46,416:INFO:Creating metrics dataframe
2023-09-14 15:03:46,425:INFO:Initializing Gradient Boosting Regressor
2023-09-14 15:03:46,425:INFO:Total runtime is 0.29740237792332963 minutes
2023-09-14 15:03:46,427:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:46,428:INFO:Initializing create_model()
2023-09-14 15:03:46,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:46,428:INFO:Checking exceptions
2023-09-14 15:03:46,428:INFO:Importing libraries
2023-09-14 15:03:46,428:INFO:Copying training dataset
2023-09-14 15:03:46,431:INFO:Defining folds
2023-09-14 15:03:46,431:INFO:Declaring metric variables
2023-09-14 15:03:46,434:INFO:Importing untrained model
2023-09-14 15:03:46,436:INFO:Gradient Boosting Regressor Imported successfully
2023-09-14 15:03:46,441:INFO:Starting cross validation
2023-09-14 15:03:46,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:47,189:INFO:Calculating mean and std
2023-09-14 15:03:47,190:INFO:Creating metrics dataframe
2023-09-14 15:03:47,281:INFO:Uploading results into container
2023-09-14 15:03:47,281:INFO:Uploading model into container now
2023-09-14 15:03:47,281:INFO:_master_model_container: 16
2023-09-14 15:03:47,281:INFO:_display_container: 2
2023-09-14 15:03:47,282:INFO:GradientBoostingRegressor(random_state=820)
2023-09-14 15:03:47,282:INFO:create_model() successfully completed......................................
2023-09-14 15:03:47,407:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:47,407:INFO:Creating metrics dataframe
2023-09-14 15:03:47,415:INFO:Initializing Extreme Gradient Boosting
2023-09-14 15:03:47,415:INFO:Total runtime is 0.31389598051706946 minutes
2023-09-14 15:03:47,417:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:47,417:INFO:Initializing create_model()
2023-09-14 15:03:47,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:47,417:INFO:Checking exceptions
2023-09-14 15:03:47,417:INFO:Importing libraries
2023-09-14 15:03:47,418:INFO:Copying training dataset
2023-09-14 15:03:47,420:INFO:Defining folds
2023-09-14 15:03:47,420:INFO:Declaring metric variables
2023-09-14 15:03:47,422:INFO:Importing untrained model
2023-09-14 15:03:47,425:INFO:Extreme Gradient Boosting Imported successfully
2023-09-14 15:03:47,429:INFO:Starting cross validation
2023-09-14 15:03:47,429:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:48,164:INFO:Calculating mean and std
2023-09-14 15:03:48,165:INFO:Creating metrics dataframe
2023-09-14 15:03:48,254:INFO:Uploading results into container
2023-09-14 15:03:48,254:INFO:Uploading model into container now
2023-09-14 15:03:48,255:INFO:_master_model_container: 17
2023-09-14 15:03:48,255:INFO:_display_container: 2
2023-09-14 15:03:48,255:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=820, ...)
2023-09-14 15:03:48,255:INFO:create_model() successfully completed......................................
2023-09-14 15:03:48,376:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:48,376:INFO:Creating metrics dataframe
2023-09-14 15:03:48,383:INFO:Initializing Light Gradient Boosting Machine
2023-09-14 15:03:48,383:INFO:Total runtime is 0.33003931045532225 minutes
2023-09-14 15:03:48,385:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:48,386:INFO:Initializing create_model()
2023-09-14 15:03:48,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:48,386:INFO:Checking exceptions
2023-09-14 15:03:48,386:INFO:Importing libraries
2023-09-14 15:03:48,386:INFO:Copying training dataset
2023-09-14 15:03:48,388:INFO:Defining folds
2023-09-14 15:03:48,388:INFO:Declaring metric variables
2023-09-14 15:03:48,390:INFO:Importing untrained model
2023-09-14 15:03:48,393:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-14 15:03:48,399:INFO:Starting cross validation
2023-09-14 15:03:48,400:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:49,437:INFO:Calculating mean and std
2023-09-14 15:03:49,438:INFO:Creating metrics dataframe
2023-09-14 15:03:49,534:INFO:Uploading results into container
2023-09-14 15:03:49,534:INFO:Uploading model into container now
2023-09-14 15:03:49,534:INFO:_master_model_container: 18
2023-09-14 15:03:49,534:INFO:_display_container: 2
2023-09-14 15:03:49,535:INFO:LGBMRegressor(n_jobs=-1, random_state=820)
2023-09-14 15:03:49,535:INFO:create_model() successfully completed......................................
2023-09-14 15:03:49,652:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:49,652:INFO:Creating metrics dataframe
2023-09-14 15:03:49,659:INFO:Initializing Dummy Regressor
2023-09-14 15:03:49,659:INFO:Total runtime is 0.3513080318768819 minutes
2023-09-14 15:03:49,661:INFO:SubProcess create_model() called ==================================
2023-09-14 15:03:49,662:INFO:Initializing create_model()
2023-09-14 15:03:49,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221A31F4970>, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:49,662:INFO:Checking exceptions
2023-09-14 15:03:49,662:INFO:Importing libraries
2023-09-14 15:03:49,662:INFO:Copying training dataset
2023-09-14 15:03:49,664:INFO:Defining folds
2023-09-14 15:03:49,664:INFO:Declaring metric variables
2023-09-14 15:03:49,667:INFO:Importing untrained model
2023-09-14 15:03:49,669:INFO:Dummy Regressor Imported successfully
2023-09-14 15:03:49,673:INFO:Starting cross validation
2023-09-14 15:03:49,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-14 15:03:50,372:INFO:Calculating mean and std
2023-09-14 15:03:50,373:INFO:Creating metrics dataframe
2023-09-14 15:03:50,460:INFO:Uploading results into container
2023-09-14 15:03:50,461:INFO:Uploading model into container now
2023-09-14 15:03:50,461:INFO:_master_model_container: 19
2023-09-14 15:03:50,461:INFO:_display_container: 2
2023-09-14 15:03:50,461:INFO:DummyRegressor()
2023-09-14 15:03:50,461:INFO:create_model() successfully completed......................................
2023-09-14 15:03:50,580:INFO:SubProcess create_model() end ==================================
2023-09-14 15:03:50,580:INFO:Creating metrics dataframe
2023-09-14 15:03:50,594:INFO:Initializing create_model()
2023-09-14 15:03:50,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=820), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:50,594:INFO:Checking exceptions
2023-09-14 15:03:50,595:INFO:Importing libraries
2023-09-14 15:03:50,595:INFO:Copying training dataset
2023-09-14 15:03:50,597:INFO:Defining folds
2023-09-14 15:03:50,597:INFO:Declaring metric variables
2023-09-14 15:03:50,597:INFO:Importing untrained model
2023-09-14 15:03:50,597:INFO:Declaring custom model
2023-09-14 15:03:50,597:INFO:Extra Trees Regressor Imported successfully
2023-09-14 15:03:50,598:INFO:Cross validation set to False
2023-09-14 15:03:50,598:INFO:Fitting Model
2023-09-14 15:03:50,751:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=820)
2023-09-14 15:03:50,751:INFO:create_model() successfully completed......................................
2023-09-14 15:03:50,864:INFO:Initializing create_model()
2023-09-14 15:03:50,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=RandomForestRegressor(n_jobs=-1, random_state=820), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:50,864:INFO:Checking exceptions
2023-09-14 15:03:50,865:INFO:Importing libraries
2023-09-14 15:03:50,865:INFO:Copying training dataset
2023-09-14 15:03:50,867:INFO:Defining folds
2023-09-14 15:03:50,867:INFO:Declaring metric variables
2023-09-14 15:03:50,867:INFO:Importing untrained model
2023-09-14 15:03:50,867:INFO:Declaring custom model
2023-09-14 15:03:50,868:INFO:Random Forest Regressor Imported successfully
2023-09-14 15:03:50,868:INFO:Cross validation set to False
2023-09-14 15:03:50,868:INFO:Fitting Model
2023-09-14 15:03:51,026:INFO:RandomForestRegressor(n_jobs=-1, random_state=820)
2023-09-14 15:03:51,026:INFO:create_model() successfully completed......................................
2023-09-14 15:03:51,150:INFO:Initializing create_model()
2023-09-14 15:03:51,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=AdaBoostRegressor(random_state=820), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:51,150:INFO:Checking exceptions
2023-09-14 15:03:51,151:INFO:Importing libraries
2023-09-14 15:03:51,151:INFO:Copying training dataset
2023-09-14 15:03:51,153:INFO:Defining folds
2023-09-14 15:03:51,153:INFO:Declaring metric variables
2023-09-14 15:03:51,154:INFO:Importing untrained model
2023-09-14 15:03:51,154:INFO:Declaring custom model
2023-09-14 15:03:51,154:INFO:AdaBoost Regressor Imported successfully
2023-09-14 15:03:51,154:INFO:Cross validation set to False
2023-09-14 15:03:51,154:INFO:Fitting Model
2023-09-14 15:03:51,248:INFO:AdaBoostRegressor(random_state=820)
2023-09-14 15:03:51,248:INFO:create_model() successfully completed......................................
2023-09-14 15:03:51,362:INFO:Initializing create_model()
2023-09-14 15:03:51,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221A4985D30>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-14 15:03:51,362:INFO:Checking exceptions
2023-09-14 15:03:51,363:INFO:Importing libraries
2023-09-14 15:03:51,363:INFO:Copying training dataset
2023-09-14 15:03:51,365:INFO:Defining folds
2023-09-14 15:03:51,365:INFO:Declaring metric variables
2023-09-14 15:03:51,365:INFO:Importing untrained model
2023-09-14 15:03:51,365:INFO:Declaring custom model
2023-09-14 15:03:51,366:INFO:K Neighbors Regressor Imported successfully
2023-09-14 15:03:51,366:INFO:Cross validation set to False
2023-09-14 15:03:51,366:INFO:Fitting Model
2023-09-14 15:03:51,438:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-14 15:03:51,438:INFO:create_model() successfully completed......................................
2023-09-14 15:03:51,574:INFO:_master_model_container: 19
2023-09-14 15:03:51,574:INFO:_display_container: 2
2023-09-14 15:03:51,575:INFO:[ExtraTreesRegressor(n_jobs=-1, random_state=820), RandomForestRegressor(n_jobs=-1, random_state=820), AdaBoostRegressor(random_state=820), KNeighborsRegressor(n_jobs=-1)]
2023-09-14 15:03:51,575:INFO:compare_models() successfully completed......................................
